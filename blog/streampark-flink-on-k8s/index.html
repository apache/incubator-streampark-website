<!doctype html>
<html lang="en" dir="ltr" class="blog-wrapper blog-post-page plugin-blog plugin-id-default" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.3.2">
<title data-rh="true">Apache StreamPark™ Flink on Kubernetes practice | Apache StreamPark (incubating)</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://streampark.apache.org/blog/streampark-flink-on-k8s"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" property="og:locale:alternate" content="zh_CN"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docusaurus_tag" content="default"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docsearch:docusaurus_tag" content="default"><meta data-rh="true" property="og:title" content="Apache StreamPark™ Flink on Kubernetes practice | Apache StreamPark (incubating)"><meta data-rh="true" name="description" content="Wuxin Technology was founded in January 2018. The current main business includes the research and development, design, manufacturing and sales of RELX brand products. With core technologies and capabilities covering the entire industry chain, RELX is committed to providing users with products that are both high quality and safe"><meta data-rh="true" property="og:description" content="Wuxin Technology was founded in January 2018. The current main business includes the research and development, design, manufacturing and sales of RELX brand products. With core technologies and capabilities covering the entire industry chain, RELX is committed to providing users with products that are both high quality and safe"><meta data-rh="true" property="og:type" content="article"><meta data-rh="true" property="article:published_time" content="2024-10-18T07:44:07.000Z"><meta data-rh="true" property="article:tag" content="StreamPark,Production Practice,FlinkSQL,Kubernetes"><link data-rh="true" rel="icon" href="/image/favicon.ico"><link data-rh="true" rel="canonical" href="https://streampark.apache.org/blog/streampark-flink-on-k8s"><link data-rh="true" rel="alternate" href="https://streampark.apache.org/blog/streampark-flink-on-k8s" hreflang="en"><link data-rh="true" rel="alternate" href="https://streampark.apache.org/zh-CN/blog/streampark-flink-on-k8s" hreflang="zh-CN"><link data-rh="true" rel="alternate" href="https://streampark.apache.org/blog/streampark-flink-on-k8s" hreflang="x-default"><link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="Apache StreamPark (incubating) RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="Apache StreamPark (incubating) Atom Feed"><link rel="stylesheet" href="/assets/css/styles.2815dd1e.css">
<script src="/assets/js/runtime~main.788200c2.js" defer="defer"></script>
<script src="/assets/js/main.237a4499.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return localStorage.getItem("theme")}catch(t){}}();null!==e?t(e):window.matchMedia("(prefers-color-scheme: dark)").matches?t("dark"):window.matchMedia("(prefers-color-scheme: light)").matches?t("light"):t("dark")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_BCtO" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/image/logo.png" alt="StreamPark Logo" class="themedComponent_Cvhi themedComponent--light_uT2j"><img src="/image/logo.png" alt="StreamPark Logo" class="themedComponent_Cvhi themedComponent--dark_ENih"></div><b class="navbar__title text--truncate">StreamPark</b></a></div><div class="navbar__items navbar__items--right"><a class="navbar__item navbar__link" href="/docs/get-started/intro">Docs</a><a class="navbar__item navbar__link" href="/download">Download</a><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link">Community</a><ul class="dropdown__menu"><li><a href="https://www.apache.org/foundation/policies/conduct" target="_blank" rel="noopener noreferrer" class="dropdown__link">Code of conduct</a></li><li><a class="dropdown__link" href="/community/contribution_guide/mailing_lists">Join the mailing lists</a></li><li><a class="dropdown__link" href="/community/contribution_guide/become_committer">Become A Committer</a></li><li><a class="dropdown__link" href="/community/contribution_guide/become_pmc_member">Become A PMC member</a></li><li><a class="dropdown__link" href="/community/contribution_guide/new_committer_process">New Committer Process</a></li><li><a class="dropdown__link" href="/community/contribution_guide/new_pmc_ember_process">New PMC Member Process</a></li><li><a class="dropdown__link" href="/community/submit_guide/document">Documentation Notice</a></li><li><a class="dropdown__link" href="/community/submit_guide/submit_code">Submit Code</a></li><li><a class="dropdown__link" href="/community/submit_guide/code_style_and_quality_guide">Code style and quality guide</a></li><li><a class="dropdown__link" href="/community/submit_guide/documentation_style_guide">Documentation style guide</a></li><li><a class="dropdown__link" href="/community/release/how_to_release_version_2.1.x">How to release version 2.1.x</a></li><li><a class="dropdown__link" href="/community/release/how_to_verify_release">How to Verify Release</a></li></ul></div><a class="navbar__item navbar__link" href="/team">Team</a><a class="navbar__item navbar__link" href="/user">Users</a><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link">ASF</a><ul class="dropdown__menu"><li><a href="https://www.apache.org/" target="_blank" rel="noopener noreferrer" class="dropdown__link">Foundation</a></li><li><a href="https://www.apache.org/licenses/" target="_blank" rel="noopener noreferrer" class="dropdown__link">License</a></li><li><a href="https://www.apache.org/events/current-event" target="_blank" rel="noopener noreferrer" class="dropdown__link">Events</a></li><li><a href="https://www.apache.org/security/" target="_blank" rel="noopener noreferrer" class="dropdown__link">Security</a></li><li><a href="https://www.apache.org/foundation/sponsorship.html" target="_blank" rel="noopener noreferrer" class="dropdown__link">Sponsorship</a></li><li><a href="https://www.apache.org/foundation/policies/privacy.html" target="_blank" rel="noopener noreferrer" class="dropdown__link">Privacy</a></li><li><a href="https://www.apache.org/foundation/thanks.html" target="_blank" rel="noopener noreferrer" class="dropdown__link">Thanks</a></li></ul></div><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/blog">Blog</a><a href="https://github.com/apache/incubator-streampark/issues/507" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">FAQ</a><a href="https://github.com/apache/incubator-streampark" target="_blank" class="githubStars_qnS9"><div class="githubStarsContainer_O7dk"><svg width="16" height="16" viewBox="0 0 16 16" fill="none" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" clip-rule="evenodd" d="M8 1.75C4.27062 1.75 1.25 4.77062 1.25 8.5C1.25 11.4869 3.18219 14.0097 5.86531 14.9041C6.20281 14.9631 6.32937 14.7606 6.32937 14.5834C6.32937 14.4231 6.32094 13.8916 6.32094 13.3263C4.625 13.6384 4.18625 12.9128 4.05125 12.5331C3.97531 12.3391 3.64625 11.74 3.35938 11.5797C3.12312 11.4531 2.78562 11.1409 3.35094 11.1325C3.8825 11.1241 4.26219 11.6219 4.38875 11.8244C4.99625 12.8453 5.96656 12.5584 6.35469 12.3813C6.41375 11.9425 6.59094 11.6472 6.785 11.4784C5.28312 11.3097 3.71375 10.7275 3.71375 8.14563C3.71375 7.41156 3.97531 6.80406 4.40563 6.33156C4.33812 6.16281 4.10187 5.47094 4.47312 4.54281C4.47312 4.54281 5.03844 4.36563 6.32937 5.23469C6.86937 5.08281 7.44313 5.00687 8.01688 5.00687C8.59063 5.00687 9.16438 5.08281 9.70438 5.23469C10.9953 4.35719 11.5606 4.54281 11.5606 4.54281C11.9319 5.47094 11.6956 6.16281 11.6281 6.33156C12.0584 6.80406 12.32 7.40312 12.32 8.14563C12.32 10.7359 10.7422 11.3097 9.24031 11.4784C9.485 11.6894 9.69594 12.0944 9.69594 12.7272C9.69594 13.63 9.6875 14.3556 9.6875 14.5834C9.6875 14.7606 9.81406 14.9716 10.1516 14.9041C12.8178 14.0097 14.75 11.4784 14.75 8.5C14.75 4.77062 11.7294 1.75 8 1.75Z" fill="currentColor"></path></svg><span class="githubText_YlX6">3.9k</span></div></a><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link"><svg viewBox="0 0 24 24" width="20" height="20" aria-hidden="true" class="iconLanguage_DSK9"><path fill="currentColor" d="M12.87 15.07l-2.54-2.51.03-.03c1.74-1.94 2.98-4.17 3.71-6.53H17V4h-7V2H8v2H1v1.99h11.17C11.5 7.92 10.44 9.75 9 11.35 8.07 10.32 7.3 9.19 6.69 8h-2c.73 1.63 1.73 3.17 2.98 4.56l-5.09 5.02L4 19l5-5 3.11 3.11.76-2.04zM18.5 10h-2L12 22h2l1.12-3h4.75L21 22h2l-4.5-12zm-2.62 7l1.62-4.33L19.12 17h-3.24z"></path></svg></a><ul class="dropdown__menu"><li><a href="/blog/streampark-flink-on-k8s" target="_self" rel="noopener noreferrer" class="dropdown__link dropdown__link--active" lang="en">English</a></li><li><a href="/zh-CN/blog/streampark-flink-on-k8s" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="zh-CN">简体中文</a></li></ul></div><a class="colorModeButton_yITp undefined"><svg xmlns="http://www.w3.org/2000/svg" fill="none" width="16" height="16" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" class="w-6 h-6"><path stroke-linecap="round" stroke-linejoin="round" d="M21.752 15.002A9.718 9.718 0 0118 15.75c-5.385 0-9.75-4.365-9.75-9.75 0-1.33.266-2.597.748-3.752A9.753 9.753 0 003 11.25C3 16.635 7.365 21 12.75 21a9.753 9.753 0 009.002-5.998z"></path></svg></a><div class="navbarSearchContainer_dCNk"><div class="navbar__search searchBarContainer_SuYZ"><input placeholder="Search" aria-label="Search" class="navbar__search-input"><div class="loadingRing_HgBb searchBarLoadingRing_om0w"><div></div><div></div><div></div><div></div></div></div></div><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_pmYA"><div class="container-wrapper blog-container"><div class="container margin-vert--lg"><div class="row"><aside class="col col--2 overflow-hidden" style="opacity:0;transform:translateX(-100px) translateZ(0)"><nav class="sidebar_brwN thin-scrollbar" aria-label="Blog recent posts navigation"><div class="backButton_MCHS"><svg xmlns="http://www.w3.org/2000/svg" width="32" height="32" viewBox="0 0 24 24"><path fill="currentColor" d="M8 7v4L2 6l6-5v4h5a8 8 0 1 1 0 16H4v-2h9a6 6 0 0 0 0-12H8Z"></path></svg></div><a class="sidebarItemTitle_r4Q1 margin-bottom--sm" href="/blog">近期文章</a><ul class="sidebarItemList_QwSx clean-list"><li class="sidebarItem_lnhn"><a aria-current="page" class="sidebarItemLink_yNGZ sidebarItemLinkActive_oSRm" href="/blog/streampark-flink-on-k8s">Apache StreamPark™ Flink on Kubernetes practice</a></li><li class="sidebarItem_lnhn"><a class="sidebarItemLink_yNGZ" href="/blog/flink-development-framework-streampark">Apache StreamPark™ - Powerful Flink Development Framework</a></li><li class="sidebarItem_lnhn"><a class="sidebarItemLink_yNGZ" href="/blog/streampark-flink-with-paimon-in-ziru">Ziroom implements the best practice of one-key data input into the lake based on Apache StreamPark™ + Paimon</a></li><li class="sidebarItem_lnhn"><a class="sidebarItemLink_yNGZ" href="/blog/streampark-usercase-tianyancha">Apache StreamPark™ helps Tianyancha real-time platform construction｜Multiple-fold increase in efficiency</a></li><li class="sidebarItem_lnhn"><a class="sidebarItemLink_yNGZ" href="/blog/streampark-usercase-joymaker">Apache StreamPark™ Cloud Native Platform Practice at Joymaker</a></li><li class="sidebarItem_lnhn"><a class="sidebarItemLink_yNGZ" href="/blog/streampark-usercase-chinaunion">China Union&#x27;s Flink Real-Time Computing Platform Ops Practice</a></li><li class="sidebarItem_lnhn"><a class="sidebarItemLink_yNGZ" href="/blog/streampark-usercase-bondex-with-paimon">Based on Apache Paimon + Apache StreamPark™&#x27;s Streaming Data Warehouse Practice by Bondex</a></li><li class="sidebarItem_lnhn"><a class="sidebarItemLink_yNGZ" href="/blog/streampark-usercase-shunwang">Apache StreamPark™ in the Large-Scale Production Practice at Shunwang Technology</a></li><li class="sidebarItem_lnhn"><a class="sidebarItemLink_yNGZ" href="/blog/streampark-usercase-dustess">Apache StreamPark™&#x27;s Best Practices at Dustess, Simplifying Complexity for the Ultimate Experience</a></li><li class="sidebarItem_lnhn"><a class="sidebarItemLink_yNGZ" href="/blog/streampark-usercase-joyme">Apache StreamPark™&#x27;s Production Practice in Joyme</a></li><li class="sidebarItem_lnhn"><a class="sidebarItemLink_yNGZ" href="/blog/streampark-usercase-haibo">An All-in-One Computation Tool in Haibo Tech&#x27;s Production Practice and facilitation in Smart City Construction</a></li><li class="sidebarItem_lnhn"><a class="sidebarItemLink_yNGZ" href="/blog/streampark-usercase-ziru">Ziroom&#x27;s Real-Time Computing Platform Practice Based on Apache StreamPark™</a></li><li class="sidebarItem_lnhn"><a class="sidebarItemLink_yNGZ" href="/blog/streampark-usercase-changan">Changan Automobile’s upgrade practice from self-developed platform to Apache StreamPark™</a></li></ul></nav></aside><main class="col col--8 overflow-hidden" itemscope="" itemtype="http://schema.org/Blog"><div><div class="row" style="margin:0"><div class="col col--12 article__details article-bg"><article itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><meta itemprop="description" content="Wuxin Technology was founded in January 2018. The current main business includes the research and development, design, manufacturing and sales of RELX brand products. With core technologies and capabilities covering the entire industry chain, RELX is committed to providing users with products that are both high quality and safe"><header><h1 class="margin-bottom--md blogPostTitle_thoQ text--center post--titleLink" itemprop="headline">Apache StreamPark™ Flink on Kubernetes practice</h1><div class="margin-vert--md"><time datetime="2024-10-18T07:44:07.000Z" itemprop="datePublished"></time> · <!-- -->14 min read</div></header><div id="__blog-post-container" class="markdown" itemprop="articleBody"><p>Wuxin Technology was founded in January 2018. The current main business includes the research and development, design, manufacturing and sales of RELX brand products. With core technologies and capabilities covering the entire industry chain, RELX is committed to providing users with products that are both high quality and safe.</p>
<h2 class="anchor anchorWithStickyNavbar_myWT" id="why-choose-native-kubernetes"><strong>Why Choose Native Kubernetes</strong><a href="#why-choose-native-kubernetes" class="hash-link" aria-label="Direct link to why-choose-native-kubernetes" title="Direct link to why-choose-native-kubernetes">​</a></h2>
<p>Native Kubernetes offers the following advantages:</p>
<ul>
<li>
<p>Shorter Failover time</p>
</li>
<li>
<p>Resource hosting can be implemented without the need to manually create TaskManager Pods, which can be automatically destroyed</p>
</li>
<li>
<p>With more convenient HA, in Native Kubernetes mode after Flink version 1.12, you can rely on the Leader election mechanism of native Kubernetes to complete JobManager&#x27;s HA</p>
<p>The main difference between Native Kubernetes and Standalone Kubernetes lies in the way Flink interacts with Kubernetes and the resulting series of advantages. Standalone Kubernetes requires users to customize the Kubernetes resource description files of JobManager and TaskManager. When submitting a job, you need to use kubectl combined with the resource description file to start the Flink cluster. The Native Kubernetes mode Flink Client integrates a Kubernetes Client, which can directly communicate with the Kubernetes API Server to complete the creation of JobManager Deployment and ConfigMap. After JobManager Development is created, the Resource Manager module in it can directly communicate with the Kubernetes API Server to complete the creation and destruction of TaskManager pods and the elastic scaling of Taskmanager. Therefore, it is recommended to use Flink on Native Kubernetes mode to deploy Flink tasks in production environments.</p>
</li>
</ul>
<p><img decoding="async" loading="lazy" src="/assets/images/nativekubernetes_architecture-ad376f8ae79ab66d90d95742e8335d53.png" width="1080" height="401" class="img__KcZ"></p>
<p>When Flink On Kubernetes meets StreamPark</p>
<p>Flink on Native Kubernetes currently supports Application mode and Session mode. Compared with the two, Application mode deployment avoids the resource isolation problem and client resource consumption problem of Session mode. Therefore, it is recommended to use Application Mode to deploy Flink tasks in ** production environments. **Let’s take a look at the method of using the original script and the process of using StreamPark to develop and deploy a Flink on Native Kubernetes job.
Deploy Kubernetes using scripts</p>
<p>In the absence of a platform that supports Flink on Kubernetes task development and deployment, you need to use scripts to submit and stop tasks. This is also the default method provided by Flink. The specific steps are as follows:</p>
<ol>
<li>Prepare the kubectl and Docker command running environment on the Flink client node, create the Kubernetes Namespace and Service Account used to deploy the Flink job, and perform RBAC</li>
<li>Write a Dockerfile file to package the Flink base image and the user’s job Jar together</li>
</ol>
<div class="language-dockerfile codeBlockContainer_APcc theme-code-block"><div class="codeBlockContent_IhPH"><pre tabindex="0" class="prism-code language-dockerfile codeBlock_tTXe thin-scrollbar" style="color:#9CDCFE;background-color:#1E1E1E"><code class="codeBlockLines_qImF"><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">FROM flink:1.13.6-scala_2.11</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">RUN mkdir -p $FLINK_HOME/usrlib</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">COPY my-flink-job.jar $FLINK_HOME/usrlib/my-flink-job.jar</span><br></span></code></pre><div class="buttonGroup_inAn"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_N8Av" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_EGLt"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_gJas"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<ol start="3">
<li>Use Flink client script to start Flink tasks</li>
</ol>
<div class="language-shell codeBlockContainer_APcc theme-code-block"><div class="codeBlockContent_IhPH"><pre tabindex="0" class="prism-code language-shell codeBlock_tTXe thin-scrollbar" style="color:#9CDCFE;background-color:#1E1E1E"><code class="codeBlockLines_qImF"><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">./bin/flink run-application \</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">    --target kubernetes-application \</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">    -Dkubernetes.namespace=flink-cluster \</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">    -Dkubernetes.jobmanager.service-account=default \</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">    -Dkubernetes.cluster-id=my-first-application-cluster \</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">    -Dkubernetes.container.image=relx_docker_url/streamx/relx_flink_1.13.6-scala_2.11:latest \</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">    -Dkubernetes.rest-service.exposed.type=NodePort \</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">    local:///opt/flink/usrlib/my-flink-job.jar</span><br></span></code></pre><div class="buttonGroup_inAn"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_N8Av" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_EGLt"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_gJas"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<ol start="4">
<li>Use the Kubectl command to obtain the WebUI access address and JobId of the Flink job.</li>
</ol>
<div class="language-shell codeBlockContainer_APcc theme-code-block"><div class="codeBlockContent_IhPH"><pre tabindex="0" class="prism-code language-shell codeBlock_tTXe thin-scrollbar" style="color:#9CDCFE;background-color:#1E1E1E"><code class="codeBlockLines_qImF"><span class="token-line" style="color:#9CDCFE"><span class="token plain">kubectl -n flink-cluster get svc</span><br></span></code></pre><div class="buttonGroup_inAn"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_N8Av" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_EGLt"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_gJas"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<ol start="5">
<li>Stop the job using Flink command</li>
</ol>
<div class="language-shell codeBlockContainer_APcc theme-code-block"><div class="codeBlockContent_IhPH"><pre tabindex="0" class="prism-code language-shell codeBlock_tTXe thin-scrollbar" style="color:#9CDCFE;background-color:#1E1E1E"><code class="codeBlockLines_qImF"><span class="token-line" style="color:#9CDCFE"><span class="token plain">./bin/flink cancel</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">    --target kubernetes-application</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">    -Dkubernetes.cluster-id=my-first-application-cluster</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">    -Dkubernetes.namespace=flink-cluster &lt;jobId&gt;</span><br></span></code></pre><div class="buttonGroup_inAn"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_N8Av" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_EGLt"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_gJas"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>The above is the process of deploying a Flink task to Kubernetes using the most original script method provided by Flink. Only the most basic task submission is achieved. If it is to reach the production use level, there are still a series of problems that need to be solved, such as: the method is too Originally, it was unable to adapt to large batches of tasks, unable to record task checkpoints and real-time status tracking, difficult to operate and monitor tasks, had no alarm mechanism, and could not be managed in a centralized manner, etc.</p>
<h2 class="anchor anchorWithStickyNavbar_myWT" id="deploy-flink-on-kubernetes-using-apache-streampark"><strong>Deploy Flink on Kubernetes using Apache StreamPark™</strong><a href="#deploy-flink-on-kubernetes-using-apache-streampark" class="hash-link" aria-label="Direct link to deploy-flink-on-kubernetes-using-apache-streampark" title="Direct link to deploy-flink-on-kubernetes-using-apache-streampark">​</a></h2>
<p>There will be higher requirements for using Flink on Kubernetes in enterprise-level production environments. Generally, you will choose to build your own platform or purchase related commercial products. No matter which solution meets the product capabilities: large-scale task development and deployment, status tracking, operation and maintenance monitoring , failure alarms, unified task management, high availability, etc. are common demands.</p>
<p>In response to the above issues, we investigated open source projects in the open source field that support the development and deployment of Flink on Kubernetes tasks. During the investigation, we also encountered other excellent open source projects. After comprehensively comparing multiple open source projects, we came to the conclusion: **StreamPark has great performance in either completness, user experience, or stability, so we finally chose StreamPark as our one-stop real-time computing platform. **</p>
<p>Let’s take a look at how StreamPark supports Flink on Kubernetes:</p>
<h3 class="anchor anchorWithStickyNavbar_myWT" id="basic-environment-configuration"><strong>Basic environment configuration</strong><a href="#basic-environment-configuration" class="hash-link" aria-label="Direct link to basic-environment-configuration" title="Direct link to basic-environment-configuration">​</a></h3>
<p>Basic environment configuration includes Kubernetes and Docker repository information as well as Flink client information configuration. The simplest way for the Kubernetes basic environment is to directly copy the .kube/config of the Kubernetes node to the StreamPark node user directory, and then use the kubectl command to create a Flink-specific Kubernetes Namespace and perform RBAC configuration.</p>
<div class="language-shell codeBlockContainer_APcc theme-code-block"><div class="codeBlockContent_IhPH"><pre tabindex="0" class="prism-code language-shell codeBlock_tTXe thin-scrollbar" style="color:#9CDCFE;background-color:#1E1E1E"><code class="codeBlockLines_qImF"><span class="token-line" style="color:#9CDCFE"><span class="token plain"># Create k8s namespace used by Flink jobs</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">kubectl create ns flink-cluster</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"># Bind RBAC resources to the default user</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">kubectl create clusterrolebinding flink-role-binding-default --clusterrole=edit --serviceaccount=flink-cluster:default</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span></code></pre><div class="buttonGroup_inAn"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_N8Av" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_EGLt"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_gJas"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Docker account information can be configured directly in the Docker Setting interface:</p>
<p><img decoding="async" loading="lazy" src="/assets/images/docker_setting-80acf43cf64fd390e4d50da8830671c0.png" width="1080" height="586" class="img__KcZ"></p>
<p>StreamPark can adapt to multi-version Flink job development. The Flink client can be configured directly on the StreamPark Setting interface:</p>
<p><img decoding="async" loading="lazy" src="/assets/images/flinkversion_setting-b170a43882590683ea0c7f109f909396.png" width="1080" height="352" class="img__KcZ"></p>
<h3 class="anchor anchorWithStickyNavbar_myWT" id="job-development"><strong>Job development</strong><a href="#job-development" class="hash-link" aria-label="Direct link to job-development" title="Direct link to job-development">​</a></h3>
<p>After StreamPark has configured the basic environment, it only takes three steps to develop and deploy a Flink job:</p>
<p><img decoding="async" loading="lazy" src="/assets/images/development_process-476918cfd29159983fe26b36ef487895.png" width="1080" height="271" class="img__KcZ"></p>
<p>StreamPark supports both Upload Jar and direct writing of Flink SQL jobs. <strong>Flink SQL jobs only need to enter SQL and dependencies. This method greatly improves the development experience and avoids problems such as dependency conflicts.</strong> This article does not focus on this part。</p>
<p>Here you need to select the deployment mode as kubernetes application, and configure the following parameters on the job development page: The parameters in the red box are the basic parameters of Flink on Kubernetes.</p>
<p><img decoding="async" loading="lazy" src="/assets/images/kubernetes_base_parameters-1a28fec8d9d3dc57744324db4ef58551.png" width="1080" height="1104" class="img__KcZ"></p>
<p>The following parameters are parameters related to Flink jobs and resources. The choice of Resolve Order is related to the code loading mode. For jobs uploaded by the Upload Jar developed by the DataStream API, choose to use Child-first, and for Flink SQL jobs, choose to use Parent-first loading.</p>
<p><img decoding="async" loading="lazy" src="/assets/images/flink_parameters-ff7790882a753bd88fbf5db9b775a0e3.png" width="1080" height="1133" class="img__KcZ"></p>
<p>Finally, there are the following two heavyweight parameters. For Native Kubernetes, k8s-pod-template generally only requires pod-template configuration. Dynamic Option is a supplement to the pod-template parameters. For some personalized configurations, you can Configured in Dynamic Option. For more Dynamic Option, please directly refer to the Flink official website.</p>
<p><img decoding="async" loading="lazy" src="/assets/images/pod_template-722285f448ec8adc0fa939d0baea2d10.png" width="1080" height="1104" class="img__KcZ"></p>
<h3 class="anchor anchorWithStickyNavbar_myWT" id="job-online"><strong>Job online</strong><a href="#job-online" class="hash-link" aria-label="Direct link to job-online" title="Direct link to job-online">​</a></h3>
<p>After the job development is completed, the job comes online. In this step, StreamPark has done a lot of work, as follows:</p>
<ul>
<li>Prepare environment</li>
<li>Dependency download in job</li>
<li>Build job (JAR package)</li>
<li>Build image</li>
<li>Push the image to the remote repository</li>
</ul>
<p><strong>For users: Just click the cloud-shaped online button in the task list</strong></p>
<p><img decoding="async" loading="lazy" src="/assets/images/operation-067a84b9b5b1491206780076f98e6f8d.png" width="1080" height="573" class="img__KcZ"></p>
<p>We can see a series of work done by StreamPark when building and pushing the image: <strong>Read the configuration, build the image, and push the image to the remote repository...</strong> I want to give StreamPark a big thumbs up!</p>
<p><img decoding="async" loading="lazy" src="/assets/images/step_details-301b14f2dbfa9c41f4c0e75a9086f0a4.png" width="948" height="1866" class="img__KcZ"></p>
<h3 class="anchor anchorWithStickyNavbar_myWT" id="assignment-submission"><strong>Assignment submission</strong><a href="#assignment-submission" class="hash-link" aria-label="Direct link to assignment-submission" title="Direct link to assignment-submission">​</a></h3>
<p>Finally, you only need to click the start Application button in Operation to start a Flink on Kubernetes job. After the job is successfully started, click on the job name to jump to the Jobmanager WebUI page. The whole process is very simple and smooth.</p>
<p><img decoding="async" loading="lazy" src="/assets/images/homework_submit-1f05dacf0fedfd1423f89ca2dec28437.png" width="1080" height="698" class="img__KcZ"></p>
<p>The entire process only requires the above three steps to complete the development and deployment of a Flink on Kubernetes job on StreamPark. StreamPark&#x27;s support for Flink on Kubernetes goes far beyond simply submitting a task.</p>
<h3 class="anchor anchorWithStickyNavbar_myWT" id="job-management"><strong>Job management</strong><a href="#job-management" class="hash-link" aria-label="Direct link to job-management" title="Direct link to job-management">​</a></h3>
<p><strong>After the job is submitted, StreamPark can obtain the latest checkpoint address of the task, the running status of the task, and the real-time resource consumption information of the cluster in real time. It can very conveniently start and stop the running task with one click, and supports recording the savepoint location when stopping the job. , as well as functions such as restoring the state from savepoint when restarting, thus ensuring the data consistency of the production environment and truly possessing the one-stop development, deployment, operation and maintenance monitoring capabilities of Flink on Kubernetes.</strong></p>
<p>Next, let’s take a look at how StreamPark supports this capability:</p>
<ul>
<li>
<p><strong>Record checkpoint in real time</strong></p>
<p>After the job is submitted, sometimes it is necessary to change the job logic but to ensure data consistency, then the platform needs to have the ability to record the location of each checkpoint in real time, as well as the ability to record the last savepoint location when stopped. StreamPark is on Flink on Kubernetes This function is implemented very well. By default, checkpoint information will be obtained and recorded in the corresponding table every 5 seconds, and according to the policy of retaining the number of checkpoints in Flink, only state.checkpoints.num-retained will be retained, and the excess will be deleted. There is an option to check the savepoint when the task is stopped. If the savepoint option is checked, the savepoint operation will be performed when the task is stopped, and the specific location of the savepoint will also be recorded in the table.</p>
<p>The root path of the default savepoint only needs to be configured in the Flink Home flink-conf.yaml file to automatically identify it. In addition to the default address, the root path of the savepoint can also be customized and specified when stopping.</p>
</li>
</ul>
<p><img decoding="async" loading="lazy" src="/assets/images/savepoint-b0288f5293875d156f20dbe768384076.png" width="1080" height="446" class="img__KcZ"></p>
<p><img decoding="async" loading="lazy" src="/assets/images/checkpoint-acf7379b24a3bac6695a517b425f466b.png" width="1080" height="479" class="img__KcZ"></p>
<ul>
<li>
<p><strong>Track running status in real time</strong></p>
<p>For challenges in the production environment, a very important point is whether monitoring is in place, especially for Flink on Kubernetes. This is very important and is the most basic capability. StreamPark can monitor the running status of Flink on Kubernetes jobs in real time and display it to users on the platform. Tasks can be easily retrieved based on various running statuses on the page.</p>
</li>
</ul>
<p><img decoding="async" loading="lazy" src="/assets/images/run_status-5a663d9169c0bce8f4cfb993db77ae59.png" width="1080" height="617" class="img__KcZ"></p>
<ul>
<li>
<p><strong>Complete alarm mechanism</strong></p>
<p>In addition, StreamPark also has complete alarm functions: supporting email, DingTalk, WeChat and SMS, etc. This is also an important reason why the company chose StreamPark as the one-stop platform for Flink on Kubernetes after initial research.</p>
</li>
</ul>
<p><img decoding="async" loading="lazy" src="/assets/images/alarm-c2104c1839a1b4bb668d48f092f25faa.png" width="1080" height="393" class="img__KcZ"></p>
<p>From the above, we can see that StreamPark has the capabilities to support the development and deployment process of Flink on Kubernetes, including: ** job development capabilities, deployment capabilities, monitoring capabilities, operation and maintenance capabilities, exception handling capabilities, etc. StreamPark provides a relatively complete set of s solution. And it already has some CICD/DevOps capabilities, and the overall completion level continues to improve. It is a product that supports the full link of Flink on Kubernetes one-stop development, deployment, operation and maintenance work in the entire open source field. StreamPark is worthy of praise. **</p>
<h2 class="anchor anchorWithStickyNavbar_myWT" id="apache-streamparks-implementation-in-wuxin-technology"><strong>Apache StreamPark™’s implementation in Wuxin Technology</strong><a href="#apache-streamparks-implementation-in-wuxin-technology" class="hash-link" aria-label="Direct link to apache-streamparks-implementation-in-wuxin-technology" title="Direct link to apache-streamparks-implementation-in-wuxin-technology">​</a></h2>
<p>StreamPark was launched late in Wuxin Technology. It is currently mainly used for the development and deployment of real-time data integration jobs and real-time indicator calculation jobs. There are Jar tasks and Flink SQL tasks, all deployed using Native Kubernetes; data sources include CDC, Kafka, etc., and Sink end There are Maxcompute, kafka, Hive, etc. The following is a screenshot of the company&#x27;s development environment StreamPark platform:</p>
<p><img decoding="async" loading="lazy" src="/assets/images/screenshot-2906914515b810aadb10db951d4f02bd.png" width="1080" height="706" class="img__KcZ"></p>
<h2 class="anchor anchorWithStickyNavbar_myWT" id="problems-encountered">Problems encountered<a href="#problems-encountered" class="hash-link" aria-label="Direct link to Problems encountered" title="Direct link to Problems encountered">​</a></h2>
<p>Any new technology has a process of exploration and fall into pitfalls. The experience of failure is precious. Here are some pitfalls and experiences that StreamPark has stepped into during the implementation of fog core technology. <strong>The content of this section is not only about StreamPark. I believe it will bring some reference to all friends who use Flink on Kubernetes</strong>.</p>
<h3 class="anchor anchorWithStickyNavbar_myWT" id="faqs-are-summarized-below"><strong>FAQs are summarized below</strong><a href="#faqs-are-summarized-below" class="hash-link" aria-label="Direct link to faqs-are-summarized-below" title="Direct link to faqs-are-summarized-below">​</a></h3>
<ul>
<li>
<p><strong>Kubernetes pod failed to pull the image</strong></p>
<p>The main problem is that Kubernetes pod-template lacks docker’s imagePullSecrets</p>
</li>
<li>
<p><strong>Scala version inconsistent</strong></p>
<p>Since StreamPark deployment requires a Scala environment, and Flink SQL operation requires the Flink SQL Client provided by StreamPark, it is necessary to ensure that the Scala version of the Flink job is consistent with the Scala version of StreamPark.</p>
</li>
<li>
<p><strong>Be aware of class conflicts</strong></p>
<p>When developing Flink SQL jobs, you need to pay attention to whether there are any class conflicts between the Flink image and the Flink connector and UDF. The best way to avoid class conflicts is to make the Flink image and the commonly used Flink connector and user UDF into a usable basic image. After that, other Flink SQL jobs can be reused directly.</p>
</li>
<li>
<p><strong>How to store checkpoint without Hadoop environment?</strong></p>
<p>HDFS, Alibaba Cloud OSS/AWS S3 can both perform checkpoint and savepoint storage. The Flink basic image already has support for OSS and S3. If you do not have HDFS, you can use Alibaba Cloud OSS or S3 to store status and checkpoint and savepoint data. You only need to use Flink Simply configure it in the dynamic parameters.</p>
</li>
</ul>
<div class="language-shell codeBlockContainer_APcc theme-code-block"><div class="codeBlockContent_IhPH"><pre tabindex="0" class="prism-code language-shell codeBlock_tTXe thin-scrollbar" style="color:#9CDCFE;background-color:#1E1E1E"><code class="codeBlockLines_qImF"><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">-Dstate.backend=rocksdb</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">-Dcontainerized.master.env.ENABLE_BUILT_IN_PLUGINS=flink-oss-fs-hadoop-1.13.6.jar</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">-Dcontainerized.taskmanager.env.ENABLE_BUILT_IN_PLUGINS=flink-oss-fs-hadoop-1.13.6.jar</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">-Dfs.oss.endpoint=xxyy.aliyuncs.com</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">-Dfs.oss.accessKeyId=xxxxxxxxxx</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">-Dfs.oss.accessKeySecret=xxxxxxxxxx</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">-Dstate.checkpoints.dir=oss://realtime-xxx/streamx/dev/checkpoints/</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">-Dstate.savepoints.dir=oss://realtime-xxx/streamx/dev/savepoints/</span><br></span></code></pre><div class="buttonGroup_inAn"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_N8Av" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_EGLt"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_gJas"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<ul>
<li>
<p><strong>The changed code did not take effect after it was republished</strong></p>
<p>This issue is related to the Kubernetes pod image pull policy. It is recommended to set the Pod image pull policy to Always:</p>
</li>
</ul>
<div class="language-shell codeBlockContainer_APcc theme-code-block"><div class="codeBlockContent_IhPH"><pre tabindex="0" class="prism-code language-shell codeBlock_tTXe thin-scrollbar" style="color:#9CDCFE;background-color:#1E1E1E"><code class="codeBlockLines_qImF"><span class="token-line" style="color:#9CDCFE"><span class="token plain">‍-Dkubernetes.container.image.pull-policy=Always</span><br></span></code></pre><div class="buttonGroup_inAn"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_N8Av" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_EGLt"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_gJas"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<ul>
<li>
<p><strong>Each restart of the task will result in one more Job instance</strong></p>
<p>Under the premise that kubernetes-based HA is configured, when you need to stop the Flink task, you need to use cancel of StreamPark. Do not delete the Deployment of the Flink task directly through the kubernetes cluster. Because Flink&#x27;s shutdown has its own shutdown process, when deleting a pod, the corresponding configuration files in the Configmap will also be deleted. Direct deletion of the pod will result in the remnants of the Configmap. When a task with the same name is restarted, two identical jobs will appear because at startup, the task will load the remaining configuration files and try to restore the closed task.</p>
</li>
<li>
<p><strong>How to implement kubernetes pod domain name access</strong></p>
<p>Domain name configuration only needs to be configured in pod-template according to Kubernetes resources. I can share with you a pod-template.yaml template that I summarized based on the above issues:</p>
</li>
</ul>
<div class="language-yaml codeBlockContainer_APcc theme-code-block"><div class="codeBlockContent_IhPH"><pre tabindex="0" class="prism-code language-yaml codeBlock_tTXe thin-scrollbar" style="color:#9CDCFE;background-color:#1E1E1E"><code class="codeBlockLines_qImF"><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"></span><span class="token key atrule">apiVersion</span><span class="token punctuation" style="color:rgb(212, 212, 212)">:</span><span class="token plain"> v1</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"></span><span class="token key atrule">kind</span><span class="token punctuation" style="color:rgb(212, 212, 212)">:</span><span class="token plain"> Pod</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"></span><span class="token key atrule">metadata</span><span class="token punctuation" style="color:rgb(212, 212, 212)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">  </span><span class="token key atrule">name</span><span class="token punctuation" style="color:rgb(212, 212, 212)">:</span><span class="token plain"> pod</span><span class="token punctuation" style="color:rgb(212, 212, 212)">-</span><span class="token plain">template</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"></span><span class="token key atrule">spec</span><span class="token punctuation" style="color:rgb(212, 212, 212)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">  </span><span class="token key atrule">serviceAccount</span><span class="token punctuation" style="color:rgb(212, 212, 212)">:</span><span class="token plain"> default</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">  </span><span class="token key atrule">containers</span><span class="token punctuation" style="color:rgb(212, 212, 212)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">  </span><span class="token punctuation" style="color:rgb(212, 212, 212)">-</span><span class="token plain"> </span><span class="token key atrule">name</span><span class="token punctuation" style="color:rgb(212, 212, 212)">:</span><span class="token plain"> flink</span><span class="token punctuation" style="color:rgb(212, 212, 212)">-</span><span class="token plain">main</span><span class="token punctuation" style="color:rgb(212, 212, 212)">-</span><span class="token plain">container</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">    </span><span class="token key atrule">image</span><span class="token punctuation" style="color:rgb(212, 212, 212)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">  </span><span class="token key atrule">imagePullSecrets</span><span class="token punctuation" style="color:rgb(212, 212, 212)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">  </span><span class="token punctuation" style="color:rgb(212, 212, 212)">-</span><span class="token plain"> </span><span class="token key atrule">name</span><span class="token punctuation" style="color:rgb(212, 212, 212)">:</span><span class="token plain"> regsecret</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">  </span><span class="token key atrule">hostAliases</span><span class="token punctuation" style="color:rgb(212, 212, 212)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">    </span><span class="token punctuation" style="color:rgb(212, 212, 212)">-</span><span class="token plain"> </span><span class="token key atrule">ip</span><span class="token punctuation" style="color:rgb(212, 212, 212)">:</span><span class="token plain"> </span><span class="token string" style="color:rgb(206, 145, 120)">&quot;192.168.0.1&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">      </span><span class="token key atrule">hostnames</span><span class="token punctuation" style="color:rgb(212, 212, 212)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">      </span><span class="token punctuation" style="color:rgb(212, 212, 212)">-</span><span class="token plain"> </span><span class="token string" style="color:rgb(206, 145, 120)">&quot;node1&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">    </span><span class="token punctuation" style="color:rgb(212, 212, 212)">-</span><span class="token plain"> </span><span class="token key atrule">ip</span><span class="token punctuation" style="color:rgb(212, 212, 212)">:</span><span class="token plain"> </span><span class="token string" style="color:rgb(206, 145, 120)">&quot;192.168.0.2&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">      </span><span class="token key atrule">hostnames</span><span class="token punctuation" style="color:rgb(212, 212, 212)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">      </span><span class="token punctuation" style="color:rgb(212, 212, 212)">-</span><span class="token plain"> </span><span class="token string" style="color:rgb(206, 145, 120)">&quot;node2&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">    </span><span class="token punctuation" style="color:rgb(212, 212, 212)">-</span><span class="token plain"> </span><span class="token key atrule">ip</span><span class="token punctuation" style="color:rgb(212, 212, 212)">:</span><span class="token plain"> </span><span class="token string" style="color:rgb(206, 145, 120)">&quot;192.168.0.3&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">      </span><span class="token key atrule">hostnames</span><span class="token punctuation" style="color:rgb(212, 212, 212)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">      </span><span class="token punctuation" style="color:rgb(212, 212, 212)">-</span><span class="token plain"> </span><span class="token string" style="color:rgb(206, 145, 120)">&quot;node3&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span></code></pre><div class="buttonGroup_inAn"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_N8Av" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_EGLt"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_gJas"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h3 class="anchor anchorWithStickyNavbar_myWT" id="best-practices"><strong>Best Practices</strong><a href="#best-practices" class="hash-link" aria-label="Direct link to best-practices" title="Direct link to best-practices">​</a></h3>
<p>Many of RELX&#x27;s big data components are based on Alibaba Cloud, such as Maxcompute and Alibaba Cloud Redis. At the same time, our Flink SQL jobs need to use some UDFs. At first, we adopted the method of using Flink Base image + maven dependency + upload udf jar, but in practice we encountered some problems such as version conflicts and class conflicts. At the same time, if it is a large-volume job, the development efficiency of this method is relatively low. Finally, we packaged the commonly used Flink connectors, udf and Flink base image at the company level into a company-level base image. New Flink SQL jobs can directly write Flink SQL after using this base image, which greatly improves development efficiency.</p>
<p><strong>Let’s share a simple step to create a basic image：</strong></p>
<p><strong>1. Prepare the required JAR</strong></p>
<p>Place the commonly used Flink Connector Jar and the user Udf Jar in the same folder lib. The following are some commonly used connector packages in Flink 1.13.6</p>
<div class="language-jar codeBlockContainer_APcc theme-code-block"><div class="codeBlockContent_IhPH"><pre tabindex="0" class="prism-code language-jar codeBlock_tTXe thin-scrollbar" style="color:#9CDCFE;background-color:#1E1E1E"><code class="codeBlockLines_qImF"><span class="token-line" style="color:#9CDCFE"><span class="token plain">bigdata-udxf-1.0.0-shaded.jar</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">flink-connector-jdbc_2.11-1.13.6.jar</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">flink-sql-connector-kafka_2.11-1.13.6.jar</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">flink-sql-connector-mysql-cdc-2.0.2.jar</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">hudi-flink-bundle_2.11-0.10.0.jar</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">ververica-connector-odps-1.13-vvr-4.0.7.jar</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">ververica-connector-redis-1.13-vvr-4.0.7.jar</span><br></span></code></pre><div class="buttonGroup_inAn"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_N8Av" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_EGLt"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_gJas"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p><strong>2. Prepare Dockerfile</strong></p>
<p>Create a Dockerfile file and place the Dockerfile file in the same folder as the above folder</p>
<div class="language-shell codeBlockContainer_APcc theme-code-block"><div class="codeBlockContent_IhPH"><pre tabindex="0" class="prism-code language-shell codeBlock_tTXe thin-scrollbar" style="color:#9CDCFE;background-color:#1E1E1E"><code class="codeBlockLines_qImF"><span class="token-line" style="color:#9CDCFE"><span class="token plain">FROM flink:1.13.6-scala_2.11COPY lib $FLINK_HOME/lib/</span><br></span></code></pre><div class="buttonGroup_inAn"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_N8Av" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_EGLt"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_gJas"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p><strong>3. Create a basic image and push it to a private repository</strong></p>
<div class="language-shell codeBlockContainer_APcc theme-code-block"><div class="codeBlockContent_IhPH"><pre tabindex="0" class="prism-code language-shell codeBlock_tTXe thin-scrollbar" style="color:#9CDCFE;background-color:#1E1E1E"><code class="codeBlockLines_qImF"><span class="token-line" style="color:#9CDCFE"><span class="token plain">docker login --username=xxxdocker \</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">build -t udf_flink_1.13.6-scala_2.11:latest \</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">.docker tag udf_flink_1.13.6-scala_2.11:latest \</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">k8s-harbor.xxx.com/streamx/udf_flink_1.13.6-scala_2.11:latestdocker \</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">push k8s-harbor.xxx.com/streamx/udf_flink_1.13.6-scala_2.11:latest</span><br></span></code></pre><div class="buttonGroup_inAn"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_N8Av" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_EGLt"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_gJas"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h2 class="anchor anchorWithStickyNavbar_myWT" id="future-expectations"><strong>Future Expectations</strong><a href="#future-expectations" class="hash-link" aria-label="Direct link to future-expectations" title="Direct link to future-expectations">​</a></h2>
<ul>
<li>
<p><strong>StreamPark supports Flink job metric monitoring</strong></p>
<p>It would be great if StreamPark could connect to Flink Metric data and display Flink’s real-time consumption data at every moment on the StreamPark platform.</p>
</li>
<li>
<p><strong>StreamPark supports Flink job log persistence</strong></p>
<p>For Flink deployed to YARN, if the Flink program hangs, we can go to YARN to view the historical logs. However, for Kubernetes, if the program hangs, the Kubernetes pod will disappear and there will be no way to check the logs. Therefore, users need to use tools on Kubernetes for log persistence. It would be better if StreamPark supports the Kubernetes log persistence interface.</p>
</li>
<li>
<p><strong>Improvement of the problem of too large image</strong></p>
<p>StreamPark&#x27;s current image support for Flink on Kubernetes jobs is to combine the basic image and user code into a Fat image and push it to the Docker repository. The problem with this method is that it takes a long time when the image is too large. It is hoped that the basic image can be restored in the future. There is no need to hit the business code together every time, which can greatly improve development efficiency and save costs.</p>
</li>
</ul></div><footer class="row docusaurus-mt-lg blogPostFooterDetailsFull_Wr5y"><div class="post-footer"><div class="col"><b>Tags:</b><ul class="tags_bUDc padding--none margin-left--sm"><li class="tag_edSN"><a class="tag_mtSO tagRegular_u5wg" href="/blog/tags/stream-park">StreamPark</a></li><li class="tag_edSN"><a class="tag_mtSO tagRegular_u5wg" href="/blog/tags/production-practice">Production Practice</a></li><li class="tag_edSN"><a class="tag_mtSO tagRegular_u5wg" href="/blog/tags/flink-sql">FlinkSQL</a></li><li class="tag_edSN"><a class="tag_mtSO tagRegular_u5wg" href="/blog/tags/kubernetes">Kubernetes</a></li></ul></div><div class="col col-3 text--right"><a href="https://github.com/apache/incubator-streampark-website/edit/dev/blog/0-streampark-flink-on-k8s.md" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_WHnd" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div></div></footer></article></div></div></div><nav class="pagination-nav docusaurus-mt-lg" aria-label="Blog post page navigation"><a class="pagination-nav__link pagination-nav__link--next paginationNavLink_UdUv" href="/blog/flink-development-framework-streampark"><div class="paginationNavContent__3xr"><div class="pagination-nav__sublabel">Older Post</div><div class="paginationNavLabel_YPzM pagination-nav__label">Apache StreamPark™ - Powerful Flink Development Framework</div></div><svg width="24" height="25" viewBox="0 0 24 25" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M14.7249 19.175L13.6749 18.125L18.5499 13.25H2.3999V11.75H18.5499L13.6749 6.87501L14.7249 5.82501L21.4249 12.5L14.7249 19.175Z" fill="currentColor"></path></svg></a></nav></main><div class="col col--2"><div class="tableOfContents_jeP5 thin-scrollbar" style="opacity:0;transform:translateX(100px) translateZ(0)"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#why-choose-native-kubernetes" class="table-of-contents__link toc-highlight"><strong>Why Choose Native Kubernetes</strong></a></li><li><a href="#deploy-flink-on-kubernetes-using-apache-streampark" class="table-of-contents__link toc-highlight"><strong>Deploy Flink on Kubernetes using Apache StreamPark™</strong></a><ul><li><a href="#basic-environment-configuration" class="table-of-contents__link toc-highlight"><strong>Basic environment configuration</strong></a></li><li><a href="#job-development" class="table-of-contents__link toc-highlight"><strong>Job development</strong></a></li><li><a href="#job-online" class="table-of-contents__link toc-highlight"><strong>Job online</strong></a></li><li><a href="#assignment-submission" class="table-of-contents__link toc-highlight"><strong>Assignment submission</strong></a></li><li><a href="#job-management" class="table-of-contents__link toc-highlight"><strong>Job management</strong></a></li></ul></li><li><a href="#apache-streamparks-implementation-in-wuxin-technology" class="table-of-contents__link toc-highlight"><strong>Apache StreamPark™’s implementation in Wuxin Technology</strong></a></li><li><a href="#problems-encountered" class="table-of-contents__link toc-highlight">Problems encountered</a><ul><li><a href="#faqs-are-summarized-below" class="table-of-contents__link toc-highlight"><strong>FAQs are summarized below</strong></a></li><li><a href="#best-practices" class="table-of-contents__link toc-highlight"><strong>Best Practices</strong></a></li></ul></li><li><a href="#future-expectations" class="table-of-contents__link toc-highlight"><strong>Future Expectations</strong></a></li></ul></div></div></div></div></div></div><footer class="footer"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Join Community</div><ul class="footer__items clean-list"><li class="footer__item">
                <div class="subscribe-box btns">
                  <a class="btn btn-primary" href="https://github.com/apache/incubator-streampark"><i class="fa fa-github"></i><span>Github</span></a>
                  <a class="btn btn-primary" href="https://github.com/apache/incubator-streampark/issues"><i class="fa fa-slack"></i><span>Issue Tracking</span></a>
                  <a class="btn btn-primary" href="javascript:void(0)">
                    <i class="fa fa-wechat"></i>
                    <span>Wechat</span>
                    <div class="wechat-dropdown"><img src="/image/join_wechat.png" alt="weChat"></div>
                  </a>
                </div>
              </li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright"><div>
        <div>
          <div style="margin-bottom: 30px;">
            <a href="https://incubator.apache.org/" class="footerLogoLink" one-link-mark="yes">
              <img alt="Apache Incubator logo" class="footer__logo" width="200">
            </a>
          </div>
          <div>
            <p>
            Apache StreamPark is an effort undergoing incubation at The Apache Software Foundation (ASF), sponsored by the Apache Incubator. Incubation is required of all newly accepted projects until a further review indicates that the infrastructure, communications, and decision making process have stabilized in a manner consistent with other successful ASF projects. While incubation status is not necessarily a reflection of the completeness or stability of the code, it does indicate that the project has yet to be fully endorsed by the ASF.
            </p>
          </div>
        </div>

        <div>
          <span>
            Copyright © 2022-2024 The Apache Software Foundation. Apache StreamPark, StreamPark, and its feather logo are trademarks of The Apache Software Foundation.
          </span>
        </div>
      </div></div></div></div></footer></div>
</body>
</html>