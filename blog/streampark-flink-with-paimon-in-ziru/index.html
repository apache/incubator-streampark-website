<!doctype html>
<html lang="en" dir="ltr" class="blog-wrapper blog-post-page plugin-blog plugin-id-default" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.3.2">
<title data-rh="true">Ziroom implements the best practice of one-key data input into the lake based on Apache StreamPark™ + Paimon | Apache StreamPark (incubating)</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://streampark.apache.org/blog/streampark-flink-with-paimon-in-ziru"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" property="og:locale:alternate" content="zh_CN"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docusaurus_tag" content="default"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docsearch:docusaurus_tag" content="default"><meta data-rh="true" property="og:title" content="Ziroom implements the best practice of one-key data input into the lake based on Apache StreamPark™ + Paimon | Apache StreamPark (incubating)"><meta data-rh="true" name="description" content="Introduction：This article mainly introduces the architecture upgrade and evolution of the self-migrating MySQL data to Hive, the original architecture involves many components, complex links, and encounters many challenges, and effectively solves the dilemmas and challenges encountered in data integration after using the combination of StreamPark + Paimon, and shares the specific practical solutions of StreamPark + Paimon in practical applications, as well as the advantages and benefits brought by this rookie combination solution."><meta data-rh="true" property="og:description" content="Introduction：This article mainly introduces the architecture upgrade and evolution of the self-migrating MySQL data to Hive, the original architecture involves many components, complex links, and encounters many challenges, and effectively solves the dilemmas and challenges encountered in data integration after using the combination of StreamPark + Paimon, and shares the specific practical solutions of StreamPark + Paimon in practical applications, as well as the advantages and benefits brought by this rookie combination solution."><meta data-rh="true" property="og:type" content="article"><meta data-rh="true" property="article:published_time" content="2024-10-18T07:44:07.000Z"><meta data-rh="true" property="article:tag" content="StreamPark,Production Practice"><link data-rh="true" rel="icon" href="/image/favicon.ico"><link data-rh="true" rel="canonical" href="https://streampark.apache.org/blog/streampark-flink-with-paimon-in-ziru"><link data-rh="true" rel="alternate" href="https://streampark.apache.org/blog/streampark-flink-with-paimon-in-ziru" hreflang="en"><link data-rh="true" rel="alternate" href="https://streampark.apache.org/zh-CN/blog/streampark-flink-with-paimon-in-ziru" hreflang="zh-CN"><link data-rh="true" rel="alternate" href="https://streampark.apache.org/blog/streampark-flink-with-paimon-in-ziru" hreflang="x-default"><link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="Apache StreamPark (incubating) RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="Apache StreamPark (incubating) Atom Feed"><link rel="stylesheet" href="/assets/css/styles.2815dd1e.css">
<script src="/assets/js/runtime~main.788200c2.js" defer="defer"></script>
<script src="/assets/js/main.237a4499.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return localStorage.getItem("theme")}catch(t){}}();null!==e?t(e):window.matchMedia("(prefers-color-scheme: dark)").matches?t("dark"):window.matchMedia("(prefers-color-scheme: light)").matches?t("light"):t("dark")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_BCtO" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/image/logo.png" alt="StreamPark Logo" class="themedComponent_Cvhi themedComponent--light_uT2j"><img src="/image/logo.png" alt="StreamPark Logo" class="themedComponent_Cvhi themedComponent--dark_ENih"></div><b class="navbar__title text--truncate">StreamPark</b></a></div><div class="navbar__items navbar__items--right"><a class="navbar__item navbar__link" href="/docs/get-started/intro">Docs</a><a class="navbar__item navbar__link" href="/download">Download</a><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link">Community</a><ul class="dropdown__menu"><li><a href="https://www.apache.org/foundation/policies/conduct" target="_blank" rel="noopener noreferrer" class="dropdown__link">Code of conduct</a></li><li><a class="dropdown__link" href="/community/contribution_guide/mailing_lists">Join the mailing lists</a></li><li><a class="dropdown__link" href="/community/contribution_guide/become_committer">Become A Committer</a></li><li><a class="dropdown__link" href="/community/contribution_guide/become_pmc_member">Become A PMC member</a></li><li><a class="dropdown__link" href="/community/contribution_guide/new_committer_process">New Committer Process</a></li><li><a class="dropdown__link" href="/community/contribution_guide/new_pmc_ember_process">New PMC Member Process</a></li><li><a class="dropdown__link" href="/community/submit_guide/document">Documentation Notice</a></li><li><a class="dropdown__link" href="/community/submit_guide/submit_code">Submit Code</a></li><li><a class="dropdown__link" href="/community/submit_guide/code_style_and_quality_guide">Code style and quality guide</a></li><li><a class="dropdown__link" href="/community/submit_guide/documentation_style_guide">Documentation style guide</a></li><li><a class="dropdown__link" href="/community/release/how_to_release_version_2.1.x">How to release version 2.1.x</a></li><li><a class="dropdown__link" href="/community/release/how_to_verify_release">How to Verify Release</a></li></ul></div><a class="navbar__item navbar__link" href="/team">Team</a><a class="navbar__item navbar__link" href="/user">Users</a><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link">ASF</a><ul class="dropdown__menu"><li><a href="https://www.apache.org/" target="_blank" rel="noopener noreferrer" class="dropdown__link">Foundation</a></li><li><a href="https://www.apache.org/licenses/" target="_blank" rel="noopener noreferrer" class="dropdown__link">License</a></li><li><a href="https://www.apache.org/events/current-event" target="_blank" rel="noopener noreferrer" class="dropdown__link">Events</a></li><li><a href="https://www.apache.org/security/" target="_blank" rel="noopener noreferrer" class="dropdown__link">Security</a></li><li><a href="https://www.apache.org/foundation/sponsorship.html" target="_blank" rel="noopener noreferrer" class="dropdown__link">Sponsorship</a></li><li><a href="https://www.apache.org/foundation/policies/privacy.html" target="_blank" rel="noopener noreferrer" class="dropdown__link">Privacy</a></li><li><a href="https://www.apache.org/foundation/thanks.html" target="_blank" rel="noopener noreferrer" class="dropdown__link">Thanks</a></li></ul></div><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/blog">Blog</a><a href="https://github.com/apache/incubator-streampark/issues/507" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">FAQ</a><a href="https://github.com/apache/incubator-streampark" target="_blank" class="githubStars_qnS9"><div class="githubStarsContainer_O7dk"><svg width="16" height="16" viewBox="0 0 16 16" fill="none" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" clip-rule="evenodd" d="M8 1.75C4.27062 1.75 1.25 4.77062 1.25 8.5C1.25 11.4869 3.18219 14.0097 5.86531 14.9041C6.20281 14.9631 6.32937 14.7606 6.32937 14.5834C6.32937 14.4231 6.32094 13.8916 6.32094 13.3263C4.625 13.6384 4.18625 12.9128 4.05125 12.5331C3.97531 12.3391 3.64625 11.74 3.35938 11.5797C3.12312 11.4531 2.78562 11.1409 3.35094 11.1325C3.8825 11.1241 4.26219 11.6219 4.38875 11.8244C4.99625 12.8453 5.96656 12.5584 6.35469 12.3813C6.41375 11.9425 6.59094 11.6472 6.785 11.4784C5.28312 11.3097 3.71375 10.7275 3.71375 8.14563C3.71375 7.41156 3.97531 6.80406 4.40563 6.33156C4.33812 6.16281 4.10187 5.47094 4.47312 4.54281C4.47312 4.54281 5.03844 4.36563 6.32937 5.23469C6.86937 5.08281 7.44313 5.00687 8.01688 5.00687C8.59063 5.00687 9.16438 5.08281 9.70438 5.23469C10.9953 4.35719 11.5606 4.54281 11.5606 4.54281C11.9319 5.47094 11.6956 6.16281 11.6281 6.33156C12.0584 6.80406 12.32 7.40312 12.32 8.14563C12.32 10.7359 10.7422 11.3097 9.24031 11.4784C9.485 11.6894 9.69594 12.0944 9.69594 12.7272C9.69594 13.63 9.6875 14.3556 9.6875 14.5834C9.6875 14.7606 9.81406 14.9716 10.1516 14.9041C12.8178 14.0097 14.75 11.4784 14.75 8.5C14.75 4.77062 11.7294 1.75 8 1.75Z" fill="currentColor"></path></svg><span class="githubText_YlX6">3.9k</span></div></a><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link"><svg viewBox="0 0 24 24" width="20" height="20" aria-hidden="true" class="iconLanguage_DSK9"><path fill="currentColor" d="M12.87 15.07l-2.54-2.51.03-.03c1.74-1.94 2.98-4.17 3.71-6.53H17V4h-7V2H8v2H1v1.99h11.17C11.5 7.92 10.44 9.75 9 11.35 8.07 10.32 7.3 9.19 6.69 8h-2c.73 1.63 1.73 3.17 2.98 4.56l-5.09 5.02L4 19l5-5 3.11 3.11.76-2.04zM18.5 10h-2L12 22h2l1.12-3h4.75L21 22h2l-4.5-12zm-2.62 7l1.62-4.33L19.12 17h-3.24z"></path></svg></a><ul class="dropdown__menu"><li><a href="/blog/streampark-flink-with-paimon-in-ziru" target="_self" rel="noopener noreferrer" class="dropdown__link dropdown__link--active" lang="en">English</a></li><li><a href="/zh-CN/blog/streampark-flink-with-paimon-in-ziru" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="zh-CN">简体中文</a></li></ul></div><a class="colorModeButton_yITp undefined"><svg xmlns="http://www.w3.org/2000/svg" fill="none" width="16" height="16" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" class="w-6 h-6"><path stroke-linecap="round" stroke-linejoin="round" d="M21.752 15.002A9.718 9.718 0 0118 15.75c-5.385 0-9.75-4.365-9.75-9.75 0-1.33.266-2.597.748-3.752A9.753 9.753 0 003 11.25C3 16.635 7.365 21 12.75 21a9.753 9.753 0 009.002-5.998z"></path></svg></a><div class="navbarSearchContainer_dCNk"><div class="navbar__search searchBarContainer_SuYZ"><input placeholder="Search" aria-label="Search" class="navbar__search-input"><div class="loadingRing_HgBb searchBarLoadingRing_om0w"><div></div><div></div><div></div><div></div></div></div></div><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_pmYA"><div class="container-wrapper blog-container"><div class="container margin-vert--lg"><div class="row"><aside class="col col--2 overflow-hidden" style="opacity:0;transform:translateX(-100px) translateZ(0)"><nav class="sidebar_brwN thin-scrollbar" aria-label="Blog recent posts navigation"><div class="backButton_MCHS"><svg xmlns="http://www.w3.org/2000/svg" width="32" height="32" viewBox="0 0 24 24"><path fill="currentColor" d="M8 7v4L2 6l6-5v4h5a8 8 0 1 1 0 16H4v-2h9a6 6 0 0 0 0-12H8Z"></path></svg></div><a class="sidebarItemTitle_r4Q1 margin-bottom--sm" href="/blog">近期文章</a><ul class="sidebarItemList_QwSx clean-list"><li class="sidebarItem_lnhn"><a class="sidebarItemLink_yNGZ" href="/blog/streampark-flink-on-k8s">Apache StreamPark™ Flink on Kubernetes practice</a></li><li class="sidebarItem_lnhn"><a class="sidebarItemLink_yNGZ" href="/blog/flink-development-framework-streampark">Apache StreamPark™ - Powerful Flink Development Framework</a></li><li class="sidebarItem_lnhn"><a aria-current="page" class="sidebarItemLink_yNGZ sidebarItemLinkActive_oSRm" href="/blog/streampark-flink-with-paimon-in-ziru">Ziroom implements the best practice of one-key data input into the lake based on Apache StreamPark™ + Paimon</a></li><li class="sidebarItem_lnhn"><a class="sidebarItemLink_yNGZ" href="/blog/streampark-usercase-tianyancha">Apache StreamPark™ helps Tianyancha real-time platform construction｜Multiple-fold increase in efficiency</a></li><li class="sidebarItem_lnhn"><a class="sidebarItemLink_yNGZ" href="/blog/streampark-usercase-joymaker">Apache StreamPark™ Cloud Native Platform Practice at Joymaker</a></li><li class="sidebarItem_lnhn"><a class="sidebarItemLink_yNGZ" href="/blog/streampark-usercase-chinaunion">China Union&#x27;s Flink Real-Time Computing Platform Ops Practice</a></li><li class="sidebarItem_lnhn"><a class="sidebarItemLink_yNGZ" href="/blog/streampark-usercase-bondex-with-paimon">Based on Apache Paimon + Apache StreamPark™&#x27;s Streaming Data Warehouse Practice by Bondex</a></li><li class="sidebarItem_lnhn"><a class="sidebarItemLink_yNGZ" href="/blog/streampark-usercase-shunwang">Apache StreamPark™ in the Large-Scale Production Practice at Shunwang Technology</a></li><li class="sidebarItem_lnhn"><a class="sidebarItemLink_yNGZ" href="/blog/streampark-usercase-dustess">Apache StreamPark™&#x27;s Best Practices at Dustess, Simplifying Complexity for the Ultimate Experience</a></li><li class="sidebarItem_lnhn"><a class="sidebarItemLink_yNGZ" href="/blog/streampark-usercase-joyme">Apache StreamPark™&#x27;s Production Practice in Joyme</a></li><li class="sidebarItem_lnhn"><a class="sidebarItemLink_yNGZ" href="/blog/streampark-usercase-haibo">An All-in-One Computation Tool in Haibo Tech&#x27;s Production Practice and facilitation in Smart City Construction</a></li><li class="sidebarItem_lnhn"><a class="sidebarItemLink_yNGZ" href="/blog/streampark-usercase-ziru">Ziroom&#x27;s Real-Time Computing Platform Practice Based on Apache StreamPark™</a></li><li class="sidebarItem_lnhn"><a class="sidebarItemLink_yNGZ" href="/blog/streampark-usercase-changan">Changan Automobile’s upgrade practice from self-developed platform to Apache StreamPark™</a></li></ul></nav></aside><main class="col col--8 overflow-hidden" itemscope="" itemtype="http://schema.org/Blog"><div><div class="row" style="margin:0"><div class="col col--12 article__details article-bg"><article itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><meta itemprop="description" content="Introduction：This article mainly introduces the architecture upgrade and evolution of the self-migrating MySQL data to Hive, the original architecture involves many components, complex links, and encounters many challenges, and effectively solves the dilemmas and challenges encountered in data integration after using the combination of StreamPark + Paimon, and shares the specific practical solutions of StreamPark + Paimon in practical applications, as well as the advantages and benefits brought by this rookie combination solution."><header><h1 class="margin-bottom--md blogPostTitle_thoQ text--center post--titleLink" itemprop="headline">Ziroom implements the best practice of one-key data input into the lake based on Apache StreamPark™ + Paimon</h1><div class="margin-vert--md"><time datetime="2024-10-18T07:44:07.000Z" itemprop="datePublished"></time> · <!-- -->14 min read</div></header><div id="__blog-post-container" class="markdown" itemprop="articleBody"><p><img decoding="async" loading="lazy" src="/assets/images/new_cover-5991f0d6d5ee86bc8716862748caf484.png" width="1080" height="460" class="img__KcZ"></p>
<p><strong>Introduction</strong>：This article mainly introduces the architecture upgrade and evolution of the self-migrating MySQL data to Hive, the original architecture involves many components, complex links, and encounters many challenges, and effectively solves the dilemmas and challenges encountered in data integration after using the combination of StreamPark + Paimon, and shares the specific practical solutions of StreamPark + Paimon in practical applications, as well as the advantages and benefits brought by this rookie combination solution.</p>
<p>StreamPark: <a href="https://github.com/apache/streampark" target="_blank" rel="noopener noreferrer">https://github.com/apache/streampark</a></p>
<p>Paimon: <a href="https://github.com/apache/paimon" target="_blank" rel="noopener noreferrer">https://github.com/apache/paimon</a></p>
<p>Welcome to follow, star, fork, and participate in contributions</p>
<p>Contributor｜Beijing Ziru Information Technology Co., Ltd.</p>
<p>Authors of the article｜Liu Tao, Liang Yansheng, Wei Linzi</p>
<p>Article compilation｜Yang Linwei</p>
<p>Content proofreading｜Pan Yuepeng</p>
<h2 class="anchor anchorWithStickyNavbar_myWT" id="1data-integration-business-background"><strong>1.Data integration business background</strong><a href="#1data-integration-business-background" class="hash-link" aria-label="Direct link to 1data-integration-business-background" title="Direct link to 1data-integration-business-background">​</a></h2>
<p>The data integration scenario of Ziroom&#x27;s rental business mainly comes from the need to synchronize MySQL tables of each business line to Hive tables. This requirement includes more than 4,400 MySQL business tables synchronized every day and more than 8,000 Hive ETL processing tasks. The amount of new data generated every day is 50T, and these numbers are still growing. According to the freshness requirements of the data, it is divided into two types: low freshness (T+1 day) and high freshness (T+10 minutes). More than 4,000 low freshness data tables are synchronously scheduled every day, and more than 400 high freshness data tables are synchronously scheduled every day. Freshness data table to ensure the timeliness and accuracy of data.</p>
<p>Ziroom&#x27;s data integration solutions can be mainly divided into two types according to business usage scenarios:</p>
<ul>
<li>
<p><strong>Low freshness</strong>: The timeliness requirement of low freshness for data is <strong>T+1day</strong>, and the Hive jdbc handler is used to pull the full amount of MySQL data to Hive at 00:00 every day. The basic The process is shown in the figure below:</p>
<p><img decoding="async" loading="lazy" src="data:image/png;base64,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" width="361" height="41" class="img__KcZ"></p>
</li>
<li>
<p><strong>High freshness</strong>: In this scenario, the required data effectiveness is <strong>T+10minutes</strong>. We reused the snapshot pull method of the low freshness scenario to obtain the full amount of data and initialized it to MySQL. Synchronously use Canal to parse the logs and collect them into Kafka, then use Flink to read the data in kafka and write it to HDFS, and finally use Airflow for scheduling to merge the incremental data into Hive. The basic logic is as follows:</p>
<p><img decoding="async" loading="lazy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAnIAAAApCAYAAACx+MSIAAAO00lEQVR4Xu2dSagdRRuG7zaLQBbBlRBw4cKFC0EQRBDBhREjIoqIoiCCivKrwRHn6XdGUHGMiwgqEsUJRaKCijiLs+I8xilRYzSTQ/15ylMnfd97zr2p091fdd//e6C5p6u7z/n6faurvq6uc+7U1HSWLl68ePWCBQs2bHsdfJm+oAv6bHu9dKpbuG+zLO5bPxf3rZ+L+9atpcN+1MG9HMWiRYtWLlmyZP2KFSvCmjVrgjMTdEEfdEIv1bAE7tvcuG/9xH3rJ+5bt+iiH3VwL8d4ScGyZcvW60HOeNBrhpDGuG/5uG/9xH3rJ+5bt+iCH3VwL7ejXi4lu9OdnLlBN/Sr1DNL3LcJcd/6ifvWT9y3blHYjzq4l8LQS563MlTn5INug+fV5rhvk+O+9RP3rZ+4b92ipB91cC9nMvSSyXP/b8+ZmwLdBpMtzXHfJsd96yfuWz9x37pFST/q4F7OpOqlbnMyQD+pb1ZoKE4G6KeCGqGhOBmgnwpqhIbiZIB+KqgRGooTivpRBz0NJ2z3UsudDJKIBdBQnAzQTwU1QkNxMkA/FdQIDcXJAP1UUCM0FCcU9aMOehpO8ESuEZKIBdBQnAzQTwU1QkNxMkA/FdQIDcXJAP1UUCM0FCcU9aMOehpO8ESuEZKIBdBQnAzQTwU1QkNxMkA/FdQIDcXJAP1UUCM0FCcU9aMOehpO8ESuEZKIBdBQnAzQTwU1QkNxMkA/FdQIDcXJAP1UUCM0FCcU9aMOehpO8ESuEZKIBdBQnAzQTwU1QkNxMkA/FdQIDcXJAP1UUCM0FCcU9aMOehpO8ESuEZKIBdBQnAzQTwU1QkNxMkA/FdQIDcXJAP1UUCM0FCcU9aMOehpO8ESuEZKIBdBQnAzQTwU1QkNxMkA/FdQIDcXJAP1UUCM0FCcU9aMOehpO8ESuEZKIBdBQnAzQTwU1QkPpFJs3bw5//PGHFncG9FNBjdBQzMCPLnuyI6CfCmqEhmLOL7/8Ev78808tLgq6qFA9QE+jUf7555/O+bQjoEvr4pTg+eefDzvttJMWt0ISsQAaSq+5/PLLw1FHHaXFrYF+KqgRGkornH322eGMM87Q4lm58847w8KFC8Ntt9020fEWoJ8KaoSGYsINN9wQzxlPDj/88HD11VfHpI6yjz/+WHefRpc8JF7R0woNpVHm8uKYY46J29955514bb344ou6SxGISXTqA3oajbJ69eqw8847a3HkwgsvjF52EXRpXZwSPPfcc/GisSCJ2ALLty0LtbCChtJrLrvssnDkkUdqcWugnwraEJ3w7ayzzgrLly/X4lnZd999w5VXXhlfT3K8BeingjZEJ3xT9tlnn3DdddfF1yRyV111Vfj777/Ds88+O+coXZc8RD8VtCGK+jabF1u2bInn/corr8R1T+TmpKiXsyVyn332Wfjggw+0uBOgS+vibNq0Key5557xznL33XcPe++9d3jyySfDEUccEUfN+Ltx48Zw7bXXhpNOOml43FtvvRWP+/XXX8ODDz4YOxkuhKOPPjqsX78+7vPuu+/G99tll13CxRdfHPbff//w0UcfzZdEbtO2Zeu25b9Toyu3htIKDDVzN4JXu+22W7jxxhuH26644opYtuuuu4bTTjst/PXXX0O/Gd1hG97ccccdw2Meeuih2DnxfozAffPNN7F8HiVynfCt2olzLe21117xuoNRvlFGbPj1wAMPZB9vBTGqoA3RCd+qqCcpkePxN9fQ119/HV5++eVYTvtHJ7THHnsMk4XZPLSG81BBG8LMt1H1vurFG2+8EQ499NA4akpfd8ghh8Tzpj1kxK6ayD388MPxvSg7+OCD4/Hfffdd3PeLL76I+5x++unh+OOPj6/5HPwjoWgC4lKhOoCZl6MgkaNfOuecc4bX0quvvhq30Z/RR3Gd4X2CHATPeHyOf1yLvAe5CPXBAnRpXZw09Eylvf/++2NCxjoVlE6d1/fdd19sYHj922+/xeMQjCTtp59+iuUci9BcIOkOlffkYuHYAw44IO735ptvzpdE7j9T/1bsLduWzVMzK7eG0gq33npr1PKxxx4Ld999dzxfGpO33347Vlg85I6U1yTcyW8aO3w57rjj4joJHneo7HfTTTfFC4TKfuqpp8bPmUeJXCd8S534hx9+GP275JJLYvk437gB4no699xzw7fffpt9vBXoV9GySTrhWxX1JCVy6RpjO20ir2kHeU2bSWIB4zwsATFWtGwSE9/G1fuqF/Q7vKbt4+b1hRdeiOv0b+yXErn33nsvltP2vfTSS+HAAw+MvjFHiwTi3nvvja/Zn/1oN3kv1pu6aeJ9Kxp1BRMvx1G9lh599NGw3377xXwFLrjggjiIhOfsk0Zguaa43vCLhI4+jfdhWgP7keC1DZ/Tujipoj/11FNxfeXKlXE9JWwHHXRQuPTSS8PWrVtjRU2dAg3YzTffHL788su4PyNBGzZsiOs0TNzBUP7jjz/G/T/99NO4Po8SOVg39e/7s2jl1lBagcpJUp245ZZbYkP2/vvvx8aFhoU7SPa76KKLhn4/88wzcX98Zp1h6XXr1sWRBcC3k08+OTZgMI8SOSjuG5041xYdzimnnDIsH+cb0CBxfU56vAUDTduiuG9K1ZPZEjnaRnjiiSeGbd84D0sw0LQtWvdtXL0flcil+XKMorFO3wQpkWPEh9G1BG0j+9G3nXDCCdEr3g/fWBh1xXcSiaYYaNVFWvdyHOla+v333+P6448/PryWUiKX/GYbkKcwWvfaa6/F8s8//zyWk9jh3apVq+J6mwy0alccnQzKyBonnzjssMOGHcGJJ54Yjj322PDJJ5/EY7gLBR67JnO5e6GSMzrEnU+CuQpsL5TIWS4MPa/itQXoiGfKV199FSs2cbAPS7Vhq07+ZR1faNjOO++84Z0md5+FEznLxdQ3OvH02XTmiXG+gSZyucdbMELXthdT35QdSeToMBJpFAjGeViCEbq2vTTq27h6r4lctd8Zl8jhY/XxHFOL2I9kgBtdnjrRv/F5TLBnWhJPnChrihF6dXlp1Mtx6LXElybTZ6ZEDshRSLjxnO0MUNBHjog7Dny0zeCz2hUnVfT0bH+2RO7pp5+OlZ3ELQ1prl27NiYFXBSM8tCw0eHfc88900RnhIfPKZTItcXaqe2VwvTuJIHeNCQJGhoei/JYgLvKNJ8j+ah+A+v4koalabC4s2XEtXAi1xbFfaMTZ+4Nj4T4zEceeSSWj/MNNJHLPd6CgaZtUdw3ZUcSueoEbU3kRnlYgoGmbdG6b+Pq/SSJHE+gmEuXSP6wP/0dr3n/22+/Pdx1110xCacszSdugoFWXaR1L8eh19K4RI5Rb3IPrkUew0KaGvb999/HOsFCP5meGLbJQKt2xdGOfbZEjon1abSGSgyvv/56LEsXA4IyKsfjVfZj7hajcTyrZn0eJXLMF9g4NbMyJzSUVrj++uvjpE+GjJnYyefSaOEBj0YheXT++efP8BtYxxfmNuI9Pv/www/xfdMjhnmUyHXCt+pEd+7+aaDwZpxvoIlc7vEWoF9FyybphG9K3URulIclIKaKlk1i4tu4ej9JIpeOJ1EA5lNVR0x5bMtx/GRJGvWp9plNwHtWNOoKJl6OQ6+lcYlcmgbGtvToNM3lv+aaa+KcRvIS1ukz24bPaV0c7dhHJXLVOVjMD2B/7kyq+1BGFszjVBorYEIpZWxLlZ+EAQPmQSJX9Bs8iZRw8XloyqNR4A6EdRa+VUcjxz5M3uWvJnJ8a45H5eybjksTQvmNrHn0O3Kd8I1OPP2G2M8//xz15tvH43zjuiFpSI9vJjneAj5L9GyKTvimVD3RRI4nFdr5aCI3ysMSEJPo2RQmvo2r96m9wwvtd9LPj6S2kG0kcsyf4tca2EZZmgeXwCPKGaBIc63OPPPM4fYm4LOnqdQNTLwch15LmshVf0cu+V+9MeJLLZSlhW85WzD4vHbFyYXGZ9SkToa0uTtRyI7TcDfnYtWhJJKILVD0N3UUvlxCw1SFO04aKRobYBh5rm9VsS+NXvoFbX5ehjki1qCfCtoQnfJtFJP4VqXu8XVAPxW0ITrvW59BPxW0Icx8a7rec2PLk6US/00AXVSoDmDmZVvwRQlGUrlxsgJdOiMOX9Pl2zzEM+nvr3DsPErk5kJDcTJAPxXUCA3FyQD9VFAjNBQnA/RTQY3QUJxQ1I866Gk4oWOJHD/yy1w55g9MCj/EyGRDS5KIBdBQnAzQTwU1QkNxMkA/FdQIDcXJAP1UUCM0FCcU9aMOehpO6Fgi11eSiAXQUJwM0E8FNUJDcTJAPxXUCA3FyQD9VFAjNBQnFPWjDnoaTvBErhGSiAXQUJwM0E8FNUJDcTJAPxXUCA3FyQD9VFAjNBQnFPWjDnoaTvBErhGSiAXQUJwM0E8FNUJDcTJAPxXUCA3FyQD9VFAjNBQnFPWjDnoaTvBErhGSiAXQUJwM0E8FNUJDcTJAPxXUCA3FyQD9VFAjNBQnFPWjDnoaTvBErhGSiAXQUJwM0E8FNUJDcTJAPxXUCA3FyQD9VFAjNBQnFPWjDnoaTvBErhGSiAXQUJwM0E8FNUJDcTJAPxXUCA3FyQD9VFAjNBQnFPWjDnoaTvBErhGSiAXQUJwM0E8FNUJDcTJAPxXUCA3FyQD9VFAjNBQnFPWjDnoaTvBErhGSiAXQUJwM0E8FNUJDcTJAPxXUCA3FyQD9VFAjNBQnFPWjDnoaThh4uWDBgg1r1qzRbc4OgG7op7XNAvdtcty3fuK+9RP3rVuU9KMO7uVMhl4uXrx49YoVK3S7swOgG/pphbPAfZsc962fuG/9xH3rFiX9qIN7OZOql0uXLFmyXndw5gbd0E/qmxXu24S4b/3Efesn7lu3KOxHHdxLYZqXixYtWrls2TIXKAP0Qrfp9cwW9y0f962fuG/9xH3rFl3wow7u5XZGekkB2R1Ddf4cejTogj7oNEPAQrhvc+O+9RP3rZ+4b92ii37Uwb2c28ulPG8dTIRM32zxZbCgy+B5dNeGpd23WRb3rZ+L+9bPxX3r1tJhP+rgXlb4H4X4OwILlsZhAAAAAElFTkSuQmCC" width="626" height="41" class="img__KcZ"></p>
</li>
</ul>
<p>However, there are many challenges and pressures in the current architecture. Firstly, the operation and maintenance costs are high, and secondly, the computing pressure, storage pressure and network pressure are all very high. In addition, although the resources are underutilized during the system running time from 0:00 to 1:00, other time periods face resource shortages. In this regard, Ziroom decided to update the data integration architecture to improve the efficiency and stability of the system.</p>
<h2 class="anchor anchorWithStickyNavbar_myWT" id="2challenges-encountered"><strong>2.Challenges encountered</strong><a href="#2challenges-encountered" class="hash-link" aria-label="Direct link to 2challenges-encountered" title="Direct link to 2challenges-encountered">​</a></h2>
<p>In the above two scenarios, we encountered the following challenges during the data integration process:</p>
<ul>
<li>
<p><strong>Network bandwidth overload problem</strong>: Since the pull task reached <strong>4000+</strong>, too many mirror full data pulls put great pressure on the database network bandwidth.</p>
</li>
<li>
<p><strong>Inefficient resource utilization</strong>: After the upstream data is synchronized from MySQL to the ODS layer table, the downstream processing table can be started. As a result, the CPU and memory resources of the Hadoop cluster are not available between 0:00 and 1:00. be fully utilized.</p>
</li>
<li>
<p><strong>High maintenance costs</strong>: When the database table structure changes, the Airflow script needs to be modified simultaneously. Otherwise, incomplete fields will appear, causing online data anomalies.</p>
</li>
<li>
<p><strong>Difficulty in troubleshooting</strong>: The data link is long. When data anomalies occur, troubleshooting costs are high. The problem may occur in any link in Canal, Kafka, Flink, and Airflow scheduling, resulting in a long recovery time. .</p>
</li>
<li>
<p><strong>Flink jobs are difficult to manage in a unified manner</strong>: Flink itself does not provide good deployment and development capabilities. As the number of Flink tasks increases, the time cost of management and maintenance also increases.</p>
</li>
</ul>
<p>In order to solve the above problems, after a series of investigations, we decided to adopt the &quot;<strong>StreamPark+Paimon</strong>&quot; strategy. So what are the reasons for choosing them? We can first look at their characteristics.</p>
<h3 class="anchor anchorWithStickyNavbar_myWT" id="paimons-core-features"><strong>Paimon’s core features</strong><a href="#paimons-core-features" class="hash-link" aria-label="Direct link to paimons-core-features" title="Direct link to paimons-core-features">​</a></h3>
<p><strong>After research and comprehensive evaluation of several data lake frameworks such as Apache Hudi/Iceberg/Paimon, we decided to use Apache Paimon</strong>. Apache Paimon is a streaming data lake storage technology that can provide users with high throughput and low cost. Delayed data ingestion, streaming subscription and real-time query capabilities support the use of Flink and Spark to build a real-time Lakehouse architecture, support batch/stream data processing operations, innovatively combine the Lake format with the LSM structure, and provide real-time streaming updates. Introducing into the Lake architecture has the following advantages:</p>
<ul>
<li>
<p><strong>Unified batch and stream processing</strong>: Paimon supports batch writing, batch reading and streaming operations, providing flexible data processing methods.</p>
</li>
<li>
<p><strong>Data Lake Features</strong>: As a data lake storage system, Paimon has the characteristics of low cost, high reliability and scalable metadata.</p>
</li>
<li>
<p><strong>Rich merging engines</strong>: Paimon provides a variety of merging engines, and you can choose to retain the latest data, perform partial updates, or perform aggregation operations according to your needs.</p>
</li>
<li>
<p><strong>Automatically generate change logs</strong>: Paimon supports a variety of Changelog producers and can automatically generate correct and complete change logs to simplify streaming task analysis.</p>
</li>
<li>
<p><strong>Rich table types</strong>: Paimon supports primary key tables and append-only tables, as well as multiple table types such as internal tables, external tables, partitioned tables, and temporary tables.</p>
</li>
<li>
<p><strong>Support table structure change synchronization</strong>: When the data source table structure changes, Paimon can automatically identify and synchronize these changes.</p>
</li>
</ul>
<p>Paimon can be used in conjunction with Apache Spark. Our scenario is Paimon combined with Flink. In this way, &quot;<strong>How to manage 4000+ Flink data synchronization jobs</strong>&quot; will be a new problem we face. After a comprehensive investigation of related projects and a comprehensive evaluation of various dimensions, <strong>we decided to use StreamPark</strong>. So why did we choose StremaPark?</p>
<h3 class="anchor anchorWithStickyNavbar_myWT" id="streamparks-core-features"><strong>StreamPark’s core features</strong><a href="#streamparks-core-features" class="hash-link" aria-label="Direct link to streamparks-core-features" title="Direct link to streamparks-core-features">​</a></h3>
<p>Apache StreamPark is a stream processing development and management framework that provides a set of fast APIs for developing Flink/Spark jobs. In addition, it also provides a one-stop stream processing job development and management platform, covering the entire life cycle from stream processing job development to launch. Cycles are supported. StreamPark mainly includes the following core features:</p>
<ul>
<li>
<p><strong>Stream processing application development framework</strong>: Based on StreamPark, developers can easily build and manage stream processing applications, and better utilize Apache Flink® to write stream processing applications.</p>
</li>
<li>
<p><strong>Perfect management capabilities</strong>: StreamPark provides a one-stop streaming task development and management platform that supports the full life cycle of Flink/Spark from application development to debugging, deployment, operation and maintenance, allowing Flink/Spark jobs to Make it simple.</p>
</li>
<li>
<p><strong>High degree of completion</strong>: StreamPark supports multiple versions of Flink, allowing flexible switching of one platform. It also supports Flink’s deployment mode, effectively solving the problem of too cumbersome Flink on YARN/K8s deployment. Through automated processes, It simplifies the process of building, testing and deploying tasks and improves development efficiency.</p>
</li>
<li>
<p><strong>Rich management API</strong>: StreamPark provides APIs for job operations, including job creation, copy, build, deployment, stop and start based on checkpoint/savepoint, etc., making it easy to implement external system calls to Apache Flink® tasks. .</p>
</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_myWT" id="3-streampark--paimon-practice"><strong>3. StreamPark + Paimon Practice</strong><a href="#3-streampark--paimon-practice" class="hash-link" aria-label="Direct link to 3-streampark--paimon-practice" title="Direct link to 3-streampark--paimon-practice">​</a></h2>
<p>Next, we will continue to share how Ziroom optimized the architecture based on <strong>StreamPark + Paimon</strong>. Let’s first look at the comparison before and after the architecture upgrade.</p>
<h3 class="anchor anchorWithStickyNavbar_myWT" id="31-before-architecture-upgrade"><strong>3.1 Before architecture upgrade</strong><a href="#31-before-architecture-upgrade" class="hash-link" aria-label="Direct link to 31-before-architecture-upgrade" title="Direct link to 31-before-architecture-upgrade">​</a></h3>
<p>The system interaction process of the data integration module before the transformation is as follows:</p>
<p><img decoding="async" loading="lazy" src="/assets/images/system_interaction_process-0fa72272598ce1fbf180e4f859cf59dc.png" width="1080" height="291" class="img__KcZ"></p>
<p><strong>Step1</strong> (User initiates access application): First, the user selects a table on the data access platform, and then clicks the Apply for Access button:</p>
<p><img decoding="async" loading="lazy" src="/assets/images/data_access_platform-a2d62b477382c15128b76c60e9c6be53.png" width="1080" height="245" class="img__KcZ"></p>
<p><strong>Step2</strong> (Initiate OA system approval process): When the OA system receives the access application, it will initiate workflow approval. If the approval fails, the application will be rejected. Only if the approval is passed will the next step be continued.</p>
<p><strong>Step3</strong> (The data access platform processes the approval event): The data access platform calls the Canal interface to deploy the Canal task and transfer the Binlog data in the table to Kafka:</p>
<p><img decoding="async" loading="lazy" src="/assets/images/canal_job-fbfcee343ac2473e1b22d199da463ad4.png" width="1041" height="760" class="img__KcZ"></p>
<p><strong>Step4</strong> (Flink task deployment): Manually use the Flink Session Submit UI to deploy the Flink template job, which is responsible for parsing the Binlog change data in Kafka, writing the data to HDFS, and mapping it into a Hive external incremental table:</p>
<p><img decoding="async" loading="lazy" src="/assets/images/flink_job-2769695ec6b0a9446b8d5f4828976b7d.png" width="946" height="331" class="img__KcZ"></p>
<p><strong>Step5</strong> (Airflow scheduling initialization table): Create Hive mapping incremental table and full table and use Airflow scheduling to complete the first initialization:</p>
<p><img decoding="async" loading="lazy" src="/assets/images/first_initialization-f270b827e85b0ff840bf3db25686349c.png" width="1080" height="884" class="img__KcZ"></p>
<p><strong>Step6</strong> (Merge data into Hive full table): Configure scheduling to merge data from Hive external incremental tables into Hive full table through Hive Merge method</p>
<p><img decoding="async" loading="lazy" src="/assets/images/data_merging-b8ac385c5de9f96c13163aa65e382496.png" width="1075" height="972" class="img__KcZ"></p>
<h3 class="anchor anchorWithStickyNavbar_myWT" id="32-after-the-architecture-upgrade"><strong>3.2 After the architecture upgrade</strong><a href="#32-after-the-architecture-upgrade" class="hash-link" aria-label="Direct link to 32-after-the-architecture-upgrade" title="Direct link to 32-after-the-architecture-upgrade">​</a></h3>
<p>The modified system interaction flow chart is as follows:</p>
<p><img decoding="async" loading="lazy" src="/assets/images/after_the_transformation-8b3717c58b603d12e8e87c8267068672.png" width="1080" height="291" class="img__KcZ"></p>
<p>Comparing the interaction flow charts before and after the transformation, it can be seen that the process of the first two steps (table access application and approval) is the same, but the only difference is the event monitoring and processing method after the approval is passed.</p>
<ul>
<li>
<p><strong>Before transformation</strong>: Call the Canal interface to deploy Canal tasks (old logic);</p>
</li>
<li>
<p><strong>After transformation</strong>: Call StreamPark’s API interface to complete Flink Paimon’s task deployment.</p>
</li>
</ul>
<p>Next, let’s look at using Paimon to complete data integration.</p>
<h3 class="anchor anchorWithStickyNavbar_myWT" id="33-paimon-implements-one-key-hive-input"><strong>3.3 Paimon implements one-key Hive input</strong><a href="#33-paimon-implements-one-key-hive-input" class="hash-link" aria-label="Direct link to 33-paimon-implements-one-key-hive-input" title="Direct link to 33-paimon-implements-one-key-hive-input">​</a></h3>
<p>After Apache Paimon version 0.5, CDC data integration capabilities are provided. Data from MySQL, Kafka, Mongo, etc. can be easily ingested into Paimon in real time through the officially provided paimon-action jar. We are using paimon- flink-action uses <strong>mysql-sync-database (whole database synchronization)</strong> and selects the tables to be synchronized through the &quot;<strong>—including_tables</strong>&quot; parameter. This synchronization mode effectively saves a lot of resource overhead. Compared with starting a Flink task for each table, it avoids a lot of waste of resources.</p>
<p>paimon-flink-action provides the function of automatically creating Paimon tables and supports Schema Evolution (for example, when the MySQL table fields change, the Paimon table will change accordingly without additional operations). The entire operation process is efficient and smooth, which solves the unnecessary operation and maintenance costs caused by adding fields to the original architecture. The specific use of paimon-action is as follows. For more information, please refer to the Paimon official website documentation.</p>
<div class="language-shell codeBlockContainer_APcc theme-code-block"><div class="codeBlockContent_IhPH"><pre tabindex="0" class="prism-code language-shell codeBlock_tTXe thin-scrollbar" style="color:#9CDCFE;background-color:#1E1E1E"><code class="codeBlockLines_qImF"><span class="token-line" style="color:#9CDCFE"><span class="token plain">&lt;FLINK_HOME&gt;/bin/flink run \</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">/path/to/paimon-flink-action-0.8-SNAPSHOT.jar \</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">mysql_sync_table</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">--warehouse &lt;warehouse-path&gt; \</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">--database &lt;database-name&gt; \</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">--table &lt;table-name&gt; \</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">[--partition_keys &lt;partition_keys&gt;] \</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">[--primary_keys &lt;primary-keys&gt;] \</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">[--type_mapping &lt;option1,option2...&gt;] \</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">[--computed_column &lt;&#x27;column-name=expr-name(args[, ...])&#x27;&gt; [--computed_column ...]] \</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">[--metadata_column &lt;metadata-column&gt;] \</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">[--mysql_conf &lt;mysql-cdc-source-conf&gt; [--mysql_conf &lt;mysql-cdc-source-conf&gt; ...]] \</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">[--catalog_conf &lt;paimon-catalog-conf&gt; [--catalog_conf &lt;paimon-catalog-conf&gt; ...]] \</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">[--table_conf &lt;paimon-table-sink-conf&gt; [--table_conf &lt;paimon-table-sink-conf&gt; ...]]</span><br></span></code></pre><div class="buttonGroup_inAn"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_N8Av" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_EGLt"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_gJas"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>The introduction of Paimon shortens the entire data access link, eliminates dependence on Canal, Kafka, and Airflow, allowing MySQL to directly connect to Hive at minute speeds, and the overall environment is clean and efficient. In addition, Paimon is fully compatible with Hive-side data reading, with extremely low conversion costs and good compatibility with the use of original architecture scripts. Paimon also supports the Tag function, which can be regarded as a lightweight snapshot, significantly reducing storage costs.</p>
<h3 class="anchor anchorWithStickyNavbar_myWT" id="34-streampark--paimon-implementation-practice"><strong>3.4 StreamPark + Paimon implementation practice</strong><a href="#34-streampark--paimon-implementation-practice" class="hash-link" aria-label="Direct link to 34-streampark--paimon-implementation-practice" title="Direct link to 34-streampark--paimon-implementation-practice">​</a></h3>
<p>StreamPark has better support for JAR type jobs in version 2.1.2, making Paimon type data integration jobs simpler. The following example demonstrates how to use StreamPark to quickly develop Paimon data migration type jobs:</p>
<p>//Video link (StreamPark deployment Paimon data integration job example)</p>
<p>It is true that StreamPark has specifically supported Paimon data integration jobs after version 2.1.2, but this method of manually creating jobs and entering job parameters still does not meet our actual needs. We need more flexible job creation, which can be done through Quickly complete job creation and startup by calling API... After our research, we found that StreamPark has completely opened various operation APIs for jobs, such as job copy, creation, deployment, start, stop, etc. In this way, we Through scheduled scheduling, it can be easily combined with StreamPark to quickly complete the development and operation of jobs. The specific methods are as follows:</p>
<p><strong>Step1</strong>：First, the api copy template interface will be called and parameters will be passed in. The relevant screenshots are as follows:</p>
<p><img decoding="async" loading="lazy" src="/assets/images/api_copy-ceff34954a24abe2b3e04bc6d10d4f26.png" width="737" height="484" class="img__KcZ"></p>
<p>In this way, the job will be created quickly, and the parameters will be passed in through the copy interface. The specific parameters are as follows:</p>
<p><img decoding="async" loading="lazy" src="/assets/images/parameter-d7feafe0cd25f249bec4b2115d64ec00.png" width="780" height="959" class="img__KcZ"></p>
<p><strong>Step2</strong>：Next, call the API to build the job image:</p>
<p><img decoding="async" loading="lazy" src="/assets/images/job_mirroring-8cbc7decc438aa15ca8166ba9a0bd7c1.png" width="870" height="522" class="img__KcZ"></p>
<p><strong>Step3</strong>：Continue to call the API to start the job:</p>
<p><img decoding="async" loading="lazy" src="/assets/images/start_the_job-036fdf864d022cf8de2282af72d4b3ca.png" width="855" height="641" class="img__KcZ"></p>
<p>Finally, after the task is successfully started, you can see the relevant status information of the task and the resource overview of the overall task on the StreamPark platform:</p>
<p><img decoding="async" loading="lazy" src="/assets/images/resource_overview-b7f0b5ccafd202f82c515c64e48cd377.png" width="1080" height="618" class="img__KcZ"></p>
<p>You can also click Application Name to schedule the Flink web UI:</p>
<p><img decoding="async" loading="lazy" src="/assets/images/flink_ui-1a5557a19b30e92802eab1b75cc4a574.png" width="1080" height="702" class="img__KcZ"></p>
<p>Finally, you can directly query the Paimon table on the Hive side to obtain the required data. The Paimon table is a data synchronization target table with low latency processed by Flink. The screenshot of Hive query Paimon table in Hue is as follows</p>
<p><img decoding="async" loading="lazy" src="/assets/images/hive_query_paimon-9203a5f6debb35ce41f9f51be06e1446.png" width="2000" height="1346" class="img__KcZ"></p>
<p>Through the above steps, the business party can easily initiate an access application. After the approval process, a Flink job is created and deployed through StreamPark. The data is entered into the Paimon table through the Flink job, allowing users to easily perform query operations on the Hive side. The entire process is simplified. User operation improves the efficiency and maintainability of data access.</p>
<h2 class="anchor anchorWithStickyNavbar_myWT" id="4-benefits"><strong>4. Benefits</strong><a href="#4-benefits" class="hash-link" aria-label="Direct link to 4-benefits" title="Direct link to 4-benefits">​</a></h2>
<p>By using Paimon and StreamPark, Ziroom has brought the following advantages and benefits:</p>
<ul>
<li>
<p><strong>Network resources and database pressure optimization</strong>: By obtaining data snapshots directly from the Paimon table, the problem of network resource constraints and excessive database pressure caused by pulling data from the business database in the early morning is solved, while data storage costs are reduced.</p>
</li>
<li>
<p><strong>Job management interface improves efficiency</strong>: Using StreamPark&#x27;s job management interface easily solves the problem of manual deployment of Flink tasks, eliminates the situation where tasks are not deployed in time due to personnel dependence on time, improves efficiency, and reduces communication costs. Improved the management efficiency of Flink jobs.</p>
</li>
<li>
<p><strong>Reduce development and maintenance costs</strong>: It solves the problems of high maintenance costs and slow problem location caused by long links in the previous solution. It also solves the problem of field inconsistency caused by field changes and realizes the unified flow and batch of data access. , reducing development and maintenance costs.</p>
</li>
<li>
<p><strong>Reduced usage costs of data integration scheduling resources and computing resources</strong>: No longer relies on external scheduling systems for incremental data merging, reducing the use of scheduling resources. It no longer relies on Hive resources for merge operations, reducing the cost of merging incremental data on Hive computing resources.</p>
</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_myWT" id="5-conclusion--expectations"><strong>5. Conclusion &amp; Expectations</strong><a href="#5-conclusion--expectations" class="hash-link" aria-label="Direct link to 5-conclusion--expectations" title="Direct link to 5-conclusion--expectations">​</a></h2>
<p>We would like to sincerely thank the <strong>Apache StreamPark</strong> community for their generous help as we use the StreamPark API. Their professional service spirit and user-oriented attitude allow us to use this powerful framework more efficiently and smoothly. As an excellent framework, StreamPark not only has excellent functions, but also supports a series of operations such as task copying, creation, deployment, start, stop and status monitoring, and has significantly played a significant role in simplifying the management and maintenance of Flink tasks. its value.</p>
<p>At the same time, we would like to express our gratitude to the <strong>Apache Paimon</strong> community for their patience and professional guidance during the testing phase of Ziroom MySQL into Paimon. This is an important support for us to successfully complete the test. As a project with great potential, Paimon has demonstrated extraordinary qualities both in terms of feature implementation and team collaboration.</p>
<p>Finally, we are full of expectations and confidence in the future of Apache StreamPark and Apache Paimon, and firmly believe that they will become excellent projects for Apache in the future. Their excellent functions and harmonious community cooperation model have laid a solid foundation for their maturity in the open source community. We expect that the StreamPark and Paimon communities will continue to maintain a professional attitude and good teamwork spirit, continue to advance the development of the project, and become a model for new Apache projects in recent years, so as to have a greater impact on the broader developer community.</p></div><footer class="row docusaurus-mt-lg blogPostFooterDetailsFull_Wr5y"><div class="post-footer"><div class="col"><b>Tags:</b><ul class="tags_bUDc padding--none margin-left--sm"><li class="tag_edSN"><a class="tag_mtSO tagRegular_u5wg" href="/blog/tags/stream-park">StreamPark</a></li><li class="tag_edSN"><a class="tag_mtSO tagRegular_u5wg" href="/blog/tags/production-practice">Production Practice</a></li></ul></div><div class="col col-3 text--right"><a href="https://github.com/apache/incubator-streampark-website/edit/dev/blog/10-streampark-flink-with-paimon-in-ziru.md" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_WHnd" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div></div></footer></article></div></div></div><nav class="pagination-nav docusaurus-mt-lg" aria-label="Blog post page navigation"><a class="pagination-nav__link pagination-nav__link--prev paginationNavLink_UdUv" href="/blog/flink-development-framework-streampark"><svg width="24" height="25" viewBox="0 0 24 25" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M9.2751 19.175L10.3251 18.125L5.4501 13.25H21.6001V11.75H5.4501L10.3251 6.87501L9.2751 5.82501L2.5751 12.5L9.2751 19.175Z" fill="currentColor"></path></svg><div class="paginationNavContent__3xr"><div class="pagination-nav__sublabel">Newer Post</div><div class="paginationNavLabel_YPzM pagination-nav__label">Apache StreamPark™ - Powerful Flink Development Framework</div></div></a><a class="pagination-nav__link pagination-nav__link--next paginationNavLink_UdUv" href="/blog/streampark-usercase-tianyancha"><div class="paginationNavContent__3xr"><div class="pagination-nav__sublabel">Older Post</div><div class="paginationNavLabel_YPzM pagination-nav__label">Apache StreamPark™ helps Tianyancha real-time platform construction｜Multiple-fold increase in efficiency</div></div><svg width="24" height="25" viewBox="0 0 24 25" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M14.7249 19.175L13.6749 18.125L18.5499 13.25H2.3999V11.75H18.5499L13.6749 6.87501L14.7249 5.82501L21.4249 12.5L14.7249 19.175Z" fill="currentColor"></path></svg></a></nav></main><div class="col col--2"><div class="tableOfContents_jeP5 thin-scrollbar" style="opacity:0;transform:translateX(100px) translateZ(0)"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#1data-integration-business-background" class="table-of-contents__link toc-highlight"><strong>1.Data integration business background</strong></a></li><li><a href="#2challenges-encountered" class="table-of-contents__link toc-highlight"><strong>2.Challenges encountered</strong></a><ul><li><a href="#paimons-core-features" class="table-of-contents__link toc-highlight"><strong>Paimon’s core features</strong></a></li><li><a href="#streamparks-core-features" class="table-of-contents__link toc-highlight"><strong>StreamPark’s core features</strong></a></li></ul></li><li><a href="#3-streampark--paimon-practice" class="table-of-contents__link toc-highlight"><strong>3. StreamPark + Paimon Practice</strong></a><ul><li><a href="#31-before-architecture-upgrade" class="table-of-contents__link toc-highlight"><strong>3.1 Before architecture upgrade</strong></a></li><li><a href="#32-after-the-architecture-upgrade" class="table-of-contents__link toc-highlight"><strong>3.2 After the architecture upgrade</strong></a></li><li><a href="#33-paimon-implements-one-key-hive-input" class="table-of-contents__link toc-highlight"><strong>3.3 Paimon implements one-key Hive input</strong></a></li><li><a href="#34-streampark--paimon-implementation-practice" class="table-of-contents__link toc-highlight"><strong>3.4 StreamPark + Paimon implementation practice</strong></a></li></ul></li><li><a href="#4-benefits" class="table-of-contents__link toc-highlight"><strong>4. Benefits</strong></a></li><li><a href="#5-conclusion--expectations" class="table-of-contents__link toc-highlight"><strong>5. Conclusion &amp; Expectations</strong></a></li></ul></div></div></div></div></div></div><footer class="footer"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Join Community</div><ul class="footer__items clean-list"><li class="footer__item">
                <div class="subscribe-box btns">
                  <a class="btn btn-primary" href="https://github.com/apache/incubator-streampark"><i class="fa fa-github"></i><span>Github</span></a>
                  <a class="btn btn-primary" href="https://github.com/apache/incubator-streampark/issues"><i class="fa fa-slack"></i><span>Issue Tracking</span></a>
                  <a class="btn btn-primary" href="javascript:void(0)">
                    <i class="fa fa-wechat"></i>
                    <span>Wechat</span>
                    <div class="wechat-dropdown"><img src="/image/join_wechat.png" alt="weChat"></div>
                  </a>
                </div>
              </li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright"><div>
        <div>
          <div style="margin-bottom: 30px;">
            <a href="https://incubator.apache.org/" class="footerLogoLink" one-link-mark="yes">
              <img alt="Apache Incubator logo" class="footer__logo" width="200">
            </a>
          </div>
          <div>
            <p>
            Apache StreamPark is an effort undergoing incubation at The Apache Software Foundation (ASF), sponsored by the Apache Incubator. Incubation is required of all newly accepted projects until a further review indicates that the infrastructure, communications, and decision making process have stabilized in a manner consistent with other successful ASF projects. While incubation status is not necessarily a reflection of the completeness or stability of the code, it does indicate that the project has yet to be fully endorsed by the ASF.
            </p>
          </div>
        </div>

        <div>
          <span>
            Copyright © 2022-2024 The Apache Software Foundation. Apache StreamPark, StreamPark, and its feather logo are trademarks of The Apache Software Foundation.
          </span>
        </div>
      </div></div></div></div></footer></div>
</body>
</html>