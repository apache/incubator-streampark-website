<!doctype html>
<html lang="en" dir="ltr" class="blog-wrapper blog-post-page plugin-blog plugin-id-default" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.3.2">
<title data-rh="true">Apache StreamPark™&#x27;s Best Practices at Dustess, Simplifying Complexity for the Ultimate Experience | Apache StreamPark (incubating)</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://streampark.apache.org/blog/streampark-usercase-dustess"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" property="og:locale:alternate" content="zh_CN"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docusaurus_tag" content="default"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docsearch:docusaurus_tag" content="default"><meta data-rh="true" property="og:title" content="Apache StreamPark™&#x27;s Best Practices at Dustess, Simplifying Complexity for the Ultimate Experience | Apache StreamPark (incubating)"><meta data-rh="true" name="description" content="Abstract"><meta data-rh="true" property="og:description" content="Abstract"><meta data-rh="true" property="og:type" content="article"><meta data-rh="true" property="article:published_time" content="2024-10-18T07:44:07.000Z"><meta data-rh="true" property="article:tag" content="StreamPark,Production Practice,FlinkSQL"><link data-rh="true" rel="icon" href="/image/favicon.ico"><link data-rh="true" rel="canonical" href="https://streampark.apache.org/blog/streampark-usercase-dustess"><link data-rh="true" rel="alternate" href="https://streampark.apache.org/blog/streampark-usercase-dustess" hreflang="en"><link data-rh="true" rel="alternate" href="https://streampark.apache.org/zh-CN/blog/streampark-usercase-dustess" hreflang="zh-CN"><link data-rh="true" rel="alternate" href="https://streampark.apache.org/blog/streampark-usercase-dustess" hreflang="x-default"><link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="Apache StreamPark (incubating) RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="Apache StreamPark (incubating) Atom Feed"><link rel="stylesheet" href="/assets/css/styles.2815dd1e.css">
<script src="/assets/js/runtime~main.788200c2.js" defer="defer"></script>
<script src="/assets/js/main.237a4499.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return localStorage.getItem("theme")}catch(t){}}();null!==e?t(e):window.matchMedia("(prefers-color-scheme: dark)").matches?t("dark"):window.matchMedia("(prefers-color-scheme: light)").matches?t("light"):t("dark")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_BCtO" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/image/logo.png" alt="StreamPark Logo" class="themedComponent_Cvhi themedComponent--light_uT2j"><img src="/image/logo.png" alt="StreamPark Logo" class="themedComponent_Cvhi themedComponent--dark_ENih"></div><b class="navbar__title text--truncate">StreamPark</b></a></div><div class="navbar__items navbar__items--right"><a class="navbar__item navbar__link" href="/docs/get-started/intro">Docs</a><a class="navbar__item navbar__link" href="/download">Download</a><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link">Community</a><ul class="dropdown__menu"><li><a href="https://www.apache.org/foundation/policies/conduct" target="_blank" rel="noopener noreferrer" class="dropdown__link">Code of conduct</a></li><li><a class="dropdown__link" href="/community/contribution_guide/mailing_lists">Join the mailing lists</a></li><li><a class="dropdown__link" href="/community/contribution_guide/become_committer">Become A Committer</a></li><li><a class="dropdown__link" href="/community/contribution_guide/become_pmc_member">Become A PMC member</a></li><li><a class="dropdown__link" href="/community/contribution_guide/new_committer_process">New Committer Process</a></li><li><a class="dropdown__link" href="/community/contribution_guide/new_pmc_ember_process">New PMC Member Process</a></li><li><a class="dropdown__link" href="/community/submit_guide/document">Documentation Notice</a></li><li><a class="dropdown__link" href="/community/submit_guide/submit_code">Submit Code</a></li><li><a class="dropdown__link" href="/community/submit_guide/code_style_and_quality_guide">Code style and quality guide</a></li><li><a class="dropdown__link" href="/community/submit_guide/documentation_style_guide">Documentation style guide</a></li><li><a class="dropdown__link" href="/community/release/how_to_release_version_2.1.x">How to release version 2.1.x</a></li><li><a class="dropdown__link" href="/community/release/how_to_verify_release">How to Verify Release</a></li></ul></div><a class="navbar__item navbar__link" href="/team">Team</a><a class="navbar__item navbar__link" href="/user">Users</a><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link">ASF</a><ul class="dropdown__menu"><li><a href="https://www.apache.org/" target="_blank" rel="noopener noreferrer" class="dropdown__link">Foundation</a></li><li><a href="https://www.apache.org/licenses/" target="_blank" rel="noopener noreferrer" class="dropdown__link">License</a></li><li><a href="https://www.apache.org/events/current-event" target="_blank" rel="noopener noreferrer" class="dropdown__link">Events</a></li><li><a href="https://www.apache.org/security/" target="_blank" rel="noopener noreferrer" class="dropdown__link">Security</a></li><li><a href="https://www.apache.org/foundation/sponsorship.html" target="_blank" rel="noopener noreferrer" class="dropdown__link">Sponsorship</a></li><li><a href="https://www.apache.org/foundation/policies/privacy.html" target="_blank" rel="noopener noreferrer" class="dropdown__link">Privacy</a></li><li><a href="https://www.apache.org/foundation/thanks.html" target="_blank" rel="noopener noreferrer" class="dropdown__link">Thanks</a></li></ul></div><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/blog">Blog</a><a href="https://github.com/apache/incubator-streampark/issues/507" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">FAQ</a><a href="https://github.com/apache/incubator-streampark" target="_blank" class="githubStars_qnS9"><div class="githubStarsContainer_O7dk"><svg width="16" height="16" viewBox="0 0 16 16" fill="none" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" clip-rule="evenodd" d="M8 1.75C4.27062 1.75 1.25 4.77062 1.25 8.5C1.25 11.4869 3.18219 14.0097 5.86531 14.9041C6.20281 14.9631 6.32937 14.7606 6.32937 14.5834C6.32937 14.4231 6.32094 13.8916 6.32094 13.3263C4.625 13.6384 4.18625 12.9128 4.05125 12.5331C3.97531 12.3391 3.64625 11.74 3.35938 11.5797C3.12312 11.4531 2.78562 11.1409 3.35094 11.1325C3.8825 11.1241 4.26219 11.6219 4.38875 11.8244C4.99625 12.8453 5.96656 12.5584 6.35469 12.3813C6.41375 11.9425 6.59094 11.6472 6.785 11.4784C5.28312 11.3097 3.71375 10.7275 3.71375 8.14563C3.71375 7.41156 3.97531 6.80406 4.40563 6.33156C4.33812 6.16281 4.10187 5.47094 4.47312 4.54281C4.47312 4.54281 5.03844 4.36563 6.32937 5.23469C6.86937 5.08281 7.44313 5.00687 8.01688 5.00687C8.59063 5.00687 9.16438 5.08281 9.70438 5.23469C10.9953 4.35719 11.5606 4.54281 11.5606 4.54281C11.9319 5.47094 11.6956 6.16281 11.6281 6.33156C12.0584 6.80406 12.32 7.40312 12.32 8.14563C12.32 10.7359 10.7422 11.3097 9.24031 11.4784C9.485 11.6894 9.69594 12.0944 9.69594 12.7272C9.69594 13.63 9.6875 14.3556 9.6875 14.5834C9.6875 14.7606 9.81406 14.9716 10.1516 14.9041C12.8178 14.0097 14.75 11.4784 14.75 8.5C14.75 4.77062 11.7294 1.75 8 1.75Z" fill="currentColor"></path></svg><span class="githubText_YlX6">3.9k</span></div></a><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link"><svg viewBox="0 0 24 24" width="20" height="20" aria-hidden="true" class="iconLanguage_DSK9"><path fill="currentColor" d="M12.87 15.07l-2.54-2.51.03-.03c1.74-1.94 2.98-4.17 3.71-6.53H17V4h-7V2H8v2H1v1.99h11.17C11.5 7.92 10.44 9.75 9 11.35 8.07 10.32 7.3 9.19 6.69 8h-2c.73 1.63 1.73 3.17 2.98 4.56l-5.09 5.02L4 19l5-5 3.11 3.11.76-2.04zM18.5 10h-2L12 22h2l1.12-3h4.75L21 22h2l-4.5-12zm-2.62 7l1.62-4.33L19.12 17h-3.24z"></path></svg></a><ul class="dropdown__menu"><li><a href="/blog/streampark-usercase-dustess" target="_self" rel="noopener noreferrer" class="dropdown__link dropdown__link--active" lang="en">English</a></li><li><a href="/zh-CN/blog/streampark-usercase-dustess" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="zh-CN">简体中文</a></li></ul></div><a class="colorModeButton_yITp undefined"><svg xmlns="http://www.w3.org/2000/svg" fill="none" width="16" height="16" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" class="w-6 h-6"><path stroke-linecap="round" stroke-linejoin="round" d="M21.752 15.002A9.718 9.718 0 0118 15.75c-5.385 0-9.75-4.365-9.75-9.75 0-1.33.266-2.597.748-3.752A9.753 9.753 0 003 11.25C3 16.635 7.365 21 12.75 21a9.753 9.753 0 009.002-5.998z"></path></svg></a><div class="navbarSearchContainer_dCNk"><div class="navbar__search searchBarContainer_SuYZ"><input placeholder="Search" aria-label="Search" class="navbar__search-input"><div class="loadingRing_HgBb searchBarLoadingRing_om0w"><div></div><div></div><div></div><div></div></div></div></div><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_pmYA"><div class="container-wrapper blog-container"><div class="container margin-vert--lg"><div class="row"><aside class="col col--2 overflow-hidden" style="opacity:0;transform:translateX(-100px) translateZ(0)"><nav class="sidebar_brwN thin-scrollbar" aria-label="Blog recent posts navigation"><div class="backButton_MCHS"><svg xmlns="http://www.w3.org/2000/svg" width="32" height="32" viewBox="0 0 24 24"><path fill="currentColor" d="M8 7v4L2 6l6-5v4h5a8 8 0 1 1 0 16H4v-2h9a6 6 0 0 0 0-12H8Z"></path></svg></div><a class="sidebarItemTitle_r4Q1 margin-bottom--sm" href="/blog">近期文章</a><ul class="sidebarItemList_QwSx clean-list"><li class="sidebarItem_lnhn"><a class="sidebarItemLink_yNGZ" href="/blog/streampark-flink-on-k8s">Apache StreamPark™ Flink on Kubernetes practice</a></li><li class="sidebarItem_lnhn"><a class="sidebarItemLink_yNGZ" href="/blog/flink-development-framework-streampark">Apache StreamPark™ - Powerful Flink Development Framework</a></li><li class="sidebarItem_lnhn"><a class="sidebarItemLink_yNGZ" href="/blog/streampark-flink-with-paimon-in-ziru">Ziroom implements the best practice of one-key data input into the lake based on Apache StreamPark™ + Paimon</a></li><li class="sidebarItem_lnhn"><a class="sidebarItemLink_yNGZ" href="/blog/streampark-usercase-tianyancha">Apache StreamPark™ helps Tianyancha real-time platform construction｜Multiple-fold increase in efficiency</a></li><li class="sidebarItem_lnhn"><a class="sidebarItemLink_yNGZ" href="/blog/streampark-usercase-joymaker">Apache StreamPark™ Cloud Native Platform Practice at Joymaker</a></li><li class="sidebarItem_lnhn"><a class="sidebarItemLink_yNGZ" href="/blog/streampark-usercase-chinaunion">China Union&#x27;s Flink Real-Time Computing Platform Ops Practice</a></li><li class="sidebarItem_lnhn"><a class="sidebarItemLink_yNGZ" href="/blog/streampark-usercase-bondex-with-paimon">Based on Apache Paimon + Apache StreamPark™&#x27;s Streaming Data Warehouse Practice by Bondex</a></li><li class="sidebarItem_lnhn"><a class="sidebarItemLink_yNGZ" href="/blog/streampark-usercase-shunwang">Apache StreamPark™ in the Large-Scale Production Practice at Shunwang Technology</a></li><li class="sidebarItem_lnhn"><a aria-current="page" class="sidebarItemLink_yNGZ sidebarItemLinkActive_oSRm" href="/blog/streampark-usercase-dustess">Apache StreamPark™&#x27;s Best Practices at Dustess, Simplifying Complexity for the Ultimate Experience</a></li><li class="sidebarItem_lnhn"><a class="sidebarItemLink_yNGZ" href="/blog/streampark-usercase-joyme">Apache StreamPark™&#x27;s Production Practice in Joyme</a></li><li class="sidebarItem_lnhn"><a class="sidebarItemLink_yNGZ" href="/blog/streampark-usercase-haibo">An All-in-One Computation Tool in Haibo Tech&#x27;s Production Practice and facilitation in Smart City Construction</a></li><li class="sidebarItem_lnhn"><a class="sidebarItemLink_yNGZ" href="/blog/streampark-usercase-ziru">Ziroom&#x27;s Real-Time Computing Platform Practice Based on Apache StreamPark™</a></li><li class="sidebarItem_lnhn"><a class="sidebarItemLink_yNGZ" href="/blog/streampark-usercase-changan">Changan Automobile’s upgrade practice from self-developed platform to Apache StreamPark™</a></li></ul></nav></aside><main class="col col--8 overflow-hidden" itemscope="" itemtype="http://schema.org/Blog"><div><div class="row" style="margin:0"><div class="col col--12 article__details article-bg"><article itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><meta itemprop="description" content="Abstract"><header><h1 class="margin-bottom--md blogPostTitle_thoQ text--center post--titleLink" itemprop="headline">Apache StreamPark™&#x27;s Best Practices at Dustess, Simplifying Complexity for the Ultimate Experience</h1><div class="margin-vert--md"><time datetime="2024-10-18T07:44:07.000Z" itemprop="datePublished"></time> · <!-- -->15 min read</div></header><div id="__blog-post-container" class="markdown" itemprop="articleBody"><p><strong>Abstract:</strong> This article originates from the production practices of StreamPark at Dustess Information, written by the senior data development engineer, Gump. The main content includes:</p>
<ol>
<li>Technology selection</li>
<li>Practical implementation</li>
<li>Business support &amp; capability opening</li>
<li>Future planning</li>
<li>Closing remarks</li>
</ol>
<p>Dustess Information is a one-stop private domain operation management solution provider based on the WeChat Work ecosystem. It is committed to becoming the leading expert in private domain operation and management across all industries, helping enterprises build a new model of private domain operation management in the digital age, and promoting high-quality development for businesses.</p>
<p>Currently, Dustess has established 13 city centers nationwide, covering five major regions: North China, Central China, East China, South China, and Southwest China, providing digital marketing services to over 10,000 enterprises across more than 30 industries.</p>
<h2 class="anchor anchorWithStickyNavbar_myWT" id="01-technology-selection"><strong>01 Technology Selection</strong><a href="#01-technology-selection" class="hash-link" aria-label="Direct link to 01-technology-selection" title="Direct link to 01-technology-selection">​</a></h2>
<p>Dustess Information entered a rapid development phase in 2021. With the increase in service industries and corporate clients, the demand for real-time solutions became more pressing, necessitating the immediate implementation of a real-time computing platform.</p>
<p>As the company is in a phase of rapid growth, with urgent and rapidly changing needs, the team&#x27;s technology selection followed these principles:</p>
<ul>
<li><strong>Speed:</strong> Due to urgent business needs, we required a quick implementation of the planned technology selection into production.</li>
<li><strong>Stability:</strong> On the basis of speed, the chosen technology must provide stable service for the business.</li>
<li><strong>Innovation:</strong> On the basis of the above, the selected technology should also be as modern as possible.</li>
<li><strong>Comprehensiveness:</strong> The selected technology should meet the company&#x27;s rapidly developing and changing business needs, be in line with the team&#x27;s long-term development goals, and support quick and efficient secondary development.</li>
</ul>
<p>Firstly, in terms of the computing engine: We chose Flink for the following reasons:</p>
<ul>
<li>Team members have an in-depth understanding of Flink and are well-versed in its source code.</li>
<li>Flink supports both batch and stream processing. Although the company&#x27;s current batch processing architecture is based on Hive, Spark, etc., using Flink for stream computing facilitates the subsequent construction of unified batch and stream processing and lake-house architecture.</li>
<li>The domestic ecosystem of Flink has become increasingly mature, and Flink is starting to break boundaries towards the development of stream-based data warehousing.</li>
</ul>
<p>At the platform level, we comprehensively compared StreamPark, Apache Zeppelin, and flink-streaming-platform-web, also thoroughly read their source code and conducted an analysis of their advantages and disadvantages. We won’t elaborate on the latter two projects in this article, but those interested can search for them on GitHub. We ultimately chose StreamPark for the following reasons:</p>
<h3 class="anchor anchorWithStickyNavbar_myWT" id="high-completion"><strong>High Completion</strong><a href="#high-completion" class="hash-link" aria-label="Direct link to high-completion" title="Direct link to high-completion">​</a></h3>
<h4 class="anchor anchorWithStickyNavbar_myWT" id="1-supports-multiple-flink-versions"><strong>1. Supports Multiple Flink Versions</strong><a href="#1-supports-multiple-flink-versions" class="hash-link" aria-label="Direct link to 1-supports-multiple-flink-versions" title="Direct link to 1-supports-multiple-flink-versions">​</a></h4>
<p>//Video link (Flink Multi-Version Support Demo)</p>
<p>When creating a task, you can <strong>freely choose the Flink version</strong>. The Flink binary package will be automatically uploaded to HDFS (if using Yarn for submission), and only one copy of a version&#x27;s binary package will be saved on HDFS. When the task is initiated, the Flink binary package in HDFS will be automatically loaded according to the context, which is very elegant. This can meet the needs for coexistence of multiple versions and for testing new versions of Flink during upgrades.</p>
<p><img decoding="async" loading="lazy" src="/assets/images/flink_home-0a6f4f2014cc87b074ef259088af2b98.png" width="1080" height="223" class="img__KcZ"></p>
<h4 class="anchor anchorWithStickyNavbar_myWT" id="2-supports-multiple-deployment-modes"><strong>2. Supports Multiple Deployment Modes</strong><a href="#2-supports-multiple-deployment-modes" class="hash-link" aria-label="Direct link to 2-supports-multiple-deployment-modes" title="Direct link to 2-supports-multiple-deployment-modes">​</a></h4>
<p>StreamPark supports <strong>all the mainstream submission modes</strong> for Flink, such as standalone, yarn-session, yarn application, yarn-perjob, kubernetes-session, kubernetes-application. Moreover, StreamPark does not simply piece together Flink run commands to submit tasks. Instead, it introduces the Flink Client source package and directly calls the Flink Client API for task submission. The advantages of this approach include modular code, readability, ease of extension, stability, and the ability to quickly adapt to upgrades of the Flink version.</p>
<p><img decoding="async" loading="lazy" src="/assets/images/execution_mode-1182aeb8efe9572ec98c2a2b95293dc1.png" width="1080" height="324" class="img__KcZ"></p>
<p>Flink SQL can greatly improve development efficiency and the popularity of Flink. StreamPark’s support for <strong>Flink SQL is very comprehensive</strong>, with an excellent SQL editor, dependency management, multi-version task management, etc. The StreamPark official website states that it will introduce metadata management integration for Flink SQL in the future. Stay tuned.</p>
<p><img decoding="async" loading="lazy" src="/assets/images/flink_sql-13f6952f92585140c5fc640b490918b0.png" width="1080" height="779" class="img__KcZ"></p>
<p><img decoding="async" loading="lazy" src="/assets/images/flink_sql_version-a02b0f0eac9c5d6c0281b7471e438b78.png" width="1080" height="736" class="img__KcZ"></p>
<h4 class="anchor anchorWithStickyNavbar_myWT" id="4-online-building-of-java-tasks"><strong>4. Online Building of JAVA Tasks</strong><a href="#4-online-building-of-java-tasks" class="hash-link" aria-label="Direct link to 4-online-building-of-java-tasks" title="Direct link to 4-online-building-of-java-tasks">​</a></h4>
<p>//Video link (JAVA Task Building Demo)</p>
<p>Although Flink SQL is now powerful enough, using JVM languages like Java and Scala to develop Flink tasks can be more flexible, more customizable, and better for tuning and improving resource utilization. The biggest problem with submitting tasks via Jar packages, compared to SQL, is the management of the Jar uploads. Without excellent tooling products, this can significantly reduce development efficiency and increase maintenance costs.</p>
<p>Besides supporting Jar uploads, StreamPark also provides an <strong>online update build</strong> feature, which elegantly solves the above problems:</p>
<ol>
<li>
<p>Create Project: Fill in the GitHub/Gitlab (supports enterprise private servers) address and username/password, and StreamPark can Pull and Build the project.</p>
</li>
<li>
<p>When creating a StreamPark Custom-Code task, refer to the Project, specify the main class, and optionally automate Pull, Build, and bind the generated Jar when starting the task, which is very elegant!</p>
</li>
</ol>
<p>At the same time, the StreamPark community is also perfecting the entire task compilation and launch process. The future StreamPark will be even more refined and professional on this foundation.</p>
<p><img decoding="async" loading="lazy" src="/assets/images/system_list-6e9c13318d5aa2cfa4cdc11ac42c5844.png" width="1080" height="362" class="img__KcZ"></p>
<h4 class="anchor anchorWithStickyNavbar_myWT" id="5-comprehensive-task-parameter-configuration"><strong>5. Comprehensive Task Parameter Configuration</strong><a href="#5-comprehensive-task-parameter-configuration" class="hash-link" aria-label="Direct link to 5-comprehensive-task-parameter-configuration" title="Direct link to 5-comprehensive-task-parameter-configuration">​</a></h4>
<p>For data development using Flink, the parameters submitted with Flink run are almost impossible to maintain. StreamPark has also <strong>elegantly solved</strong> this kind of problem, mainly because, as mentioned above, StreamPark directly calls the Flink Client API and has connected the entire process through the StreamPark product frontend.</p>
<p><img decoding="async" loading="lazy" src="/assets/images/parameter_configuration-94fb5d7ee0c9c04ed6d79ddb1cd3c1c7.png" width="1080" height="1001" class="img__KcZ"></p>
<p>As you can see, StreamPark&#x27;s task parameter settings cover all the mainstream parameters, and every parameter has been thoughtfully provided with an introduction and an optimal recommendation based on best practices. This is also very beneficial for newcomers to Flink, helping them to avoid common pitfalls!</p>
<h4 class="anchor anchorWithStickyNavbar_myWT" id="6-excellent-configuration-file-design"><strong>6. Excellent Configuration File Design</strong><a href="#6-excellent-configuration-file-design" class="hash-link" aria-label="Direct link to 6-excellent-configuration-file-design" title="Direct link to 6-excellent-configuration-file-design">​</a></h4>
<p>In addition to the native parameters for Flink tasks, which are covered by the task parameters above, StreamPark also provides a powerful <strong>Yaml configuration file</strong> mode and <strong>programming model</strong>.</p>
<p><img decoding="async" loading="lazy" src="/assets/images/extended_parameters-75c3f87809d0675c2fc82bc8d2ec096e.jpg" width="1080" height="2245" class="img__KcZ"></p>
<ol>
<li>
<p>For Flink SQL tasks, you can configure the parameters that StreamPark has already built-in, such as <strong>CheckPoint, retry mechanism, State Backend, table planner, mode</strong>, etc., directly using the task&#x27;s Yaml configuration file.</p>
</li>
<li>
<p>For Jar tasks, StreamPark offers a generic programming model that encapsulates the native Flink API. Combined with the wrapper package provided by StreamPark, it can very elegantly retrieve custom parameters from the configuration file. For more details, see the documentation:</p>
</li>
</ol>
<p>Programming model:</p>
<div class="codeBlockContainer_APcc theme-code-block"><div class="codeBlockContent_IhPH"><pre tabindex="0" class="prism-code language-text codeBlock_tTXe thin-scrollbar" style="color:#9CDCFE;background-color:#1E1E1E"><code class="codeBlockLines_qImF"><span class="token-line" style="color:#9CDCFE"><span class="token plain">https://streampark.apache.org/docs/development/dev-model</span><br></span></code></pre><div class="buttonGroup_inAn"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_N8Av" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_EGLt"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_gJas"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Built-in Configuration File Parameters:</p>
<div class="codeBlockContainer_APcc theme-code-block"><div class="codeBlockContent_IhPH"><pre tabindex="0" class="prism-code language-text codeBlock_tTXe thin-scrollbar" style="color:#9CDCFE;background-color:#1E1E1E"><code class="codeBlockLines_qImF"><span class="token-line" style="color:#9CDCFE"><span class="token plain">https://streampark.apache.org/docs/development/config</span><br></span></code></pre><div class="buttonGroup_inAn"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_N8Av" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_EGLt"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_gJas"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>In addition:</p>
<p>StreamPark also <strong>supports Apache Flink® native tasks</strong>. The parameter configuration can be statically maintained within the Java task internal code, covering a wide range of scenarios, such as seamless migration of existing Flink tasks, etc.</p>
<h4 class="anchor anchorWithStickyNavbar_myWT" id="7-checkpoint-management"><strong>7. Checkpoint Management</strong><a href="#7-checkpoint-management" class="hash-link" aria-label="Direct link to 7-checkpoint-management" title="Direct link to 7-checkpoint-management">​</a></h4>
<p>Regarding Flink&#x27;s Checkpoint (Savepoint) mechanism, the greatest difficulty is maintenance. StreamPark has also elegantly solved this problem:</p>
<ul>
<li>StreamPark will <strong>automatically maintain</strong> the task Checkpoint directory and versions in the system for easy retrieval.</li>
<li>When users need to update and restart an application, they can choose whether to save a Savepoint.</li>
<li>When restarting a task, it is possible to choose to recover from a specified version of Checkpoint/Savepoint.</li>
</ul>
<p>As shown below, developers can very intuitively and conveniently upgrade or deal with exceptional tasks, which is very powerful.</p>
<p><img decoding="async" loading="lazy" src="/assets/images/checkpoint-e9edd22da076247770a0b40595626fb7.png" width="1080" height="483" class="img__KcZ"></p>
<p><img decoding="async" loading="lazy" src="/assets/images/recover-f1de53fdbe66c50b465d58d0a66050de.jpg" width="1053" height="391" class="img__KcZ"></p>
<h4 class="anchor anchorWithStickyNavbar_myWT" id="8-comprehensive-alerting-features"><strong>8. Comprehensive Alerting Features</strong><a href="#8-comprehensive-alerting-features" class="hash-link" aria-label="Direct link to 8-comprehensive-alerting-features" title="Direct link to 8-comprehensive-alerting-features">​</a></h4>
<p>For streaming computations, which are 7*24H resident tasks, monitoring and alerting are very important. StreamPark also has a <strong>comprehensive solution</strong> for these issues:</p>
<ul>
<li>It comes with an email-based alerting method, which has zero development cost and can be used once configured.</li>
<li>Thanks to the excellent modularity of the StreamPark source code, it&#x27;s possible to enhance the code at the Task Track point and introduce the company&#x27;s internal SDK for telephone, group, and other alerting methods, all with a very low development cost.</li>
</ul>
<p><img decoding="async" loading="lazy" src="/assets/images/alarm_email-fd4c9ba1995ec69b7557bd1378dce737.png" width="1009" height="1340" class="img__KcZ"></p>
<h3 class="anchor anchorWithStickyNavbar_myWT" id="excellent-source-code"><strong>Excellent Source Code</strong><a href="#excellent-source-code" class="hash-link" aria-label="Direct link to excellent-source-code" title="Direct link to excellent-source-code">​</a></h3>
<p>Following the principle of technology selection, a new technology must be sufficiently understood in terms of underlying principles and architectural ideas before it is considered for production use. Before choosing StreamPark, its architecture and source code were subjected to in-depth study and reading. It was found that the underlying technologies used by StreamPark are very familiar to Chinese developers: MySQL, Spring Boot, Mybatis Plus, Vue, etc. The code style is unified and elegantly implemented with complete annotations. The modules are independently abstracted and reasonable, employing numerous design patterns, and the code quality is very high, making it highly suitable for troubleshooting and further development in the later stages.</p>
<p><img decoding="async" loading="lazy" src="/assets/images/code_notebook-542046feb8a312b5f6c057af551421c6.png" width="1080" height="527" class="img__KcZ"></p>
<p>In November 2021, StreamPark was successfully selected by Open Source China as a GVP - Gitee &quot;Most Valuable Open Source Project,&quot; which speaks volumes about its quality and potential.</p>
<p><img decoding="async" loading="lazy" src="/assets/images/certificate-2f5b95ebb0816ead327ec169c12996b6.png" width="1080" height="684" class="img__KcZ"></p>
<h3 class="anchor anchorWithStickyNavbar_myWT" id="03-active-community"><strong>03 Active Community</strong><a href="#03-active-community" class="hash-link" aria-label="Direct link to 03-active-community" title="Direct link to 03-active-community">​</a></h3>
<p>The community is currently very active. Since the end of November 2021, when StreamPark (based on 1.2.0-release) was implemented, StreamPark had just started to be recognized by everyone, and there were some minor bugs in the user experience (not affecting core functionality). At that time, in order to go live quickly, some features were disabled and some minor bugs were fixed. Just as we were preparing to contribute back to the community, we found that these had already been fixed, indicating that the community&#x27;s iteration cycle is very fast. In the future, our company&#x27;s team will also strive to stay in sync with the community, quickly implement new features, and improve data development efficiency while reducing maintenance costs.</p>
<h2 class="anchor anchorWithStickyNavbar_myWT" id="02-implementation-practice"><strong>02 Implementation Practice</strong><a href="#02-implementation-practice" class="hash-link" aria-label="Direct link to 02-implementation-practice" title="Direct link to 02-implementation-practice">​</a></h2>
<p>StreamPark&#x27;s environment setup is very straightforward, following the official website&#x27;s building tutorial you can complete the setup within a few hours. It now supports a front-end and back-end separation packaging deployment model, which can meet the needs of more companies, and there has already been a Docker Build related PR, suggesting that StreamPark&#x27;s compilation and deployment will become even more convenient and quick in the future. Related documentation is as follows:</p>
<div class="codeBlockContainer_APcc theme-code-block"><div class="codeBlockContent_IhPH"><pre tabindex="0" class="prism-code language-text codeBlock_tTXe thin-scrollbar" style="color:#9CDCFE;background-color:#1E1E1E"><code class="codeBlockLines_qImF"><span class="token-line" style="color:#9CDCFE"><span class="token plain">https://streampark.apache.org/docs/user-guide/deployment</span><br></span></code></pre><div class="buttonGroup_inAn"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_N8Av" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_EGLt"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_gJas"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>For rapid implementation and production use, we chose the reliable On Yarn resource management mode (even though StreamPark already supports K8S quite well), and there are already many companies that have deployed using StreamPark on K8S, which you can refer to:</p>
<div class="codeBlockContainer_APcc theme-code-block"><div class="codeBlockContent_IhPH"><pre tabindex="0" class="prism-code language-text codeBlock_tTXe thin-scrollbar" style="color:#9CDCFE;background-color:#1E1E1E"><code class="codeBlockLines_qImF"><span class="token-line" style="color:#9CDCFE"><span class="token plain">https://streampark.apache.org/blog/flink-development-framework-streampark</span><br></span></code></pre><div class="buttonGroup_inAn"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_N8Av" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_EGLt"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_gJas"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Integrating StreamPark with the Hadoop ecosystem can be said to be zero-cost (provided that Flink is integrated with the Hadoop ecosystem according to the Flink official website, and tasks can be launched via Flink scripts).</p>
<p>Currently, we are also conducting K8S testing and solution design, and will be migrating to K8S in the future.</p>
<h3 class="anchor anchorWithStickyNavbar_myWT" id="01-implementing-flinksql-tasks"><strong>01 Implementing FlinkSQL Tasks</strong><a href="#01-implementing-flinksql-tasks" class="hash-link" aria-label="Direct link to 01-implementing-flinksql-tasks" title="Direct link to 01-implementing-flinksql-tasks">​</a></h3>
<p>At present, our company&#x27;s tasks based on Flink SQL are mainly for simple real-time ETL and computing scenarios, with about 10 tasks, all of which have been very stable since they went live.</p>
<p><img decoding="async" loading="lazy" src="/assets/images/online_flinksql-ca82a6f42e04e54e9f6da2b1e391b073.png" width="1080" height="118" class="img__KcZ"></p>
<p>StreamPark has thoughtfully prepared a demo SQL task that can be run directly on a newly set up platform. This attention to detail demonstrates the community&#x27;s commitment to user experience. Initially, our simple tasks were written and executed using Flink SQL, and StreamPark&#x27;s support for Flink SQL is excellent, with a superior SQL editor and innovative POM and Jar package dependency management that can meet many SQL scenario needs.</p>
<p>Currently, we are researching and designing solutions related to metadata, permissions, UDFs, etc.</p>
<h3 class="anchor anchorWithStickyNavbar_myWT" id="02-implementing-jar-tasks"><strong>02 Implementing Jar Tasks</strong><a href="#02-implementing-jar-tasks" class="hash-link" aria-label="Direct link to 02-implementing-jar-tasks" title="Direct link to 02-implementing-jar-tasks">​</a></h3>
<p>Since most of the data development team members have a background in Java and Scala, we&#x27;ve implemented Jar-based builds for more flexible development, transparent tuning of Flink tasks, and to cover more scenarios. Our implementation was in two phases:</p>
<p><strong>First Phase:</strong> StreamPark provides support for native Apache Flink® projects. We configured our existing tasks&#x27; Git addresses in StreamPark, used Maven to package them as Jar files, and created StreamPark Apache Flink® tasks for seamless migration. In this process, StreamPark was merely used as a platform tool for task submission and state maintenance, without leveraging the other features mentioned above.</p>
<p><strong>Second Phase:</strong> After migrating tasks to StreamPark in the first phase and having them run on the platform, the tasks&#x27; configurations, such as checkpoint, fault tolerance, and adjustments to business parameters within Flink tasks, required source code modifications, pushes, and builds. This was very inefficient and opaque.</p>
<p>Therefore, following StreamPark&#x27;s QuickStart, we quickly integrated StreamPark&#x27;s programming model, which is an encapsulation for StreamPark Flink tasks (for Apache Flink).</p>
<p>Example：</p>
<div class="codeBlockContainer_APcc theme-code-block"><div class="codeBlockContent_IhPH"><pre tabindex="0" class="prism-code language-text codeBlock_tTXe thin-scrollbar" style="color:#9CDCFE;background-color:#1E1E1E"><code class="codeBlockLines_qImF"><span class="token-line" style="color:#9CDCFE"><span class="token plain">StreamingContext = ParameterTool + StreamExecutionEnvironment</span><br></span></code></pre><div class="buttonGroup_inAn"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_N8Av" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_EGLt"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_gJas"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<ul>
<li>StreamingContext is the encapsulation object for StreamPark</li>
<li>ParameterTool is the parameter object after parsing the configuration file</li>
</ul>
<div class="codeBlockContainer_APcc theme-code-block"><div class="codeBlockContent_IhPH"><pre tabindex="0" class="prism-code language-text codeBlock_tTXe thin-scrollbar" style="color:#9CDCFE;background-color:#1E1E1E"><code class="codeBlockLines_qImF"><span class="token-line" style="color:#9CDCFE"><span class="token plain"> String value = ParameterTool.get(&quot;${user.custom.key}&quot;)</span><br></span></code></pre><div class="buttonGroup_inAn"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_N8Av" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_EGLt"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_gJas"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<ul>
<li>StreamExecutionEnvironment is the native task context for Apache Flink</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_myWT" id="03-business-support--capability-opening"><strong>03 Business Support &amp; Capability Opening</strong><a href="#03-business-support--capability-opening" class="hash-link" aria-label="Direct link to 03-business-support--capability-opening" title="Direct link to 03-business-support--capability-opening">​</a></h2>
<p>Currently, Dustess Info&#x27;s real-time computing platform based on StreamPark has been online since the end of November last year and has launched 50+ Flink tasks, including 10+ Flink SQL tasks and 40+ Jar tasks. At present, it is mainly used internally by the data team, and the real-time computing platform will be opened up for use by business teams across the company shortly, which will significantly increase the number of tasks.</p>
<p><img decoding="async" loading="lazy" src="/assets/images/online_jar-48549248f657388c7aebc0c8491660fa.png" width="1080" height="445" class="img__KcZ"></p>
<h3 class="anchor anchorWithStickyNavbar_myWT" id="01-real-time-data-warehouse"><strong>01 Real-Time Data Warehouse</strong><a href="#01-real-time-data-warehouse" class="hash-link" aria-label="Direct link to 01-real-time-data-warehouse" title="Direct link to 01-real-time-data-warehouse">​</a></h3>
<p>The real-time data warehouse mainly uses Jar tasks because the model is more generic. Using Jar tasks can generically handle a large number of data table synchronization and calculations, and even achieve configuration-based synchronization. Our real-time data warehouse mainly uses Apache Doris for storage, with Flink handling the cleaning and calculations (the goal being storage-computation separation).</p>
<p>Using StreamPark to integrate other components is also very straightforward, and we have also abstracted the configuration related to Apache Doris and Kafka into the configuration file, which greatly enhances our development efficiency and flexibility.</p>
<h3 class="anchor anchorWithStickyNavbar_myWT" id="02-capability-opening"><strong>02 Capability Opening</strong><a href="#02-capability-opening" class="hash-link" aria-label="Direct link to 02-capability-opening" title="Direct link to 02-capability-opening">​</a></h3>
<p>Other business teams outside the data team also have many stream processing scenarios. Hence, after secondary development of the real-time computing platform based on StreamPark, we opened up the following capabilities to all business teams in the company:</p>
<ul>
<li>Business capability opening: The upstream real-time data warehouse collects all business tables through log collection and writes them into Kafka. Business teams can base their business-related development on Kafka, or they can perform OLAP analysis through the real-time data warehouse (Apache Doris).</li>
<li>Computing capability opening: The server resources of the big data platform are made available for use by business teams.</li>
<li>Solution opening: The mature Connectors of the Flink ecosystem and support for Exactly Once semantics can reduce the development and maintenance costs related to stream processing for business teams.</li>
</ul>
<p>Currently, StreamPark does not support multi-business group functions. The multi-business group function will be abstracted and contributed to the community.</p>
<p><img decoding="async" loading="lazy" src="/assets/images/manager-07ba2a4bc979cd2dd86fc9e07384ec61.png" width="1080" height="235" class="img__KcZ"></p>
<p><img decoding="async" loading="lazy" src="/assets/images/task_retrieval-eee86f9c0af117cbf15d2af5d528b2cc.png" width="1080" height="382" class="img__KcZ"></p>
<h2 class="anchor anchorWithStickyNavbar_myWT" id="04-future-planning"><strong>04 Future Planning</strong><a href="#04-future-planning" class="hash-link" aria-label="Direct link to 04-future-planning" title="Direct link to 04-future-planning">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_myWT" id="01-flink-on-k8s"><strong>01 Flink on K8S</strong><a href="#01-flink-on-k8s" class="hash-link" aria-label="Direct link to 01-flink-on-k8s" title="Direct link to 01-flink-on-k8s">​</a></h3>
<p>Currently, all our company&#x27;s Flink tasks run on Yarn, which meets current needs, but Flink on Kubernetes has the following advantages:</p>
<ul>
<li><strong>Unified Operations</strong>. The company has unified operations with a dedicated department managing K8S.</li>
<li><strong>CPU Isolation</strong>. There is CPU isolation between K8S Pods, so real-time tasks do not affect each other, leading to more stability.</li>
<li><strong>Separation of Storage and Computation</strong>. Flink&#x27;s computational resources and state storage are separated; computational resources can be mixed with other component resources, improving machine utilization.</li>
<li><strong>Elastic Scaling</strong>. It is capable of elastic scaling, better saving manpower and material costs.</li>
</ul>
<p>I am also currently organizing and implementing related technical architectures and solutions and have completed the technical verification of Flink on Kubernetes using StreamPark in an experimental environment. With the support of the StreamPark platform and the enthusiastic help of the community, I believe that production implementation is not far off.</p>
<h3 class="anchor anchorWithStickyNavbar_myWT" id="02-stream-batch-unification-construction"><strong>02 Stream-Batch Unification Construction</strong><a href="#02-stream-batch-unification-construction" class="hash-link" aria-label="Direct link to 02-stream-batch-unification-construction" title="Direct link to 02-stream-batch-unification-construction">​</a></h3>
<p>Personally, I think the biggest difference between batch and stream processing lies in the scheduling strategy of operator tasks and the data transfer strategy between operators:</p>
<ul>
<li><strong>Batch processing</strong>: Upstream and downstream operator tasks have sequential scheduling (upstream tasks end and release resources), and data has a Shuffle strategy (landing on disk). The downside is lower timeliness and no intermediate state in computation, but the upside is high throughput, suitable for offline computation of super-large data volumes.</li>
<li><strong>Stream processing</strong>: Upstream and downstream operator tasks start at the same time (occupying resources simultaneously), and data is streamed between nodes through the network. The downside is insufficient throughput, but the advantage is high timeliness and intermediate state in computation, suitable for real-time and incremental computation scenarios.</li>
</ul>
<p>As mentioned above, I believe that choosing <strong>batch or stream processing</strong> <strong>is a tuning method for data development according to different data volumes and business scenarios</strong>. However, currently, because the computing engine and platform distinguish offline and real-time, it causes development and maintenance fragmentation, with prohibitively high costs. To achieve stream-batch unification, the following aspects must be realized:</p>
<ul>
<li>Unified storage (unification of metadata): Supports batch and stream writing/reading.</li>
<li>Unified computing engine: Able to use a set of APIs or SQL to develop offline and real-time tasks.</li>
<li>Unified data platform: Able to support the persistent real-time tasks, as well as offline scheduling strategies.</li>
</ul>
<p>Regarding the unification of stream and batch, I am also currently researching and organizing, and I welcome interested friends to discuss and study the project together.</p>
<h2 class="anchor anchorWithStickyNavbar_myWT" id="05-closing-words"><strong>05 Closing Words</strong><a href="#05-closing-words" class="hash-link" aria-label="Direct link to 05-closing-words" title="Direct link to 05-closing-words">​</a></h2>
<p>That&#x27;s all for the sharing of StreamPark in the production practice at Dustess Info. Thank you all for reading this far. The original intention of writing this article was to bring a bit of StreamPark&#x27;s production practice experience and reference to everyone, and together with the buddies in the StreamPark community, to jointly build StreamPark. In the future, I plan to participate and contribute more. A big thank you to the developers of StreamPark for providing such an excellent product; in many details, we can feel everyone&#x27;s dedication. Although the current production version used by the company (1.2.0-release) still has some room for improvement in task group search, edit return jump page, and other interactive experiences, the merits outweigh the minor issues. I believe that StreamPark will get better and better, <strong>and I also believe that StreamPark will promote the popularity of Apache Flink</strong>. Finally, let&#x27;s end with a phrase from the Apache Flink® community: The future is real-time!</p>
<p><img decoding="async" loading="lazy" src="/assets/images/author-487ad3c1ad9a397cd4c2614f54976368.png" width="844" height="439" class="img__KcZ"></p></div><footer class="row docusaurus-mt-lg blogPostFooterDetailsFull_Wr5y"><div class="post-footer"><div class="col"><b>Tags:</b><ul class="tags_bUDc padding--none margin-left--sm"><li class="tag_edSN"><a class="tag_mtSO tagRegular_u5wg" href="/blog/tags/stream-park">StreamPark</a></li><li class="tag_edSN"><a class="tag_mtSO tagRegular_u5wg" href="/blog/tags/production-practice">Production Practice</a></li><li class="tag_edSN"><a class="tag_mtSO tagRegular_u5wg" href="/blog/tags/flink-sql">FlinkSQL</a></li></ul></div><div class="col col-3 text--right"><a href="https://github.com/apache/incubator-streampark-website/edit/dev/blog/5-streampark-usercase-dustess.md" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_WHnd" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div></div></footer></article></div></div></div><nav class="pagination-nav docusaurus-mt-lg" aria-label="Blog post page navigation"><a class="pagination-nav__link pagination-nav__link--prev paginationNavLink_UdUv" href="/blog/streampark-usercase-shunwang"><svg width="24" height="25" viewBox="0 0 24 25" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M9.2751 19.175L10.3251 18.125L5.4501 13.25H21.6001V11.75H5.4501L10.3251 6.87501L9.2751 5.82501L2.5751 12.5L9.2751 19.175Z" fill="currentColor"></path></svg><div class="paginationNavContent__3xr"><div class="pagination-nav__sublabel">Newer Post</div><div class="paginationNavLabel_YPzM pagination-nav__label">Apache StreamPark™ in the Large-Scale Production Practice at Shunwang Technology</div></div></a><a class="pagination-nav__link pagination-nav__link--next paginationNavLink_UdUv" href="/blog/streampark-usercase-joyme"><div class="paginationNavContent__3xr"><div class="pagination-nav__sublabel">Older Post</div><div class="paginationNavLabel_YPzM pagination-nav__label">Apache StreamPark™&#x27;s Production Practice in Joyme</div></div><svg width="24" height="25" viewBox="0 0 24 25" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M14.7249 19.175L13.6749 18.125L18.5499 13.25H2.3999V11.75H18.5499L13.6749 6.87501L14.7249 5.82501L21.4249 12.5L14.7249 19.175Z" fill="currentColor"></path></svg></a></nav></main><div class="col col--2"><div class="tableOfContents_jeP5 thin-scrollbar" style="opacity:0;transform:translateX(100px) translateZ(0)"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#01-technology-selection" class="table-of-contents__link toc-highlight"><strong>01 Technology Selection</strong></a><ul><li><a href="#high-completion" class="table-of-contents__link toc-highlight"><strong>High Completion</strong></a></li><li><a href="#excellent-source-code" class="table-of-contents__link toc-highlight"><strong>Excellent Source Code</strong></a></li><li><a href="#03-active-community" class="table-of-contents__link toc-highlight"><strong>03 Active Community</strong></a></li></ul></li><li><a href="#02-implementation-practice" class="table-of-contents__link toc-highlight"><strong>02 Implementation Practice</strong></a><ul><li><a href="#01-implementing-flinksql-tasks" class="table-of-contents__link toc-highlight"><strong>01 Implementing FlinkSQL Tasks</strong></a></li><li><a href="#02-implementing-jar-tasks" class="table-of-contents__link toc-highlight"><strong>02 Implementing Jar Tasks</strong></a></li></ul></li><li><a href="#03-business-support--capability-opening" class="table-of-contents__link toc-highlight"><strong>03 Business Support &amp; Capability Opening</strong></a><ul><li><a href="#01-real-time-data-warehouse" class="table-of-contents__link toc-highlight"><strong>01 Real-Time Data Warehouse</strong></a></li><li><a href="#02-capability-opening" class="table-of-contents__link toc-highlight"><strong>02 Capability Opening</strong></a></li></ul></li><li><a href="#04-future-planning" class="table-of-contents__link toc-highlight"><strong>04 Future Planning</strong></a><ul><li><a href="#01-flink-on-k8s" class="table-of-contents__link toc-highlight"><strong>01 Flink on K8S</strong></a></li><li><a href="#02-stream-batch-unification-construction" class="table-of-contents__link toc-highlight"><strong>02 Stream-Batch Unification Construction</strong></a></li></ul></li><li><a href="#05-closing-words" class="table-of-contents__link toc-highlight"><strong>05 Closing Words</strong></a></li></ul></div></div></div></div></div></div><footer class="footer"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Join Community</div><ul class="footer__items clean-list"><li class="footer__item">
                <div class="subscribe-box btns">
                  <a class="btn btn-primary" href="https://github.com/apache/incubator-streampark"><i class="fa fa-github"></i><span>Github</span></a>
                  <a class="btn btn-primary" href="https://github.com/apache/incubator-streampark/issues"><i class="fa fa-slack"></i><span>Issue Tracking</span></a>
                  <a class="btn btn-primary" href="javascript:void(0)">
                    <i class="fa fa-wechat"></i>
                    <span>Wechat</span>
                    <div class="wechat-dropdown"><img src="/image/join_wechat.png" alt="weChat"></div>
                  </a>
                </div>
              </li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright"><div>
        <div>
          <div style="margin-bottom: 30px;">
            <a href="https://incubator.apache.org/" class="footerLogoLink" one-link-mark="yes">
              <img alt="Apache Incubator logo" class="footer__logo" width="200">
            </a>
          </div>
          <div>
            <p>
            Apache StreamPark is an effort undergoing incubation at The Apache Software Foundation (ASF), sponsored by the Apache Incubator. Incubation is required of all newly accepted projects until a further review indicates that the infrastructure, communications, and decision making process have stabilized in a manner consistent with other successful ASF projects. While incubation status is not necessarily a reflection of the completeness or stability of the code, it does indicate that the project has yet to be fully endorsed by the ASF.
            </p>
          </div>
        </div>

        <div>
          <span>
            Copyright © 2022-2024 The Apache Software Foundation. Apache StreamPark, StreamPark, and its feather logo are trademarks of The Apache Software Foundation.
          </span>
        </div>
      </div></div></div></div></footer></div>
</body>
</html>