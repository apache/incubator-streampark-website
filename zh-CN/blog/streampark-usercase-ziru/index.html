<!doctype html>
<html lang="zh-CN" dir="ltr" class="blog-wrapper blog-post-page plugin-blog plugin-id-default" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.3.2">
<title data-rh="true">自如基于Apache StreamPark™ 的实时计算平台实践 | Apache StreamPark (incubating)</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://streampark.apache.org/zh-CN/blog/streampark-usercase-ziru"><meta data-rh="true" property="og:locale" content="zh_CN"><meta data-rh="true" property="og:locale:alternate" content="en"><meta data-rh="true" name="docusaurus_locale" content="zh-CN"><meta data-rh="true" name="docusaurus_tag" content="default"><meta data-rh="true" name="docsearch:language" content="zh-CN"><meta data-rh="true" name="docsearch:docusaurus_tag" content="default"><meta data-rh="true" property="og:title" content="自如基于Apache StreamPark™ 的实时计算平台实践 | Apache StreamPark (incubating)"><meta data-rh="true" name="description" content="导读：自如作为一家专注于提供租房产品和服务的 O2O 互联网公司，构建了一个涵盖城市居住生活领域全链条的在线化、数据化、智能化平台，实时计算在自如一直扮演着重要的角色。到目前为止，自如每日需要处理 TB 级别的数据，本文由来自自如的实时计算小伙伴带来，介绍了自如基于 StreamPark 的实时计算平台深度实践。"><meta data-rh="true" property="og:description" content="导读：自如作为一家专注于提供租房产品和服务的 O2O 互联网公司，构建了一个涵盖城市居住生活领域全链条的在线化、数据化、智能化平台，实时计算在自如一直扮演着重要的角色。到目前为止，自如每日需要处理 TB 级别的数据，本文由来自自如的实时计算小伙伴带来，介绍了自如基于 StreamPark 的实时计算平台深度实践。"><meta data-rh="true" property="og:type" content="article"><meta data-rh="true" property="article:published_time" content="2024-10-18T07:44:07.000Z"><meta data-rh="true" property="article:tag" content="StreamPark,生产实践"><link data-rh="true" rel="icon" href="/zh-CN/image/favicon.ico"><link data-rh="true" rel="canonical" href="https://streampark.apache.org/zh-CN/blog/streampark-usercase-ziru"><link data-rh="true" rel="alternate" href="https://streampark.apache.org/blog/streampark-usercase-ziru" hreflang="en"><link data-rh="true" rel="alternate" href="https://streampark.apache.org/zh-CN/blog/streampark-usercase-ziru" hreflang="zh-CN"><link data-rh="true" rel="alternate" href="https://streampark.apache.org/blog/streampark-usercase-ziru" hreflang="x-default"><link rel="alternate" type="application/rss+xml" href="/zh-CN/blog/rss.xml" title="Apache StreamPark (incubating) RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/zh-CN/blog/atom.xml" title="Apache StreamPark (incubating) Atom Feed"><link rel="stylesheet" href="/zh-CN/assets/css/styles.973b1f1a.css">
<script src="/zh-CN/assets/js/runtime~main.470707f1.js" defer="defer"></script>
<script src="/zh-CN/assets/js/main.ef599892.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return localStorage.getItem("theme")}catch(t){}}();null!==e?t(e):window.matchMedia("(prefers-color-scheme: dark)").matches?t("dark"):window.matchMedia("(prefers-color-scheme: light)").matches?t("light"):t("dark")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="跳到主要内容"><a class="skipToContent_BCtO" href="#__docusaurus_skipToContent_fallback">跳到主要内容</a></div><nav aria-label="主导航" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><a class="navbar__brand" href="/zh-CN/"><div class="navbar__logo"><img src="/zh-CN/image/logo.png" alt="StreamPark Logo" class="themedComponent_Cvhi themedComponent--light_uT2j"><img src="/zh-CN/image/logo.png" alt="StreamPark Logo" class="themedComponent_Cvhi themedComponent--dark_ENih"></div><b class="navbar__title text--truncate">StreamPark</b></a></div><div class="navbar__items navbar__items--right"><a class="navbar__item navbar__link" href="/zh-CN/docs/get-started/intro">文档</a><a class="navbar__item navbar__link" href="/zh-CN/download">下载</a><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link">社区</a><ul class="dropdown__menu"><li><a href="https://www.apache.org/foundation/policies/conduct" target="_blank" rel="noopener noreferrer" class="dropdown__link">行为守则</a></li><li><a class="dropdown__link" href="/zh-CN/community/contribution_guide/mailing_lists">加入邮件列表</a></li><li><a class="dropdown__link" href="/zh-CN/community/contribution_guide/become_committer">成为 Committer</a></li><li><a class="dropdown__link" href="/zh-CN/community/contribution_guide/become_pmc_member">成为 PMC 成员</a></li><li><a class="dropdown__link" href="/zh-CN/community/contribution_guide/new_committer_process">新的 Committer 流程</a></li><li><a class="dropdown__link" href="/zh-CN/community/contribution_guide/new_pmc_ember_process">新的 PMC 成员流程</a></li><li><a class="dropdown__link" href="/zh-CN/community/submit_guide/document">文档</a></li><li><a class="dropdown__link" href="/zh-CN/community/submit_guide/submit_code">提交代码</a></li><li><a class="dropdown__link" href="/zh-CN/community/submit_guide/code_style_and_quality_guide">代码风格和质量指南</a></li><li><a class="dropdown__link" href="/zh-CN/community/submit_guide/documentation_style_guide">文档书写规范</a></li><li><a class="dropdown__link" href="/zh-CN/community/release/how_to_release_version_2.1.x">How to release version 2.1.x</a></li><li><a class="dropdown__link" href="/zh-CN/community/release/how_to_verify_release">如何验证发版</a></li></ul></div><a class="navbar__item navbar__link" href="/zh-CN/team">团队</a><a class="navbar__item navbar__link" href="/zh-CN/user">用户</a><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link">Apache</a><ul class="dropdown__menu"><li><a href="https://www.apache.org/" target="_blank" rel="noopener noreferrer" class="dropdown__link">基金会</a></li><li><a href="https://www.apache.org/licenses/" target="_blank" rel="noopener noreferrer" class="dropdown__link">证书</a></li><li><a href="https://www.apache.org/events/current-event" target="_blank" rel="noopener noreferrer" class="dropdown__link">事件</a></li><li><a href="https://www.apache.org/security/" target="_blank" rel="noopener noreferrer" class="dropdown__link">安全</a></li><li><a href="https://www.apache.org/foundation/sponsorship.html" target="_blank" rel="noopener noreferrer" class="dropdown__link">赞助</a></li><li><a href="https://www.apache.org/foundation/policies/privacy.html" target="_blank" rel="noopener noreferrer" class="dropdown__link">Privacy</a></li><li><a href="https://www.apache.org/foundation/thanks.html" target="_blank" rel="noopener noreferrer" class="dropdown__link">致谢</a></li></ul></div><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/zh-CN/blog">博客</a><a href="https://github.com/apache/incubator-streampark/issues/507" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">FAQ</a><a href="https://github.com/apache/incubator-streampark" target="_blank" class="githubStars_qnS9"><div class="githubStarsContainer_O7dk"><svg width="16" height="16" viewBox="0 0 16 16" fill="none" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" clip-rule="evenodd" d="M8 1.75C4.27062 1.75 1.25 4.77062 1.25 8.5C1.25 11.4869 3.18219 14.0097 5.86531 14.9041C6.20281 14.9631 6.32937 14.7606 6.32937 14.5834C6.32937 14.4231 6.32094 13.8916 6.32094 13.3263C4.625 13.6384 4.18625 12.9128 4.05125 12.5331C3.97531 12.3391 3.64625 11.74 3.35938 11.5797C3.12312 11.4531 2.78562 11.1409 3.35094 11.1325C3.8825 11.1241 4.26219 11.6219 4.38875 11.8244C4.99625 12.8453 5.96656 12.5584 6.35469 12.3813C6.41375 11.9425 6.59094 11.6472 6.785 11.4784C5.28312 11.3097 3.71375 10.7275 3.71375 8.14563C3.71375 7.41156 3.97531 6.80406 4.40563 6.33156C4.33812 6.16281 4.10187 5.47094 4.47312 4.54281C4.47312 4.54281 5.03844 4.36563 6.32937 5.23469C6.86937 5.08281 7.44313 5.00687 8.01688 5.00687C8.59063 5.00687 9.16438 5.08281 9.70438 5.23469C10.9953 4.35719 11.5606 4.54281 11.5606 4.54281C11.9319 5.47094 11.6956 6.16281 11.6281 6.33156C12.0584 6.80406 12.32 7.40312 12.32 8.14563C12.32 10.7359 10.7422 11.3097 9.24031 11.4784C9.485 11.6894 9.69594 12.0944 9.69594 12.7272C9.69594 13.63 9.6875 14.3556 9.6875 14.5834C9.6875 14.7606 9.81406 14.9716 10.1516 14.9041C12.8178 14.0097 14.75 11.4784 14.75 8.5C14.75 4.77062 11.7294 1.75 8 1.75Z" fill="currentColor"></path></svg><span class="githubText_YlX6">3.9k</span></div></a><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link"><svg viewBox="0 0 24 24" width="20" height="20" aria-hidden="true" class="iconLanguage_DSK9"><path fill="currentColor" d="M12.87 15.07l-2.54-2.51.03-.03c1.74-1.94 2.98-4.17 3.71-6.53H17V4h-7V2H8v2H1v1.99h11.17C11.5 7.92 10.44 9.75 9 11.35 8.07 10.32 7.3 9.19 6.69 8h-2c.73 1.63 1.73 3.17 2.98 4.56l-5.09 5.02L4 19l5-5 3.11 3.11.76-2.04zM18.5 10h-2L12 22h2l1.12-3h4.75L21 22h2l-4.5-12zm-2.62 7l1.62-4.33L19.12 17h-3.24z"></path></svg></a><ul class="dropdown__menu"><li><a href="/blog/streampark-usercase-ziru" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="en">English</a></li><li><a href="/zh-CN/blog/streampark-usercase-ziru" target="_self" rel="noopener noreferrer" class="dropdown__link dropdown__link--active" lang="zh-CN">简体中文</a></li></ul></div><a class="colorModeButton_yITp undefined"><svg xmlns="http://www.w3.org/2000/svg" fill="none" width="16" height="16" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" class="w-6 h-6"><path stroke-linecap="round" stroke-linejoin="round" d="M21.752 15.002A9.718 9.718 0 0118 15.75c-5.385 0-9.75-4.365-9.75-9.75 0-1.33.266-2.597.748-3.752A9.753 9.753 0 003 11.25C3 16.635 7.365 21 12.75 21a9.753 9.753 0 009.002-5.998z"></path></svg></a><div class="navbarSearchContainer_dCNk"><div class="navbar__search searchBarContainer_SuYZ"><input placeholder="搜索" aria-label="Search" class="navbar__search-input"><div class="loadingRing_HgBb searchBarLoadingRing_om0w"><div></div><div></div><div></div><div></div></div></div></div><button aria-label="切换导航栏" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_pmYA"><div class="container-wrapper blog-container"><div class="container margin-vert--lg"><div class="row"><aside class="col col--2 overflow-hidden" style="opacity:0;transform:translateX(-100px) translateZ(0)"><nav class="sidebar_brwN thin-scrollbar" aria-label="最近博文导航"><div class="backButton_MCHS"><svg xmlns="http://www.w3.org/2000/svg" width="32" height="32" viewBox="0 0 24 24"><path fill="currentColor" d="M8 7v4L2 6l6-5v4h5a8 8 0 1 1 0 16H4v-2h9a6 6 0 0 0 0-12H8Z"></path></svg></div><a class="sidebarItemTitle_r4Q1 margin-bottom--sm" href="/zh-CN/blog">近期文章</a><ul class="sidebarItemList_QwSx clean-list"><li class="sidebarItem_lnhn"><a class="sidebarItemLink_yNGZ" href="/zh-CN/blog/streampark-flink-on-k8s">Apache StreamPark™ Flink on Kubernetes 实践</a></li><li class="sidebarItem_lnhn"><a class="sidebarItemLink_yNGZ" href="/zh-CN/blog/flink-development-framework-streampark">Flink 开发利器 Apache StreamPark™</a></li><li class="sidebarItem_lnhn"><a class="sidebarItemLink_yNGZ" href="/zh-CN/blog/streampark-flink-with-paimon-in-ziru">自如基于 Apache StreamPark™ + Paimon 实现数据一键入湖最佳实践</a></li><li class="sidebarItem_lnhn"><a class="sidebarItemLink_yNGZ" href="/zh-CN/blog/streampark-usercase-tianyancha">Apache StreamPark™ 助力天眼查实时平台建设｜效率数倍提升</a></li><li class="sidebarItem_lnhn"><a class="sidebarItemLink_yNGZ" href="/zh-CN/blog/streampark-usercase-joymaker">Apache StreamPark™ 在欢乐互娱的云原生平台实践</a></li><li class="sidebarItem_lnhn"><a class="sidebarItemLink_yNGZ" href="/zh-CN/blog/streampark-usercase-chinaunion">联通 Flink 实时计算平台化运维实践</a></li><li class="sidebarItem_lnhn"><a class="sidebarItemLink_yNGZ" href="/zh-CN/blog/streampark-usercase-bondex-with-paimon">海程邦达基于 Apache Paimon + Apache StreamPark™ 的流式数仓实践</a></li><li class="sidebarItem_lnhn"><a class="sidebarItemLink_yNGZ" href="/zh-CN/blog/streampark-usercase-shunwang">Apache StreamPark™ 在顺网科技的大规模生产实践</a></li><li class="sidebarItem_lnhn"><a class="sidebarItemLink_yNGZ" href="/zh-CN/blog/streampark-usercase-dustess">Apache StreamPark™ 在尘锋信息的最佳实践，化繁为简极致体验</a></li><li class="sidebarItem_lnhn"><a class="sidebarItemLink_yNGZ" href="/zh-CN/blog/streampark-usercase-joyme">Apache StreamPark™ 在 Joyme 的生产实践</a></li><li class="sidebarItem_lnhn"><a class="sidebarItemLink_yNGZ" href="/zh-CN/blog/streampark-usercase-haibo">Apache StreamPark™ 一站式计算利器在海博科技的生产实践，助力智慧城市建设</a></li><li class="sidebarItem_lnhn"><a aria-current="page" class="sidebarItemLink_yNGZ sidebarItemLinkActive_oSRm" href="/zh-CN/blog/streampark-usercase-ziru">自如基于Apache StreamPark™ 的实时计算平台实践</a></li><li class="sidebarItem_lnhn"><a class="sidebarItemLink_yNGZ" href="/zh-CN/blog/streampark-usercase-changan">长安汽车从自研平台到Apache StreamPark™ 的升级实践</a></li></ul></nav></aside><main class="col col--8 overflow-hidden" itemscope="" itemtype="http://schema.org/Blog"><div><div class="row" style="margin:0"><div class="col col--12 article__details article-bg"><article itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><meta itemprop="description" content="导读：自如作为一家专注于提供租房产品和服务的 O2O 互联网公司，构建了一个涵盖城市居住生活领域全链条的在线化、数据化、智能化平台，实时计算在自如一直扮演着重要的角色。到目前为止，自如每日需要处理 TB 级别的数据，本文由来自自如的实时计算小伙伴带来，介绍了自如基于 StreamPark 的实时计算平台深度实践。"><header><h1 class="margin-bottom--md blogPostTitle_thoQ text--center post--titleLink" itemprop="headline">自如基于Apache StreamPark™ 的实时计算平台实践</h1><div class="margin-vert--md"><time datetime="2024-10-18T07:44:07.000Z" itemprop="datePublished"></time> · <!-- -->阅读需 37 分钟</div></header><div id="__blog-post-container" class="markdown" itemprop="articleBody"><p><img decoding="async" loading="lazy" src="/zh-CN/assets/images/cover-87ff8832da8f5d9398ed5a1e2f283d0d.png" width="1080" height="460" class="img__KcZ"></p>
<p>**导读：**自如作为一家专注于提供租房产品和服务的 O2O 互联网公司，构建了一个涵盖城市居住生活领域全链条的在线化、数据化、智能化平台，实时计算在自如一直扮演着重要的角色。到目前为止，自如每日需要处理 TB 级别的数据，本文由来自自如的实时计算小伙伴带来，介绍了自如基于 StreamPark 的实时计算平台深度实践。</p>
<ul>
<li>实时计算遇到的挑战</li>
<li>需求解决方案之路</li>
<li>基于 StreamPark 的深度实践</li>
<li>实践经验总结和示例</li>
<li>带来的收益</li>
<li>未来规划</li>
</ul>
<p>自如作为提供租房产品及服务的 O2O 互联网品牌，成立于 2011 年 10 月，自如已为近 50 万业主、500 万自如客提供服务，管理房源超过 100 万间。截至 2021 年 3 月，自如已开通北京、上海、深圳、杭州、南京、广州、成都、天津、武汉、苏州 10 大城市。
自如通过打造涵盖 To C 和 To B 的品质居住产品、逐步实现城市居住生活领域全链条的线上化、数据化、智能化的平台能力。自如 APP 装机量累计达 1.4 亿次，日均线上服务调用达 4 亿次，拥有智能化房源万余间。自如现已在 PC、APP、微信全渠道实现租房、服务、社区的 O2O 闭环，省去传统租房模式所有中间冗余环节，通过 O2O 模式重构居住市场格局，并建立了中国最大的 O2O 青年居住社区。</p>
<p>在拥有庞大用户群体情况下，自如为了给用 户提供更加优质的产品体验，实现企业的数字化转型，从 2021 年开始大力发展实时计算，Flink 在自如的实时计算中一直扮演着重要的角色。到目前为止，自如每日需要处理 TB 级别的数据，总共拥有 500+ 个实时作业，并支撑每日超过 1000 万次的数据调用请求。</p>
<h2 class="anchor anchorWithStickyNavbar_myWT" id="实时计算遇到的挑战"><strong>实时计算遇到的挑战</strong><a href="#实时计算遇到的挑战" class="hash-link" aria-label="实时计算遇到的挑战的直接链接" title="实时计算遇到的挑战的直接链接">​</a></h2>
<p>在自如，实时计算大概分为 2 个应用场景：</p>
<ul>
<li>
<p>数据同步：包括 Kafka、Mysql、Mongo 数据同步到 Hive / Paimon / ClickHouse 等。</p>
</li>
<li>
<p>实时数仓：包括出租、收房、家服等业务实时指标。</p>
</li>
</ul>
<p>在实时计算实践过程中遇到了一些挑战，大致如下：</p>
<h3 class="anchor anchorWithStickyNavbar_myWT" id="01-作业上线效率低"><strong>01 作业上线效率低</strong><a href="#01-作业上线效率低" class="hash-link" aria-label="01-作业上线效率低的直接链接" title="01-作业上线效率低的直接链接">​</a></h3>
<p>在自如实时作业的开发上线流程是：数据仓库开发人员将 Flink SQL 代码嵌入到程序中，在本地进行代码调试，然后编译成 FatJar，最后再将作业以工单和 JAR 包形式提交给运维，运维负责作业上线的小伙伴再通过命令行的方式将作业部署到线上 Kubernetes session 环境。可以看到这一过程涉及到诸多环节，每一步都是需要人为介入，效率极其低下，而且非常容易出错，影响工作效率和稳定性。因此，我们亟需构建一套高效、自动化的实时计算平台，以满足日益增涨的实时计算需求。</p>
<p><img decoding="async" loading="lazy" src="/zh-CN/assets/images/job_goes_online-ae38a4f939687b0e80e8e5677885fe0d.png" width="1080" height="356" class="img__KcZ"></p>
<h3 class="anchor anchorWithStickyNavbar_myWT" id="02-作业归属信息不明确"><strong>02 作业归属信息不明确</strong><a href="#02-作业归属信息不明确" class="hash-link" aria-label="02-作业归属信息不明确的直接链接" title="02-作业归属信息不明确的直接链接">​</a></h3>
<p>由于实时计算平台没有对作业进行统一管理，业务代码都是由 GitLab 管理，虽然解决了部分问题，但是我们发现仓库代码与线上部署的 Flink 作业管理之间仍然存在缺陷：缺乏明确归属、缺少分组和有效权限控制，导致作业管理混乱且责任链路难以追溯。为确保代码和上线作业的一致和可控性，亟需建立严格且清晰的作业管理体系，其中包括实行严格的代码版本控制、明确作业归属和负责人、以及建立有效的权限控制。</p>
<h3 class="anchor anchorWithStickyNavbar_myWT" id="03-作业维护困难"><strong>03 作业维护困难</strong><a href="#03-作业维护困难" class="hash-link" aria-label="03-作业维护困难的直接链接" title="03-作业维护困难的直接链接">​</a></h3>
<p>在自如有多个不同版本的 Flink 作业在运行，由于 Apache Flink® 的 API 在大版本升级中经常会发生变动，且不保证向下兼容性，这直接导致流作业项目代码的升级成本变得很高。因此如何管理这些不同版本的作业成了头痛的问题。</p>
<p>由于没有统一的作业平台，这些作业在提交时，只能通过执行脚本的形式进行提交。不同的作业有不同重要程度和数据量级，作业所需资源和运行参数也都各不相同，都需要相应的修改。我们可以通过修改提交脚本或直接在代码中设置参数来进行修改，但这使得配置信息的获取变得困难，尤其是当作业出现重启或失败时，FlinkUI 无法打开，配置信息变成一个黑盒。因此，亟需建立一个更加高效、支持配置实时  计算平台。</p>
<h3 class="anchor anchorWithStickyNavbar_myWT" id="04-作业开发调试困难"><strong>04 作业开发调试困难</strong><a href="#04-作业开发调试困难" class="hash-link" aria-label="04-作业开发调试困难的直接链接" title="04-作业开发调试困难的直接链接">​</a></h3>
<p>在以往的开发流程中，我们通常在本地的 IDEA 环境中，通过将 SQL 代码嵌入程序代码的方式进行作业的开发和调试，以验证程序的正确性。然而，这种方式存在如下弊端：</p>
<p>1.多数据源调试困难。通常，一个需求可能涉及多个不同的数据源。为了在本地环境调试，开发人员需要申请开通数据访问需要的白名单，这一过程既耗时又繁琐。</p>
<p>2.SQL 代码难以阅读和修改。由于 SQL 代码是嵌入在程序代码中的，这使得代码难以阅读，修改起来也相当不便。更为困难的是，当需要通过 SQL 片段的方式进行调试时，由于缺少 SQL 版本管理和语法校验的支持，开发人员很难通过客户端日志定位到具体的 SQL 行号，从而找出执行失败的原因。</p>
<p>因此，急需提高开发、调试的效率</p>
<h2 class="anchor anchorWithStickyNavbar_myWT" id="寻求解决方案之路"><strong>寻求解决方案之路</strong><a href="#寻求解决方案之路" class="hash-link" aria-label="寻求解决方案之路的直接链接" title="寻求解决方案之路的直接链接">​</a></h2>
<p>在平台构建的初期阶段，2022 年初开始我们就全面调查了行业内的几乎所有相关项目，涵盖了商业付费版和开源版。经过调查和对比发现，这些项目都或多或少地存在一定的局限性，可用性和稳定性也无法有效地保障。</p>
<p>综合下来 StreamPark 在我们的评估中表现最优，是唯一一个没有硬伤且扩展性很强的项目：同时支持 SQL 和 JAR 作业，在 Flink 作业的部署模式上也是最为完善和稳定的，特有的架构设计使  得不仅不会锁定 Flink 版本，还支持便捷的版本切换和并行处理，有效解决了作业依赖隔离和冲突的问题。我们重点关注的作业管理 &amp; 运维能力也非常完善，包括监控、告警、SQL 校验、SQL 版本对比、CI 等功能，StreamPark 对 Flink on K8s 的支持也是我们调研的所有开源项目中最为完善的。但 StreamPark 的 K8s 模式提交需在本地构建镜像导致存储资源消耗。</p>
<p>目前在最新的 2.2 版本中社区已经重构了这部分实现</p>
<p>在深入分析了众多开源项目的优缺点后，我们认为可以先去参与了解那些拥有优秀的架构、充满发展潜力，并且核心团队积极努力的项目，投身其中。基于这样的认识，我们做出了如下决策：</p>
<p>1.在作业部署模式上，我们决定采用 On Kubernetes 的模式。实时作业的资源消耗具有动态性，对 Kubernetes 提供的弹性扩缩容有强烈的需求，这有助于我们更好地应对数据产出的波动，确保作业的稳定运行。</p>
<p>2.在开源组件的选择上，我们经过各项指标综合对比评估，最终选择了当时的 StreamX。后续和社区保持密切的沟通，在此过程中深刻感受到创始人认真负责的态度和社区的团结友善的氛围，也见证了项目 2022 年 09 月加入 Apache 孵化器的过程，这让我们对该项目的未来充满希望。</p>
<p>3.在 StreamPark 基础上，我们要推动与公司已有生态的整合，以便更好地满足我们的业务需求。</p>
<h2 class="anchor anchorWithStickyNavbar_myWT" id="基于-apache-streampark-的深度实践"><strong>基于 Apache StreamPark™ 的深度实践</strong><a href="#基于-apache-streampark-的深度实践" class="hash-link" aria-label="基于-apache-streampark-的深度实践的直接链接" title="基于-apache-streampark-的深度实践的直接链接">​</a></h2>
<p>基于上述决策，我们启动了以 “痛点需求” 为导向的实时计算平台演进 工作，基于StremaPark 打造一个稳定、高效、易维护的实时计算平台。从 2022 年初开始我们便参与社区的建设，同时我们内部平台建设也正式提上日程。</p>
<p>首先我们在 StreamPark 的基础上进一步完善相关的功能：</p>
<p><img decoding="async" loading="lazy" src="/zh-CN/assets/images/platform_construction-b73e12b57a4a9f558ada77038496bf50.png" width="1080" height="522" class="img__KcZ"></p>
<h3 class="anchor anchorWithStickyNavbar_myWT" id="01-ldap-登录支持"><strong>01 LDAP 登录支持</strong><a href="#01-ldap-登录支持" class="hash-link" aria-label="01-ldap-登录支持的直接链接" title="01-ldap-登录支持的直接链接">​</a></h3>
<p>在 StreamPark 的基础上，我们进一步完善了相关的功能，其中包括对 LDAP 的支持，以便我们未来可以完全开放实时能力，让公司的四个业务线所属的分析师能够使用该平台，预计届时人数将达到 170 人左右。随着人数的增加，账号的管理变得越发重要，特别是在人员变动时，账号的注销和申请将成为一项频繁且耗时的操作。所以，接入 LDAP 变得尤为重要。因此我们及时和社区沟通，并且发起讨论，最终我们贡献了该 Feature。现在在 StreamPark 开启 LDAP 已经变得非常简单，只需要简单两步即可：</p>
<h4 class="anchor anchorWithStickyNavbar_myWT" id="step1-填写对应的-ldap-配置">step1: 填写对应的 LDAP 配置:<a href="#step1-填写对应的-ldap-配置" class="hash-link" aria-label="step1: 填写对应的 LDAP 配置:的直接链接" title="step1: 填写对应的 LDAP 配置:的直接链接">​</a></h4>
<p>编辑 application.yml 文件，设置 LDAP 基础信息，如下：</p>
<div class="language-yaml codeBlockContainer_APcc theme-code-block"><div class="codeBlockContent_IhPH"><pre tabindex="0" class="prism-code language-yaml codeBlock_tTXe thin-scrollbar" style="color:#9CDCFE;background-color:#1E1E1E"><code class="codeBlockLines_qImF"><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"></span><span class="token key atrule">ldap</span><span class="token punctuation" style="color:rgb(212, 212, 212)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">  </span><span class="token comment" style="color:rgb(106, 153, 85)"># Is ldap enabled?</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">  </span><span class="token key atrule">enable</span><span class="token punctuation" style="color:rgb(212, 212, 212)">:</span><span class="token plain"> </span><span class="token boolean important">false</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">  </span><span class="token comment" style="color:rgb(106, 153, 85)">## AD server IP, default port 389</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">  </span><span class="token key atrule">urls</span><span class="token punctuation" style="color:rgb(212, 212, 212)">:</span><span class="token plain"> ldap</span><span class="token punctuation" style="color:rgb(212, 212, 212)">:</span><span class="token plain">//99.99.99.99</span><span class="token punctuation" style="color:rgb(212, 212, 212)">:</span><span class="token number" style="color:rgb(181, 206, 168)">389</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">  </span><span class="token comment" style="color:rgb(106, 153, 85)">## Login Account</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">  </span><span class="token key atrule">base-dn</span><span class="token punctuation" style="color:rgb(212, 212, 212)">:</span><span class="token plain"> dc=streampark</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain">dc=com</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">  </span><span class="token key atrule">username</span><span class="token punctuation" style="color:rgb(212, 212, 212)">:</span><span class="token plain"> cn=Manager</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain">dc=streampark</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain">dc=com</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">  </span><span class="token key atrule">password</span><span class="token punctuation" style="color:rgb(212, 212, 212)">:</span><span class="token plain"> streampark</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">  </span><span class="token key atrule">user</span><span class="token punctuation" style="color:rgb(212, 212, 212)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">    </span><span class="token key atrule">identity-attribute</span><span class="token punctuation" style="color:rgb(212, 212, 212)">:</span><span class="token plain"> uid</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">    </span><span class="token key atrule">email-attribute</span><span class="token punctuation" style="color:rgb(212, 212, 212)">:</span><span class="token plain"> mail</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span></code></pre><div class="buttonGroup_inAn"><button type="button" aria-label="复制代码到剪贴板" title="复制" class="clean-btn"><span class="copyButtonIcons_N8Av" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_EGLt"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_gJas"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h4 class="anchor anchorWithStickyNavbar_myWT" id="step2--ldap-登陆">step2:  LDAP 登陆<a href="#step2--ldap-登陆" class="hash-link" aria-label="step2:  LDAP 登陆的直接链接" title="step2:  LDAP 登陆的直接链接">​</a></h4>
<p>登录界面点击 LDAP 方式登录，然后输入对应的账号密码，点击登录即可</p>
<p><img decoding="async" loading="lazy" src="/zh-CN/assets/images/ldap-39a8f66b7bba105117ecbfc54551dc95.png" width="1080" height="581" class="img__KcZ"></p>
<h3 class="anchor anchorWithStickyNavbar_myWT" id="02-提交作业自动生成-ingress"><strong>02 提交作业自动生成 Ingress</strong><a href="#02-提交作业自动生成-ingress" class="hash-link" aria-label="02-提交作业自动生成-ingress的直接链接" title="02-提交作业自动生成-ingress的直接链接">​</a></h3>
<p>由于公司的网络安全政策，运维人员在 Kubernetes 的宿主机上仅开放了 80 端口，这导致我们无法直接通过 “域名+随机端口” 的方式访问在 Kubernetes 上的作业 WebUI。为了解决这个问题，我们需要使用Ingress在访问路径上增加一层代理，从而启到访问路由的效果。在 StreamPark 2.0 版本我们贡献了 Ingress 相关的功能[3]。采用了策略模式的实现方式，在初始构建阶段，获取 Kubernetes 的元数据信息来识别其版本，针对不同版本来进行相应的对象构建，确保了在各种 Kubernetes 环境中都能够顺利地使用 Ingress 功能。</p>
<p>具体的配置步骤如下：</p>
<h4 class="anchor anchorWithStickyNavbar_myWT" id="step1-点击进入-setting--选择-ingress-setting填写域名">step1: 点击进入 Setting-&gt; 选择 Ingress Setting，填写域名<a href="#step1-点击进入-setting--选择-ingress-setting填写域名" class="hash-link" aria-label="step1: 点击进入 Setting-&gt; 选择 Ingress Setting，填写域名的直接链接" title="step1: 点击进入 Setting-&gt; 选择 Ingress Setting，填写域名的直接链接">​</a></h4>
<p><img decoding="async" loading="lazy" src="/zh-CN/assets/images/ingress_setting-2b8e1403aae4ff708a05f61f87d34733.png" width="1080" height="384" class="img__KcZ"></p>
<h4 class="anchor anchorWithStickyNavbar_myWT" id="step2-提交作业">step2: 提交作业<a href="#step2-提交作业" class="hash-link" aria-label="step2: 提交作业的直接链接" title="step2: 提交作业的直接链接">​</a></h4>
<p><img decoding="async" loading="lazy" src="/zh-CN/assets/images/k8s_job-1759da059df126162f2b7e0c7b9b121a.png" width="1080" height="367" class="img__KcZ"></p>
<p>点击进入 K8s 管理平台，可以观察到在提交 Flink 作业的同时会对应提交一个名称相同的 Ingress</p>
<h4 class="anchor anchorWithStickyNavbar_myWT" id="step3-点击进入-flink-的-webui">step3: 点击进入 Flink 的 WebUI<a href="#step3-点击进入-flink-的-webui" class="hash-link" aria-label="step3: 点击进入 Flink 的 WebUI的直接链接" title="step3: 点击进入 Flink 的 WebUI的直接链接">​</a></h4>
<p>可以观察到生成的地址将由三部分组成：域名 + 作业提交的命名空间 + 作业名称</p>
<p><img decoding="async" loading="lazy" src="/zh-CN/assets/images/flink_webui-ca719f066a60a19004af7d6761eae27d.png" width="1080" height="451" class="img__KcZ"></p>
<h3 class="anchor anchorWithStickyNavbar_myWT" id="03-支持查看作业部署日志"><strong>03 支持查看作业部署日志</strong><a href="#03-支持查看作业部署日志" class="hash-link" aria-label="03-支持查看作业部署日志的直接链接" title="03-支持查看作业部署日志的直接链接">​</a></h3>
<p>在持续部署作业的过程中，我们逐渐意识到，没有日志就无法进行有效的运维操作，日志的留存归档和查看成为了我们在后期排查问题时非常重要的一环。因此在 StreamPark 2.0 版本我们贡献了 On Kubernetes 模式下启动日志存档、页面查看的能力[4]，现在点击作业列表里的日志查看按钮，可以很方便的查看作业的实时日志。</p>
<p><img decoding="async" loading="lazy" src="/zh-CN/assets/images/k8s_log-aafb7f2dff97d584b187ab4a22de9eaf.png" width="1080" height="473" class="img__KcZ"></p>
<h3 class="anchor anchorWithStickyNavbar_myWT" id="04-集成-grafana-监控图表链接"><strong>04 集成 Grafana 监控图表链接</strong><a href="#04-集成-grafana-监控图表链接" class="hash-link" aria-label="04-集成-grafana-监控图表链接的直接链接" title="04-集成-grafana-监控图表链接的直接链接">​</a></h3>
<p>在实际的使用过程中，我们发现随着作业数量的增加，使用人数的上升，以及涉及的部门的增多，面临故障自排查困难的问题。我们团队的运维能力实际上是非常有限的。由于专业领域的不同，当我们告诉用户去 Grafana、ELK 上查看图表和日志时，用户通常会感到无从下手，不知道如何去找到与自己作业相关的信息。</p>
<p>为了解决这个问题，我们在社区提出一个需求：希望每个作业都能够通过超链接直接跳转到对应的监控图表和日志归档页面，这样使用者就可以直接查看与自己作业相关的监控信息和日志。无需在复杂的系统界面中进行繁琐的搜索，从而提高故障排查的效率。</p>
<p>我们在社区展开了讨论、并很快得到响应、大家都认为这是一个普遍存在的需求、因此很快有开发小伙伴提交了设计和相关PR，该问题也很快被解决，现在在 StreamPark 中要开启该功能已经变得非常简单:</p>
<h4 class="anchor anchorWithStickyNavbar_myWT" id="step1-创建徽章标签">step1: 创建徽章标签<a href="#step1-创建徽章标签" class="hash-link" aria-label="step1: 创建徽章标签的直接链接" title="step1: 创建徽章标签的直接链接">​</a></h4>
<p><img decoding="async" loading="lazy" src="/zh-CN/assets/images/create_badge_label-a6542822bd5a1e9274ca0017d25a9ccd.png" width="1080" height="649" class="img__KcZ"></p>
<h4 class="anchor anchorWithStickyNavbar_myWT" id="step2-将徽章标签和跳转链接进行关联">step2: 将徽章标签和跳转链接进行关联<a href="#step2-将徽章标签和跳转链接进行关联" class="hash-link" aria-label="step2: 将徽章标签和跳转链接进行关联的直接链接" title="step2: 将徽章标签和跳转链接进行关联的直接链接">​</a></h4>
<p><img decoding="async" loading="lazy" src="/zh-CN/assets/images/relevancy-a1914717d6479d16e07f7f1e6193f409.png" width="1062" height="400" class="img__KcZ"></p>
<h4 class="anchor anchorWithStickyNavbar_myWT" id="step3-点击徽章标签进行链接跳转">step3: 点击徽章标签进行链接跳转<a href="#step3-点击徽章标签进行链接跳转" class="hash-link" aria-label="step3: 点击徽章标签进行链接跳转的直接链接" title="step3: 点击徽章标签进行链接跳转的直接链接">​</a></h4>
<p><img decoding="async" loading="lazy" src="/zh-CN/assets/images/link_jump-f353a479fac3e5576056edcaab705dda.png" width="1080" height="381" class="img__KcZ"></p>
<h3 class="anchor anchorWithStickyNavbar_myWT" id="05-集成-flink-sql-security-权限控制"><strong>05 集成 Flink sql security 权限控制</strong><a href="#05-集成-flink-sql-security-权限控制" class="hash-link" aria-label="05-集成-flink-sql-security-权限控制的直接链接" title="05-集成-flink-sql-security-权限控制的直接链接">​</a></h3>
<p>在我们的系统中，血缘关系管理采用 Apache Atlas，权限管理基于开源项目 Flink-sql-security，这是一个FlinkSQL数据脱敏和行级权限解决方案的开源项目，支持面向用户级别的数据脱敏和行级数据访问控制， 即特定用户只能访问到脱敏后的数据或授权过的行。</p>
<p>这种设计是为了处理一些复杂的继承逻辑。例如，当将加密字段 age 的A 表与 B 表进行 join 操作，得到 C 表时，C 表中的 age 字段应继承 A 表的加密逻辑，以确保数据的加密状态不会因数据处理过程中的转换而失效。这样，我们可以更好地保护数据的安全性，确保数据在整个处理过程中都符合安全标准。</p>
<p>在权限控制方面，我们基于 Flink-sql-security 做了二次开发，实现了 flink-sql-security-streampark 插件。基本的实现思路如下：</p>
<p>1.在检查提交时系统会解析传入的 SQL，获取 InputTable 和 OutputTable 两个数据集。</p>
<p>2.系统通过对远端权限服务的查询，获取到用户所绑定的 RBAC（基于角色的访问控制）权限。</p>
<p>3.根据获取到的 RBAC 权限，系统会得到对应的表的加密规则。</p>
<p>4.系统将通过重写 SQL，将原本 SQL 查询字段包上一层预设的加密算法，进而实现逻辑的重组。</p>
<p>5.最后，系统会根据重组后的逻辑，进行相应的提交。</p>
<p>通过这样的整合和插件的开发，我们实现了对用户查询请求的权限控制，从而确保了数据的安全性。</p>
<p><strong>01行级权限条件</strong></p>
<p><img decoding="async" loading="lazy" src="/zh-CN/assets/images/row_level_permissions-cd7665f926dd3c92e8479be34f9084d5.png" width="1080" height="348" class="img__KcZ"></p>
<p><img decoding="async" loading="lazy" src="/zh-CN/assets/images/row_level_permissions_table-780239498d6b6d09c8a5c1ffe4ad44ef.png" width="1080" height="151" class="img__KcZ"></p>
<p>输入 SQL</p>
<div class="language-shell codeBlockContainer_APcc theme-code-block"><div class="codeBlockContent_IhPH"><pre tabindex="0" class="prism-code language-shell codeBlock_tTXe thin-scrollbar" style="color:#9CDCFE;background-color:#1E1E1E"><code class="codeBlockLines_qImF"><span class="token-line" style="color:#9CDCFE"><span class="token plain">SELECT * FROM orders;执行SQL</span><br></span></code></pre><div class="buttonGroup_inAn"><button type="button" aria-label="复制代码到剪贴板" title="复制" class="clean-btn"><span class="copyButtonIcons_N8Av" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_EGLt"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_gJas"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>用户 A 的真实执行 SQL:</p>
<div class="language-shell codeBlockContainer_APcc theme-code-block"><div class="codeBlockContent_IhPH"><pre tabindex="0" class="prism-code language-shell codeBlock_tTXe thin-scrollbar" style="color:#9CDCFE;background-color:#1E1E1E"><code class="codeBlockLines_qImF"><span class="token-line" style="color:#9CDCFE"><span class="token plain">SELECT * FROM orders WHERE region = &#x27;beijing&#x27;;</span><br></span></code></pre><div class="buttonGroup_inAn"><button type="button" aria-label="复制代码到剪贴板" title="复制" class="clean-btn"><span class="copyButtonIcons_N8Av" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_EGLt"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_gJas"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>用户 B 的真实执行 SQL:</p>
<div class="language-shell codeBlockContainer_APcc theme-code-block"><div class="codeBlockContent_IhPH"><pre tabindex="0" class="prism-code language-shell codeBlock_tTXe thin-scrollbar" style="color:#9CDCFE;background-color:#1E1E1E"><code class="codeBlockLines_qImF"><span class="token-line" style="color:#9CDCFE"><span class="token plain">SELECT * FROM orders WHERE region = &#x27;hangzhou&#x27;;</span><br></span></code></pre><div class="buttonGroup_inAn"><button type="button" aria-label="复制代码到剪贴板" title="复制" class="clean-btn"><span class="copyButtonIcons_N8Av" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_EGLt"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_gJas"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p><strong>02字段脱敏条件</strong></p>
<p><img decoding="async" loading="lazy" src="/zh-CN/assets/images/field_desensitization-3005c6f1d9c2f7ad0530d09a5a9aecea.png" width="1080" height="269" class="img__KcZ"></p>
<p><img decoding="async" loading="lazy" src="/zh-CN/assets/images/field_desensitization_table-e200cbbf0081e2d416411659a188bb90.png" width="1080" height="160" class="img__KcZ"></p>
<p>输入 SQL</p>
<div class="language-shell codeBlockContainer_APcc theme-code-block"><div class="codeBlockContent_IhPH"><pre tabindex="0" class="prism-code language-shell codeBlock_tTXe thin-scrollbar" style="color:#9CDCFE;background-color:#1E1E1E"><code class="codeBlockLines_qImF"><span class="token-line" style="color:#9CDCFE"><span class="token plain">SELECT name, age, price, phone FROM user;</span><br></span></code></pre><div class="buttonGroup_inAn"><button type="button" aria-label="复制代码到剪贴板" title="复制" class="clean-btn"><span class="copyButtonIcons_N8Av" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_EGLt"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_gJas"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>执行 SQL:</p>
<p>用户 A 的真实执行 SQL:</p>
<div class="language-shell codeBlockContainer_APcc theme-code-block"><div class="codeBlockContent_IhPH"><pre tabindex="0" class="prism-code language-shell codeBlock_tTXe thin-scrollbar" style="color:#9CDCFE;background-color:#1E1E1E"><code class="codeBlockLines_qImF"><span class="token-line" style="color:#9CDCFE"><span class="token plain">SELECT Encryption_function(name), age, price, Sensitive_field_functions(phone) FROM user;</span><br></span></code></pre><div class="buttonGroup_inAn"><button type="button" aria-label="复制代码到剪贴板" title="复制" class="clean-btn"><span class="copyButtonIcons_N8Av" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_EGLt"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_gJas"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>用户 B 的真实执行 SQL:</p>
<div class="language-shell codeBlockContainer_APcc theme-code-block"><div class="codeBlockContent_IhPH"><pre tabindex="0" class="prism-code language-shell codeBlock_tTXe thin-scrollbar" style="color:#9CDCFE;background-color:#1E1E1E"><code class="codeBlockLines_qImF"><span class="token-line" style="color:#9CDCFE"><span class="token plain">SELECT name, Encryption_function(age), price, Sensitive_field_functions(phone) FROM user;</span><br></span></code></pre><div class="buttonGroup_inAn"><button type="button" aria-label="复制代码到剪贴板" title="复制" class="clean-btn"><span class="copyButtonIcons_N8Av" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_EGLt"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_gJas"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h3 class="anchor anchorWithStickyNavbar_myWT" id="06-基于-apache-streampark-的数据同步平台"><strong>06 基于 Apache StreamPark™ 的数据同步平台</strong><a href="#06-基于-apache-streampark-的数据同步平台" class="hash-link" aria-label="06-基于-apache-streampark-的数据同步平台的直接链接" title="06-基于-apache-streampark-的数据同步平台的直接链接">​</a></h3>
<p>随着 StreamPark 的技术解决方案在公司的成功落地，我们实现了对 Flink 作业的深度支持，从而为数据处理带来质的飞跃。这促使我们对过往的数据同步逻辑进行彻底的革新，目标是通过技术的优化和整合，最大限度地降低运维成本。因此，我们逐步替换了历史上的 Sqoop 作业、Canal 作业和 Hive JDBC Handler 作业，转而采用 Flink CDC 作业、Flink 流和批作业。在这个过程中，我们也不断优化和强化 StreamPark 的接口能力，新增了状态回调机制，同时实现了与 DolphinScheduler[7] 调度系统的完美集成，进一步提升了我们的数据处理能力。</p>
<p>外部系统集成 StreamPark 步骤如下，只需要简单几个步骤即可：</p>
<p>1.首先创建 API 访问的 Token：</p>
<p><img decoding="async" loading="lazy" src="/zh-CN/assets/images/token-94cb364497fe129fc62be3bbb7193390.png" width="1080" height="288" class="img__KcZ"></p>
<p>2.查看 Application 外部调用链接：</p>
<p><img decoding="async" loading="lazy" src="/zh-CN/assets/images/call_link-da9d24e3a1993590cf25da174d5fb676.png" width="1080" height="390" class="img__KcZ"></p>
<div class="language-shell codeBlockContainer_APcc theme-code-block"><div class="codeBlockContent_IhPH"><pre tabindex="0" class="prism-code language-shell codeBlock_tTXe thin-scrollbar" style="color:#9CDCFE;background-color:#1E1E1E"><code class="codeBlockLines_qImF"><span class="token-line" style="color:#9CDCFE"><span class="token plain">curl -X POST &#x27;/flink/app/start&#x27; \</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">-H &#x27;Authorization: $token&#x27; \</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">-H &#x27;Content-Type: application/x-www-form-urlencoded; charset=UTF-8&#x27; \</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">--data-urlencode &#x27;savePoint=&#x27; \</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">--data-urlencode &#x27;allowNonRestored=false&#x27; \</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">--data-urlencode &#x27;savePointed=false&#x27; \</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">--data-urlencode &#x27;id=100501&#x27;</span><br></span></code></pre><div class="buttonGroup_inAn"><button type="button" aria-label="复制代码到剪贴板" title="复制" class="clean-btn"><span class="copyButtonIcons_N8Av" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_EGLt"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_gJas"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>3.DolphinScheduler 中配置 Http 调度</p>
<p><img decoding="async" loading="lazy" src="/zh-CN/assets/images/http_scheduling-267e8ae0aa04d5901cd98bea50370d69.png" width="1080" height="576" class="img__KcZ"></p>
<h2 class="anchor anchorWithStickyNavbar_myWT" id="实践经验总结"><strong>实践经验总结</strong><a href="#实践经验总结" class="hash-link" aria-label="实践经验总结的直接链接" title="实践经验总结的直接链接">​</a></h2>
<p>在深度使用 StreamPark 实践过程中，我们总结了一些常见问题和实践过程中所探索出解决方案，我们把这些汇总成示例，仅供大家参考。</p>
<h3 class="anchor anchorWithStickyNavbar_myWT" id="01-构建-base-镜像"><strong>01 构建 Base 镜像</strong><a href="#01-构建-base-镜像" class="hash-link" aria-label="01-构建-base-镜像的直接链接" title="01-构建-base-镜像的直接链接">​</a></h3>
<p>要使用 StreamPark 在 Kubernetes 上部署一个 Flink 作业，首先要准备一个基于 Flink 构建的 Base 镜像。然后，在 Kubernetes 平台上，会使用用户所提供的镜像来启动 Flink 作业。如果是沿用官方所提供的 “裸镜像”，在实际开发中是远远不够的，用户开发的业务逻辑往往会涉及到上下游多个数据源，这就需要相关数据源的 Connector，以及 Hadoop 等关联依赖。因此需要将这部分依赖项打入镜像中，下面我将介绍具体操作步骤。</p>
<h4 class="anchor anchorWithStickyNavbar_myWT" id="step1-首先创建一个文件夹内部包含两个文件夹和一个-dockerfile-文件">step1: 首先创建一个文件夹，内部包含两个文件夹和一个 Dockerfile 文件<a href="#step1-首先创建一个文件夹内部包含两个文件夹和一个-dockerfile-文件" class="hash-link" aria-label="step1: 首先创建一个文件夹，内部包含两个文件夹和一个 Dockerfile 文件的直接链接" title="step1: 首先创建一个文件夹，内部包含两个文件夹和一个 Dockerfile 文件的直接链接">​</a></h4>
<p><img decoding="async" loading="lazy" src="data:image/png;base64,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" width="796" height="166" class="img__KcZ"></p>
<p>conf 文件夹：存放 HDFS 配置文件，主要用于配置 Flink 的 Checkpoint 写入和FlinkSQL 中使用 Hive 的元数据</p>
<p><img decoding="async" loading="lazy" src="/zh-CN/assets/images/hdfs_conf-8af6d1660d09b58fc28a6fec1bff604b.png" width="824" height="284" class="img__KcZ"></p>
<p>lib 文件夹：存放涉及到的 Jar 依赖包，如下：</p>
<p><img decoding="async" loading="lazy" src="/zh-CN/assets/images/lib-faa76eddded5bdcb4228bf65c2d3122d.png" width="842" height="722" class="img__KcZ"></p>
<p>Dockerfile 文件用于定义镜像的构建</p>
<div class="language-dockerfile codeBlockContainer_APcc theme-code-block"><div class="codeBlockContent_IhPH"><pre tabindex="0" class="prism-code language-dockerfile codeBlock_tTXe thin-scrollbar" style="color:#9CDCFE;background-color:#1E1E1E"><code class="codeBlockLines_qImF"><span class="token-line" style="color:#9CDCFE"><span class="token plain">FROM apache/flink:1.14.5-scala_2.11-java8</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">ENV TIME_ZONE=Asia/Shanghai</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">COPY ./conf /opt/hadoop/conf</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">COPY lib $FLINK_HOME/lib/</span><br></span></code></pre><div class="buttonGroup_inAn"><button type="button" aria-label="复制代码到剪贴板" title="复制" class="clean-btn"><span class="copyButtonIcons_N8Av" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_EGLt"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_gJas"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h4 class="anchor anchorWithStickyNavbar_myWT" id="step2-镜像构建命令使用多架构构建模式如下">step2: 镜像构建命令使用多架构构建模式，如下：<a href="#step2-镜像构建命令使用多架构构建模式如下" class="hash-link" aria-label="step2: 镜像构建命令使用多架构构建模式，如下：的直接链接" title="step2: 镜像构建命令使用多架构构建模式，如下：的直接链接">​</a></h4>
<div class="language-dockerfile codeBlockContainer_APcc theme-code-block"><div class="codeBlockContent_IhPH"><pre tabindex="0" class="prism-code language-dockerfile codeBlock_tTXe thin-scrollbar" style="color:#9CDCFE;background-color:#1E1E1E"><code class="codeBlockLines_qImF"><span class="token-line" style="color:#9CDCFE"><span class="token plain">docker buildx build --push --platform linux/amd64 -t ${私有镜像仓库地址}</span><br></span></code></pre><div class="buttonGroup_inAn"><button type="button" aria-label="复制代码到剪贴板" title="复制" class="clean-btn"><span class="copyButtonIcons_N8Av" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_EGLt"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_gJas"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h3 class="anchor anchorWithStickyNavbar_myWT" id="02-base-镜像集成-arthas-示例"><strong>02 Base 镜像集成 Arthas 示例</strong><a href="#02-base-镜像集成-arthas-示例" class="hash-link" aria-label="02-base-镜像集成-arthas-示例的直接链接" title="02-base-镜像集成-arthas-示例的直接链接">​</a></h3>
<p>随着公司内新发布上线的运行作业越来越多，团队内常常会遇到作业在长时间运行后性能下降的这种问题，如 Kafka 消费能力减弱、内存使用增加和 GC 时间延长等，我们是比较推荐使用Arthas，一  款阿里巴巴开源的 Java 诊断工具。可以通过全局视角实时查看java应用 load、内存、gc、线程的状态信息，并能在不修改应用代码的情况下，完成查看方法调用的出入参、异常，监测方法执行耗时，类加载信息等，可以大大提升我们线上问题排查效率。</p>
<p><img decoding="async" loading="lazy" src="/zh-CN/assets/images/arthas-31f8df2a167d53420d2b4a828003a449.png" width="1080" height="526" class="img__KcZ"></p>
<p><img decoding="async" loading="lazy" src="/zh-CN/assets/images/advanced-e5c462ae9a888deddb5939a7c8065732.png" width="1080" height="416" class="img__KcZ"></p>
<p><img decoding="async" loading="lazy" src="/zh-CN/assets/images/arthas_log-fbc7dc0891690e569c6ad63359fc52fd.png" width="1080" height="390" class="img__KcZ"></p>
<p>因此做了 base 镜像集成 arthas，来方便运行时问题的排查。</p>
<div class="language-dockerfile codeBlockContainer_APcc theme-code-block"><div class="codeBlockContent_IhPH"><pre tabindex="0" class="prism-code language-dockerfile codeBlock_tTXe thin-scrollbar" style="color:#9CDCFE;background-color:#1E1E1E"><code class="codeBlockLines_qImF"><span class="token-line" style="color:#9CDCFE"><span class="token plain">FROM apache/flink:1.14.5-scala_2.11-java8</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">ENV TIME_ZONE=Asia/Shanghai</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">COPY ./conf /opt/hadoop/conf</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">COPY lib $FLINK_HOME/lib/</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">RUN apt-get update --fix-missing &amp;&amp; apt-get install -y fontconfig --fix-missing &amp;&amp; \</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">    apt-get install -y openjdk-8-jdk &amp;&amp; \</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">    apt-get install -y ant &amp;&amp; \</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">    apt-get clean;</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">RUN apt-get install sudo -y</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"># Fix certificate issues</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">RUN apt-get update &amp;&amp; \</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">    apt-get install ca-certificates-java &amp;&amp; \</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">    apt-get clean &amp;&amp; \</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">    update-ca-certificates -f;</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"># Setup JAVA_HOME -- useful for docker commandline</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">ENV JAVA_HOME /usr/lib/jvm/java-8-openjdk-amd64/</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">RUN export JAVA_HOME</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">RUN apt-get install -y unzip</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">RUN curl -Lo arthas-packaging-latest-bin.zip  &#x27;https://arthas.aliyun.com/download/latest_version?mirror=aliyun&#x27;</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">RUN unzip -d arthas-latest-bin arthas-packaging-latest-bin.zip</span><br></span></code></pre><div class="buttonGroup_inAn"><button type="button" aria-label="复制代码到剪贴板" title="复制" class="clean-btn"><span class="copyButtonIcons_N8Av" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_EGLt"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_gJas"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h3 class="anchor anchorWithStickyNavbar_myWT" id="03-镜像中依赖冲突的解决方式"><strong>03 镜像中依赖冲突的解决方式</strong><a href="#03-镜像中依赖冲突的解决方式" class="hash-link" aria-label="03-镜像中依赖冲突的解决方式的直接链接" title="03-镜像中依赖冲突的解决方式的直接链接">​</a></h3>
<p>在使用 StreamPark 的过程中，我们常遇到基于 Base 镜像运行的 Flink 作业中出现 NoClassDefFoundError、ClassNotFoundException 和 NoSuchMethodError 这三种依赖冲突异常。排查思路就是，找到报错中所示的冲突类，所在的包路径。例如这个报错的类在 org.apache.orc<!-- -->:orc-core<!-- -->， 就到相应模块的目录下跑 mvn dependency::tree 然后搜 orc-core，看一下是谁带进来的依赖，用 exclusion 去掉就可以了。下面我通过一个 base 镜像中的 flink-shaded-hadoop-3-uber JAR 包引起的依赖冲突示例，来详细介绍通过自定义打包的方法来解决依赖冲突。</p>
<h4 class="anchor anchorWithStickyNavbar_myWT" id="step1-clone-flink-shaded-项目到本地">step1: Clone flink-shaded 项目到本地👇<a href="#step1-clone-flink-shaded-项目到本地" class="hash-link" aria-label="step1: Clone flink-shaded 项目到本地👇的 直接链接" title="step1: Clone flink-shaded 项目到本地👇的直接链接">​</a></h4>
<div class="language-shell codeBlockContainer_APcc theme-code-block"><div class="codeBlockContent_IhPH"><pre tabindex="0" class="prism-code language-shell codeBlock_tTXe thin-scrollbar" style="color:#9CDCFE;background-color:#1E1E1E"><code class="codeBlockLines_qImF"><span class="token-line" style="color:#9CDCFE"><span class="token plain">git clone https://github.com/apache/flink-shaded.git</span><br></span></code></pre><div class="buttonGroup_inAn"><button type="button" aria-label="复制代码到剪贴板" title="复制" class="clean-btn"><span class="copyButtonIcons_N8Av" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_EGLt"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_gJas"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p><img decoding="async" loading="lazy" src="/zh-CN/assets/images/flink_shaded-f21909c81059b2ea4ebd8307998cbc26.png" width="1080" height="529" class="img__KcZ"></p>
<h4 class="anchor anchorWithStickyNavbar_myWT" id="step2-项目加载到-idea-中">step2: 项目加载到 IDEA 中<a href="#step2-项目加载到-idea-中" class="hash-link" aria-label="step2: 项目加载到 IDEA 中的直接链接" title="step2: 项目加载到 IDEA 中的直接链接">​</a></h4>
<p><img decoding="async" loading="lazy" src="/zh-CN/assets/images/idea-d654040d5fad6fefd756ede9a9ac8a4b.png" width="1080" height="586" class="img__KcZ"></p>
<h4 class="anchor anchorWithStickyNavbar_myWT" id="step3-针对冲突的部分进行排除后再进行打包">step3: 针对冲突的部分进行排除后再进行打包。<a href="#step3-针对冲突的部分进行排除后再进行打包" class="hash-link" aria-label="step3: 针对冲突的部分进行排除  后再进行打包。的直接链接" title="step3: 针对冲突的部分进行排除后再进行打包。的直接链接">​</a></h4>
<h3 class="anchor anchorWithStickyNavbar_myWT" id="04-集中作业配置示例"><strong>04 集中作业配置示例</strong><a href="#04-集中作业配置示例" class="hash-link" aria-label="04-集中作业配置示例的直接链接" title="04-集中作业配置示例的直接链接">​</a></h3>
<p>使用 StreamPark 有个非常大的便利就是可以进行配置的集中管理，可以将所有的配置项，配置到平台所绑定的 Flink 目录下的 conf 文件中。</p>
<div class="language-shell codeBlockContainer_APcc theme-code-block"><div class="codeBlockContent_IhPH"><pre tabindex="0" class="prism-code language-shell codeBlock_tTXe thin-scrollbar" style="color:#9CDCFE;background-color:#1E1E1E"><code class="codeBlockLines_qImF"><span class="token-line" style="color:#9CDCFE"><span class="token plain">cd /flink-1.14.5/conf</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">vim flink-conf.yaml</span><br></span></code></pre><div class="buttonGroup_inAn"><button type="button" aria-label="复制代码到剪贴板" title="复制" class="clean-btn"><span class="copyButtonIcons_N8Av" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_EGLt"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_gJas"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p><img decoding="async" loading="lazy" src="/zh-CN/assets/images/conf-ff77bc47a1f6af137a3326cc05cfdfee.png" width="1080" height="562" class="img__KcZ"></p>
<p>配置完成后保存。然后进入到平台的 Setting 下，点击 Flink Conf 这个图标。</p>
<p><img decoding="async" loading="lazy" src="/zh-CN/assets/images/flink_conf-db4fdbcbac08f9e19eaf550c1332de25.png" width="1080" height="351" class="img__KcZ"></p>
<p>点击 Sync Conf 全局配置文件就会进行相应的同步，新提交的作业就会按照新的配置进行提交。</p>
<p><img decoding="async" loading="lazy" src="/zh-CN/assets/images/sync_conf-9d2b45b6f42376859fda062127e33d82.png" width="1080" height="485" class="img__KcZ"></p>
<h3 class="anchor anchorWithStickyNavbar_myWT" id="05-apache-streampark-配置-dns-解析"><strong>05 Apache StreamPark™ 配置 DNS 解析</strong><a href="#05-apache-streampark-配置-dns-解析" class="hash-link" aria-label="05-apache-streampark-配置-dns-解析的直接链接" title="05-apache-streampark-配置-dns-解析的直接链接">​</a></h3>
<p>在使用 StreamPark 平台提交 FlinkSQL 的过程中，一个正确合理的 DNS 解析配置非常重要。主要涉及到以下几点：</p>
<p>1.Flink 作业的 Checkpoint 写入 HDFS 需要通过 ResourceManager 获取的一个 HDFS 节点进行快照写入，如果企业中同时有发生Hadoop集群的扩容，并且这些这些新扩容出来的节点，没有被DNS解析服务所覆盖，就直接会导致Checkpoint失败，从而影响线上稳定。</p>
<p>2.Flink 作业的通常需要配置公司内部不同数据源的连接串。如果配置数据库的真实 IP 地址，往往这个地址会随着迁库时常发生变化，而导致线上作业异常退出。因此在实际生产中连接串往往是由域名加属性参数构成，请求时由DNS服务将其解析为真实 IP 地址，在进行访问。</p>
<p>起初，我们是通过 Pod Template 来维护 DNS 配置的。</p>
<div class="language-shell codeBlockContainer_APcc theme-code-block"><div class="codeBlockContent_IhPH"><pre tabindex="0" class="prism-code language-shell codeBlock_tTXe thin-scrollbar" style="color:#9CDCFE;background-color:#1E1E1E"><code class="codeBlockLines_qImF"><span class="token-line" style="color:#9CDCFE"><span class="token plain">apiVersion: v1</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">kind: Pod</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">metadata:</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">  name: pod-template</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">spec:</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">  hostAliases:</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">    - ip: 10.216.xxx.79</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">      hostnames:</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">        - handoop1</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">    - hostnames:</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">        - handoop2</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">      ip: 10.16.xx.48</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">    - hostnames:</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">        - handoop3</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">      ip: 10.16.xx.49</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">    - hostnames:</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">        - handoop4</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">      ip: 10.16.xx.50</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">   .......</span><br></span></code></pre><div class="buttonGroup_inAn"><button type="button" aria-label="复制代码到剪贴板" title="复制" class="clean-btn"><span class="copyButtonIcons_N8Av" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_EGLt"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_gJas"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>虽然该方法理论上可行，但在实际操作过程中，我们遭遇到了一系列问题。当进行 HDFS 扩容时，我们发现 Flink 的 Checkpoint 功能出现了写入失败的情况，而数据库迁移也出现了链接失败的问题，这导致我们的线上服务突然宕机。经过深入的排查，我们发现这些问题的根源在于 DNS 解析。</p>
<p>过去，我们曾使用 hostAliases 来维护域名和 IP 地址之间的映射关系。但这种方法在实际操作中代价较大，因为每当更新 hostAliases 时，我们都需要停掉所有的 Flink 作业，这无疑增加了我们的运维成本。为了寻求一种更为灵活和可靠的方法来管理 DNS 解析配置，保障 Flink 作业的正常运行，我们决定搭建 dnsmasq 来进行双向的 DNS 解析。</p>
<p>在完成 dnsmasq 的配置和安装后，我们首先需要对 Flink 镜像中 /etc 目录下的resolv.conf 配置文件进行覆盖。然而，由于 resolv.conf 是一个只读文件，如果我们想要覆盖它，就需要使用挂载的方式。因此，我们首先将 resolv.conf 配置成 ConfigMap，以便在覆盖过程中使用。这样，我们就能够更为灵活和可靠地管理DNS 解析配置，从而确保 Flink 作业的稳定运行。</p>
<div class="language-yaml codeBlockContainer_APcc theme-code-block"><div class="codeBlockContent_IhPH"><pre tabindex="0" class="prism-code language-yaml codeBlock_tTXe thin-scrollbar" style="color:#9CDCFE;background-color:#1E1E1E"><code class="codeBlockLines_qImF"><span class="token-line" style="color:#9CDCFE"><span class="token key atrule">apiVersion</span><span class="token punctuation" style="color:rgb(212, 212, 212)">:</span><span class="token plain"> v1</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"></span><span class="token key atrule">data</span><span class="token punctuation" style="color:rgb(212, 212, 212)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">  </span><span class="token key atrule">resolv.conf</span><span class="token punctuation" style="color:rgb(212, 212, 212)">:</span><span class="token plain"> &quot;nameserver  10.216.138.226&quot; //DNS服务</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"></span><span class="token key atrule">kind</span><span class="token punctuation" style="color:rgb(212, 212, 212)">:</span><span class="token plain"> ConfigMap</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"></span><span class="token key atrule">metadata</span><span class="token punctuation" style="color:rgb(212, 212, 212)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">  </span><span class="token key atrule">creationTimestamp</span><span class="token punctuation" style="color:rgb(212, 212, 212)">:</span><span class="token plain"> </span><span class="token string" style="color:rgb(206, 145, 120)">&quot;2022-07-13T10:16:18Z&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">  </span><span class="token key atrule">managedFields</span><span class="token punctuation" style="color:rgb(212, 212, 212)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">  </span><span class="token key atrule">name</span><span class="token punctuation" style="color:rgb(212, 212, 212)">:</span><span class="token plain"> dns</span><span class="token punctuation" style="color:rgb(212, 212, 212)">-</span><span class="token plain">configmap</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">  </span><span class="token key atrule">namespace</span><span class="token punctuation" style="color:rgb(212, 212, 212)">:</span><span class="token plain"> native</span><span class="token punctuation" style="color:rgb(212, 212, 212)">-</span><span class="token plain">flink</span><br></span></code></pre><div class="buttonGroup_inAn"><button type="button" aria-label="复制代码到剪贴板" title="复制" class="clean-btn"><span class="copyButtonIcons_N8Av" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_EGLt"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_gJas"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>在通过 Pod Template 进行挂载。</p>
<p><img decoding="async" loading="lazy" src="/zh-CN/assets/images/pod_template-d8a9864bc8486d493025cc5e8b0e6dd1.png" width="1080" height="476" class="img__KcZ"></p>
<p>这样大数据平台相关的 DNS 就可以维护在 dnsmasq 上，而 Flink 作业所运行的宿主机就可以按照 DNS 解析流程。</p>
<p>1.先检查自己本地的 hosts 文件，是否存在对应关系，读取到记录进行解析，没有则进行下一步</p>
<p>2.操作系统会去查看本地的 DNS 缓存，没有则进行下一步</p>
<p>3.操作系统会去我们在网络配置中定义的 DNS 服务器地址上进行查找</p>
<p>以此来实现动态的实现 DNS 的变更识别。</p>
<h3 class="anchor anchorWithStickyNavbar_myWT" id="06-多实例部署实践"><strong>06 多实例部署实践</strong><a href="#06-多实例部署实践" class="hash-link" aria-label="06-多实例部署实践的直接链接" title="06-多实例部署实践的直接链接">​</a></h3>
<p>在实际生产环境中，我们常常需要操作多个集群，包括一套用于测试的集群和一套线上正式集群。任务首先在测试集群中进行结果验证和性能压测，确保无误后再发布到线上正式集群。</p>
<h4 class="anchor anchorWithStickyNavbar_myWT" id="step1-修改端口号避免多个服务端口冲突">step1: 修改端口号，避免多个服务端口冲突<a href="#step1-修改端口号避免多个服务端口冲突" class="hash-link" aria-label="step1: 修改端口号，避免多个服务端口冲突的直接链接" title="step1: 修改端口号，避免多个服务端口冲突的直接链接">​</a></h4>
<p><img decoding="async" loading="lazy" src="/zh-CN/assets/images/port_number-e421801c946def0b0e2df3747239fec6.png" width="1080" height="622" class="img__KcZ"></p>
<h4 class="anchor anchorWithStickyNavbar_myWT" id="step2-修改-workspace">step2: 修改 workspace<a href="#step2-修改-workspace" class="hash-link" aria-label="step2: 修改 workspace的直接链接" title="step2: 修改 workspace的直接链接">​</a></h4>
<p>多个不同的实例服务需要配置多个不同的 workspace，这样避免资源干扰导致出现一些奇怪 bug。</p>
<h4 class="anchor anchorWithStickyNavbar_myWT" id="step3-启动多实例服务">step3: 启动多实例服务<a href="#step3-启动多实例服务" class="hash-link" aria-label="step3: 启动多实例服务的直接链接" title="step3: 启动多实例服务的直接链接">​</a></h4>
<p>为了实现生产环境与测试环境的隔离，我们在启动流程的初始阶段引入了一个关键步骤。我们通过输入命令(针对Hadoop B 集群):</p>
<div class="language-shell codeBlockContainer_APcc theme-code-block"><div class="codeBlockContent_IhPH"><pre tabindex="0" class="prism-code language-shell codeBlock_tTXe thin-scrollbar" style="color:#9CDCFE;background-color:#1E1E1E"><code class="codeBlockLines_qImF"><span class="token-line" style="color:#9CDCFE"><span class="token plain">export HADOOP_CONF_DIR=/home/streamx/conf</span><br></span></code></pre><div class="buttonGroup_inAn"><button type="button" aria-label="复制代码到剪贴板" title="复制" class="clean-btn"><span class="copyButtonIcons_N8Av" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_EGLt"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_gJas"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>有效地切断了 Flink on K8s 加载 HDFS 配置的默认逻辑。这样的操作确保了 A StreamPark 仅连接至 A Hadoop 环境，而 B StreamPark 则对应连接至 B Hadoop 环境，从而达到了将测试和生产环境进行完整隔离的目的。</p>
<p>具体来说，在这一操作指令生效后，我们就可以确保在 10002 端口提交的 Flink 作业所连接的 Hadoop 环境为 B Hadoop 环境。这样一来，B Hadoop 环境与过去在 10000 端口提交的 Flink 作业所使用的Hadoop环境就成功实现了隔离，有效防止了不同环境之间的相互干扰，确保了系统的稳定性和可靠性。</p>
<p>下述内容为 Flink 加载 Hadoop 环境逻辑代码分析：</p>
<div class="language-yaml codeBlockContainer_APcc theme-code-block"><div class="codeBlockContent_IhPH"><pre tabindex="0" class="prism-code language-yaml codeBlock_tTXe thin-scrollbar" style="color:#9CDCFE;background-color:#1E1E1E"><code class="codeBlockLines_qImF"><span class="token-line" style="color:#9CDCFE"><span class="token plain">// 寻找hadoop配置文件的流程</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">//1、先去寻找是否添加了参数</span><span class="token punctuation" style="color:rgb(212, 212, 212)">:</span><span class="token plain">kubernetes.hadoop.conf.config</span><span class="token punctuation" style="color:rgb(212, 212, 212)">-</span><span class="token plain">map.name</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">@Override</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">public Optional&lt;String</span><span class="token punctuation" style="color:rgb(212, 212, 212)">&gt;</span><span class="token plain"> getExistingHadoopConfigurationConfigMap() </span><span class="token punctuation" style="color:rgb(212, 212, 212)">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">    final String existingHadoopConfigMap =</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">            flinkConfig.getString(KubernetesConfigOptions.HADOOP_CONF_CONFIG_MAP);</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">    if (StringUtils.isBlank(existingHadoopConfigMap)) </span><span class="token punctuation" style="color:rgb(212, 212, 212)">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">        return Optional.empty();</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">    </span><span class="token punctuation" style="color:rgb(212, 212, 212)">}</span><span class="token plain"> else </span><span class="token punctuation" style="color:rgb(212, 212, 212)">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">        return Optional.of(existingHadoopConfigMap.trim());</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">    </span><span class="token punctuation" style="color:rgb(212, 212, 212)">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"></span><span class="token punctuation" style="color:rgb(212, 212, 212)">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">@Override</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">public Optional&lt;String</span><span class="token punctuation" style="color:rgb(212, 212, 212)">&gt;</span><span class="token plain"> getLocalHadoopConfigurationDirectory() </span><span class="token punctuation" style="color:rgb(212, 212, 212)">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">    // 2、如果没有 1 中指定的参数，查找提交 native 命令的本地环境是否有环境变量</span><span class="token punctuation" style="color:rgb(212, 212, 212)">:</span><span class="token plain">HADOOP_CONF_DIR</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">    final String hadoopConfDirEnv = System.getenv(Constants.ENV_HADOOP_CONF_DIR);</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">    if (StringUtils.isNotBlank(hadoopConfDirEnv)) </span><span class="token punctuation" style="color:rgb(212, 212, 212)">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">        return Optional.of(hadoopConfDirEnv);</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">    </span><span class="token punctuation" style="color:rgb(212, 212, 212)">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">    // 3、如果没有 2 中环境变量，再继续看否有环境变量</span><span class="token punctuation" style="color:rgb(212, 212, 212)">:</span><span class="token plain">HADOOP_HOME</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">    final String hadoopHomeEnv = System.getenv(Constants.ENV_HADOOP_HOME);</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">    if (StringUtils.isNotBlank(hadoopHomeEnv)) </span><span class="token punctuation" style="color:rgb(212, 212, 212)">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">        // Hadoop 2.2+</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">        final File hadoop2ConfDir = new File(hadoopHomeEnv</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"> &quot;/etc/hadoop&quot;);</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">        if (hadoop2ConfDir.exists()) </span><span class="token punctuation" style="color:rgb(212, 212, 212)">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">            return Optional.of(hadoop2ConfDir.getAbsolutePath());</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">        </span><span class="token punctuation" style="color:rgb(212, 212, 212)">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">        // Hadoop 1.x</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">        final File hadoop1ConfDir = new File(hadoopHomeEnv</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"> &quot;/conf&quot;);</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">        if (hadoop1ConfDir.exists()) </span><span class="token punctuation" style="color:rgb(212, 212, 212)">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">            return Optional.of(hadoop1ConfDir.getAbsolutePath());</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">        </span><span class="token punctuation" style="color:rgb(212, 212, 212)">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">    </span><span class="token punctuation" style="color:rgb(212, 212, 212)">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">    return Optional.empty();</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"></span><span class="token punctuation" style="color:rgb(212, 212, 212)">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">final List&lt;File</span><span class="token punctuation" style="color:rgb(212, 212, 212)">&gt;</span><span class="token plain"> hadoopConfigurationFileItems = getHadoopConfigurationFileItems(localHadoopConfigurationDirectory.get());</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">// 如果没有找到 1、2、3 说明没有 hadoop 环境</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">if (hadoopConfigurationFileItems.isEmpty()) </span><span class="token punctuation" style="color:rgb(212, 212, 212)">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">    LOG.warn(</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">            &quot;Found 0 files in directory </span><span class="token punctuation" style="color:rgb(212, 212, 212)">{</span><span class="token punctuation" style="color:rgb(212, 212, 212)">}</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"> skip to mount the Hadoop Configuration ConfigMap.&quot;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">            localHadoopConfigurationDirectory.get());</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">    return flinkPod;</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"></span><span class="token punctuation" style="color:rgb(212, 212, 212)">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">// 如果 2 或者 3 存在，会在路径下查找 core</span><span class="token punctuation" style="color:rgb(212, 212, 212)">-</span><span class="token plain">site.xml 和 hdfs</span><span class="token punctuation" style="color:rgb(212, 212, 212)">-</span><span class="token plain">site.xml 文件</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">private List&lt;File</span><span class="token punctuation" style="color:rgb(212, 212, 212)">&gt;</span><span class="token plain"> getHadoopConfigurationFileItems(String localHadoopConfigurationDirectory) </span><span class="token punctuation" style="color:rgb(212, 212, 212)">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">    final List&lt;String</span><span class="token punctuation" style="color:rgb(212, 212, 212)">&gt;</span><span class="token plain"> expectedFileNames = new ArrayList&lt;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">&gt;</span><span class="token plain">();</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">    expectedFileNames.add(&quot;core</span><span class="token punctuation" style="color:rgb(212, 212, 212)">-</span><span class="token plain">site.xml&quot;);</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">    expectedFileNames.add(&quot;hdfs</span><span class="token punctuation" style="color:rgb(212, 212, 212)">-</span><span class="token plain">site.xml&quot;);</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">    final File directory = new File(localHadoopConfigurationDirectory);</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">    if (directory.exists() </span><span class="token important">&amp;&amp;</span><span class="token plain"> directory.isDirectory()) </span><span class="token punctuation" style="color:rgb(212, 212, 212)">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">        return Arrays.stream(directory.listFiles())</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">                .filter(</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">                        file </span><span class="token punctuation" style="color:rgb(212, 212, 212)">-</span><span class="token punctuation" style="color:rgb(212, 212, 212)">&gt;</span><span class="token scalar string" style="color:rgb(206, 145, 120)"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token scalar string" style="color:rgb(206, 145, 120)">                                file.isFile()</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token scalar string" style="color:rgb(206, 145, 120)">                                        &amp;&amp; expectedFileNames.stream()</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token scalar string" style="color:rgb(206, 145, 120)">                                                .anyMatch(name -&gt; file.getName().equals(name)))</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">                .collect(Collectors.toList());</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">    </span><span class="token punctuation" style="color:rgb(212, 212, 212)">}</span><span class="token plain"> else </span><span class="token punctuation" style="color:rgb(212, 212, 212)">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">        return Collections.emptyList();</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">    </span><span class="token punctuation" style="color:rgb(212, 212, 212)">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"></span><span class="token punctuation" style="color:rgb(212, 212, 212)">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">//如果有 hadoop 的环境，将会把上述两个文件解析为 kv 对，然后构建成一个 ConfigMap，名字命名规则如下</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">public static String getHadoopConfConfigMapName(String clusterId) </span><span class="token punctuation" style="color:rgb(212, 212, 212)">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">    return Constants.HADOOP_CONF_CONFIG_MAP_PREFIX + clusterId;</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"></span><span class="token punctuation" style="color:rgb(212, 212, 212)">}</span><br></span></code></pre><div class="buttonGroup_inAn"><button type="button" aria-label="复制代码到剪贴板" title="复制" class="clean-btn"><span class="copyButtonIcons_N8Av" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_EGLt"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_gJas"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>然后进行进程端口占用查询：</p>
<div class="language-shell codeBlockContainer_APcc theme-code-block"><div class="codeBlockContent_IhPH"><pre tabindex="0" class="prism-code language-shell codeBlock_tTXe thin-scrollbar" style="color:#9CDCFE;background-color:#1E1E1E"><code class="codeBlockLines_qImF"><span class="token-line" style="color:#9CDCFE"><span class="token plain">netstat -tlnp | grep 10000</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">netstat -tlnp | grep 10002</span><br></span></code></pre><div class="buttonGroup_inAn"><button type="button" aria-label="复制代码到剪贴板" title="复制" class="clean-btn"><span class="copyButtonIcons_N8Av" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_EGLt"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_gJas"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h2 class="anchor anchorWithStickyNavbar_myWT" id="带来的收益"><strong>带来的收益</strong><a href="#带来的收益" class="hash-link" aria-label="带来的收益的直接链接" title="带来的收益的直接链接">​</a></h2>
<p>我们的团队从 StreamX（即 StreamPark 的前身）开始使用，经过一年多的实践和磨合，StreamPark 显著改善了我们在 Apache Flink® 作业的开发管理和运维上的诸多挑战。StreamPark 作为一站式服务平台，极大地简化了整个开发流程。现在，我们可以直接在 StreamPark 平台上完成作业的开发、编译和发布，这不仅降低了 Flink 的管理和部署门槛，还显著提高了开发效率。</p>
<p>自从部署 StreamPark 以来，我们已经在生产环境中大规模使用该平台。从最初管理的 50 多个 FlinkSQL 作业，增长到目前近 500 个作业，如图在 StreamPark 上划分为 7 个 team，每个 team 中有几十个作业。这一转变不仅展示了 StreamPark 的可扩展性和高效性，也充分证明了它在实际业务中的强大应用价值。</p>
<p><img decoding="async" loading="lazy" src="/zh-CN/assets/images/production_environment-4f155f3b14a4e95c5367ba99a6c5a6f8.png" width="1080" height="522" class="img__KcZ"></p>
<h2 class="anchor anchorWithStickyNavbar_myWT" id="未-来-期-待"><strong>未 来 期 待</strong><a href="#未-来-期-待" class="hash-link" aria-label="未-来-期-待的直接链接" title="未-来-期-待的直接链接">​</a></h2>
<p>自如作为 StreamPark 早期的用户之一，我们一直和社区同学保持密切交流，参与 StreamPark 的稳定性打磨，我们将生产运维中遇到的 Bug 和新的 Feature 提交给了社区。在未来，我们希望可以在 StreamPark 上管理 Apache Paimon 湖表的元数据信息和 Paimon 的 Action 辅助作业的能力，基于 Flink 引擎通过对接湖  表的 Catalog 和 Action 作业，来实现湖表作业的管理、优化于一体的能力。目前 StreamPark 正在对接 Paimon 数据集成的能力，这一块在未来对于实时一键入湖会提供很大的帮助。</p>
<p>在此也非常感谢 StreamPark 团队一直以来对我们的技术支持，祝 Apache StreamPark 越来越好，越来越多用户去使用，早日毕业成为顶级 Apache 项目。</p></div><footer class="row docusaurus-mt-lg blogPostFooterDetailsFull_Wr5y"><div class="post-footer"><div class="col"><b>标签：</b><ul class="tags_bUDc padding--none margin-left--sm"><li class="tag_edSN"><a class="tag_mtSO tagRegular_u5wg" href="/zh-CN/blog/tags/stream-park">StreamPark</a></li><li class="tag_edSN"><a class="tag_mtSO tagRegular_u5wg" href="/zh-CN/blog/tags/生产实践">生产实践</a></li></ul></div><div class="col col-3 text--right"><a href="https://github.com/apache/incubator-streampark-website/edit/dev/blog/8-streampark-usercase-ziru.md" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_WHnd" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>编辑此页</a></div></div></footer></article></div></div></div><nav class="pagination-nav docusaurus-mt-lg" aria-label="博文分页导航"><a class="pagination-nav__link pagination-nav__link--prev paginationNavLink_UdUv" href="/zh-CN/blog/streampark-usercase-haibo"><svg width="24" height="25" viewBox="0 0 24 25" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M9.2751 19.175L10.3251 18.125L5.4501 13.25H21.6001V11.75H5.4501L10.3251 6.87501L9.2751 5.82501L2.5751 12.5L9.2751 19.175Z" fill="currentColor"></path></svg><div class="paginationNavContent__3xr"><div class="pagination-nav__sublabel">较新一篇</div><div class="paginationNavLabel_YPzM pagination-nav__label">Apache StreamPark™ 一站式计算利器在海博科技的生产实践，助力智慧城市建设</div></div></a><a class="pagination-nav__link pagination-nav__link--next paginationNavLink_UdUv" href="/zh-CN/blog/streampark-usercase-changan"><div class="paginationNavContent__3xr"><div class="pagination-nav__sublabel">较旧一篇</div><div class="paginationNavLabel_YPzM pagination-nav__label">长安汽车从自研平台到Apache StreamPark™ 的升级实践</div></div><svg width="24" height="25" viewBox="0 0 24 25" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M14.7249 19.175L13.6749 18.125L18.5499 13.25H2.3999V11.75H18.5499L13.6749 6.87501L14.7249 5.82501L21.4249 12.5L14.7249 19.175Z" fill="currentColor"></path></svg></a></nav></main><div class="col col--2"><div class="tableOfContents_jeP5 thin-scrollbar" style="opacity:0;transform:translateX(100px) translateZ(0)"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#实时计算遇到的挑战" class="table-of-contents__link toc-highlight"><strong>实时计算遇到的挑战</strong></a><ul><li><a href="#01-作业上线效率低" class="table-of-contents__link toc-highlight"><strong>01 作业上线效率低</strong></a></li><li><a href="#02-作业归属信息不明确" class="table-of-contents__link toc-highlight"><strong>02 作业归属信息不明确</strong></a></li><li><a href="#03-作业维护困难" class="table-of-contents__link toc-highlight"><strong>03 作业维护困难</strong></a></li><li><a href="#04-作业开发调试困难" class="table-of-contents__link toc-highlight"><strong>04 作业开发调试困难</strong></a></li></ul></li><li><a href="#寻求解决方案之路" class="table-of-contents__link toc-highlight"><strong>寻求解决方案之路</strong></a></li><li><a href="#基于-apache-streampark-的深度实践" class="table-of-contents__link toc-highlight"><strong>基于 Apache StreamPark™ 的深度实践</strong></a><ul><li><a href="#01-ldap-登录支持" class="table-of-contents__link toc-highlight"><strong>01 LDAP 登录支持</strong></a></li><li><a href="#02-提交作业自动生成-ingress" class="table-of-contents__link toc-highlight"><strong>02 提交作业自动生成 Ingress</strong></a></li><li><a href="#03-支持查看作业部署日志" class="table-of-contents__link toc-highlight"><strong>03 支持查看作业部署日志</strong></a></li><li><a href="#04-集成-grafana-监控图表链接" class="table-of-contents__link toc-highlight"><strong>04 集成 Grafana 监控图表链接</strong></a></li><li><a href="#05-集成-flink-sql-security-权限控制" class="table-of-contents__link toc-highlight"><strong>05 集成 Flink sql security 权限控制</strong></a></li><li><a href="#06-基于-apache-streampark-的数据同步平台" class="table-of-contents__link toc-highlight"><strong>06 基于 Apache StreamPark™ 的数据同步平台</strong></a></li></ul></li><li><a href="#实践经验总结" class="table-of-contents__link toc-highlight"><strong>实践经验总结</strong></a><ul><li><a href="#01-构建-base-镜像" class="table-of-contents__link toc-highlight"><strong>01 构建 Base 镜像</strong></a></li><li><a href="#02-base-镜像集成-arthas-示例" class="table-of-contents__link toc-highlight"><strong>02 Base 镜像集成 Arthas 示例</strong></a></li><li><a href="#03-镜像中依赖冲突的解决方式" class="table-of-contents__link toc-highlight"><strong>03 镜像中依赖冲突的解决方式</strong></a></li><li><a href="#04-集中作业配置示例" class="table-of-contents__link toc-highlight"><strong>04 集中作业配置示例</strong></a></li><li><a href="#05-apache-streampark-配置-dns-解析" class="table-of-contents__link toc-highlight"><strong>05 Apache StreamPark™ 配置 DNS 解析</strong></a></li><li><a href="#06-多实例部署实践" class="table-of-contents__link toc-highlight"><strong>06 多实例部署实践</strong></a></li></ul></li><li><a href="#带来的收益" class="table-of-contents__link toc-highlight"><strong>带来的收益</strong></a></li><li><a href="#未-来-期-待" class="table-of-contents__link toc-highlight"><strong>未 来 期 待</strong></a></li></ul></div></div></div></div></div></div><footer class="footer"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">加入社区</div><ul class="footer__items clean-list"><li class="footer__item">
                <div class="subscribe-box btns">
                  <a class="btn btn-primary" href="https://github.com/apache/incubator-streampark"><i class="fa fa-github"></i><span>Github</span></a>
                  <a class="btn btn-primary" href="https://github.com/apache/incubator-streampark/issues"><i class="fa fa-slack"></i><span>Issue Tracking</span></a>
                  <a class="btn btn-primary" href="javascript:void(0)">
                    <i class="fa fa-wechat"></i>
                    <span>Wechat</span>
                    <div class="wechat-dropdown"><img src="/image/join_wechat.png" alt="weChat"></div>
                  </a>
                </div>
              </li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright"><div>
        <div>
          <div style="margin-bottom: 30px;">
            <a href="https://incubator.apache.org/" class="footerLogoLink" one-link-mark="yes">
              <img alt="Apache Incubator logo" class="footer__logo" width="200">
            </a>
          </div>
          <div>
            <p>
            Apache StreamPark is an effort undergoing incubation at The Apache Software Foundation (ASF), sponsored by the Apache Incubator. Incubation is required of all newly accepted projects until a further review indicates that the infrastructure, communications, and decision making process have stabilized in a manner consistent with other successful ASF projects. While incubation status is not necessarily a reflection of the completeness or stability of the code, it does indicate that the project has yet to be fully endorsed by the ASF.
            </p>
          </div>
        </div>

        <div>
          <span>
            Copyright © 2022-2024 The Apache Software Foundation. Apache StreamPark, StreamPark, and its feather logo are trademarks of The Apache Software Foundation.
          </span>
        </div>
      </div></div></div></div></footer></div>
</body>
</html>